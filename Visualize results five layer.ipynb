{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8fbc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62836500",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RESULTS_DIR = os.path.join(\"P:/early_stopping_double_descent\", \"...\") # enter folder direction here (i.e., two_layer_results)\n",
    "RESULTS_DIR = \"results/five_layer_results\" #\"two_layer_classification_results\"\n",
    "\n",
    "SMALL_SIZE = 10\n",
    "MEDIUM_SIZE = 12\n",
    "BIGGER_SIZE = 14\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('axes', titlesize=BIGGER_SIZE)    # fontsize of the figure title\n",
    "\n",
    "\n",
    "def get_all_files(lr):\n",
    "    files = os.listdir(RESULTS_DIR)\n",
    "    files = [file for file in files if file.startswith(f'lr={lr}') and file.endswith(\"log.json\")]\n",
    "\n",
    "    return files\n",
    "\n",
    "\n",
    "def get_files():\n",
    "    files = os.listdir(RESULTS_DIR)\n",
    "    files = [file for file in files if file.endswith(\"log.json\")]\n",
    "\n",
    "    \n",
    "def append_id(filename, id):\n",
    "    return \"{0}_{2}.{1}\".format(*filename.rsplit('.', 1) + [id])\n",
    "\n",
    "\n",
    "# TODO: clean this up\n",
    "def get_run_name(lr1, lr2, wd=None, lrdecay=None, norandomflip=True, norandomcrop=True, momentum=True, inv_sqrt_lr=False, track_weights=False):\n",
    "    \n",
    "    run_name = f\"lr={lr1}_{lr2}\"\n",
    "    \n",
    "    if not norandomflip:\n",
    "        run_name += \"_r_flip\"\n",
    "        \n",
    "    if not norandomcrop:\n",
    "        run_name += \"_r_crop\"\n",
    "    \n",
    "    if wd is not None:\n",
    "        run_name += f\"_wd={wd}\"\n",
    "        \n",
    "    if lrdecay is not None:\n",
    "        run_name += f\"_ld={lrdecay}\"\n",
    "        \n",
    "    if track_weights:\n",
    "        run_name += \"_tw\"\n",
    "        \n",
    "    if not momentum:\n",
    "        run_name += \"_no_momentum\"\n",
    "        \n",
    "    if inv_sqrt_lr:\n",
    "        run_name += \"_inv_sq_lr\"\n",
    "        \n",
    "    return run_name\n",
    "    \n",
    "\n",
    "def get_filename_individual(lr1, lr2, ext=''):\n",
    "    result_path = os.path.split(RESULTS_DIR)[1]\n",
    "    result_path_split = result_path.split('_')\n",
    "    \n",
    "    name = f'lr1={lr1}_lr2={lr2}{ext}.pdf'\n",
    "    \n",
    "    return name\n",
    "\n",
    "\n",
    "def get_filename(lr, vmax):\n",
    "    result_path = os.path.split(RESULTS_DIR)[1]\n",
    "    result_path_split = result_path.split('_')\n",
    "\n",
    "    name = f'{lr}_vmax={vmax}.pdf'\n",
    "    \n",
    "    return name\n",
    "\n",
    "\n",
    "def get_filename_range(lr1, lr2_low, lr2_high):\n",
    "    result_path = os.path.split(RESULTS_DIR)[1]\n",
    "    result_path_split = result_path.split('_')\n",
    "    \n",
    "    name = f'lr1={lr1}_lr2_low={lr2_low}_lr2_high={lr2_high}.pdf'\n",
    "        \n",
    "    return name\n",
    "\n",
    "def get_save_dir():\n",
    "    \n",
    "    save_dir = \"plots\"\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)  \n",
    "\n",
    "    return save_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ef107b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(file_path, running_avg):\n",
    "    f = open(file_path)\n",
    "    data = json.load(f)\n",
    "\n",
    "    train_acc, test_acc = [], []\n",
    "\n",
    "    for i, d in enumerate(data):\n",
    "        train_acc.append(d[\"train\"][\"acc1\"])\n",
    "        test_acc.append(d[\"test\"][\"acc1\"])\n",
    "\n",
    "    train_err, test_err =  100 - np.array(train_acc), 100 - np.array(test_acc)\n",
    "\n",
    "    if running_avg:\n",
    "        train_err, test_err = get_running_avg(train_err), get_running_avg(test_err)\n",
    "        \n",
    "    return train_err, test_err\n",
    "\n",
    "\n",
    "def get_running_avg(x, step=3):\n",
    "    cumsum = np.cumsum(x) \n",
    "    return (cumsum[step:] - cumsum[:-step]) / float(step)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239115ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_individual_run(lr1, lr2, wd=None, lrdecay=None, norandomflip=True, norandomcrop=True, momentum=True, inv_sq_lr=False, track_weights=False, running_avg=False):\n",
    "\n",
    "    run_name = get_run_name(lr1, lr2, wd, lrdecay, norandomflip, norandomcrop, momentum, inv_sq_lr, track_weights)\n",
    "    file_path = os.path.join(RESULTS_DIR, run_name + \"_log.json\")\n",
    "    \n",
    "    data = extract_data(file_path, running_avg)\n",
    "    \n",
    "    cmap = matplotlib.colormaps['viridis']\n",
    "    colorList = [cmap(50 / 1000), cmap(350 / 1000)]\n",
    "\n",
    "    fig, ax = plt.subplots(len(data), 1, sharex=True)\n",
    "    ylabels = [\"Train error\", \"Test error\"]\n",
    "    for k in range(len(data)):\n",
    "        ax[k].set_xscale('log')\n",
    "        data_vec = data[k]\n",
    "        ax[k].plot(np.arange(0, data_vec.shape[0]), data_vec, color=colorList[k], lw=2)\n",
    "        ax[k].set_ylabel(ylabels[k])\n",
    "        \n",
    "    plt.suptitle(fr\"$\\eta_{{\\mathbf{{W}}}} = {lr1}$, $\\eta_{{\\mathbf{{v}}}} = {lr2}$\")\n",
    "    \n",
    "    save_dir = get_save_dir()  \n",
    "        \n",
    "    plt.savefig(os.path.join(save_dir, get_filename_individual(lr1, lr2)))\n",
    "    plt.show() \n",
    "\n",
    "\n",
    "def plot_results(lr, vmax=100, keep_nan=True, plot_nans=False):\n",
    "    \n",
    "    files = get_all_files(lr)\n",
    "\n",
    "    f_ext = \"_log.json\"\n",
    "    lrs = [f.split('_')[1] for f in files]\n",
    "    \n",
    "    print(fr'Loading {len(lrs)} files')\n",
    "    \n",
    "    #assert len(lrs) == 99, \"Something wrong with the amount of files\"\n",
    "    lrs_float = [float(l) for l in lrs]\n",
    "    lrs_float, lrs = zip(*sorted(zip(lrs_float, lrs)))\n",
    "    \n",
    "    num_its = 1000\n",
    "    train_err, test_err = np.zeros((len(lrs), num_its)), np.zeros((len(lrs), num_its))\n",
    "    for i, l in enumerate(lrs):\n",
    "        data = extract_data(os.path.join(RESULTS_DIR, f\"lr={lr}_{l}{f_ext}\"), running_avg=False)\n",
    "        train_err[i] = data[0]\n",
    "        test_err[i] = data[1]\n",
    "    if (~np.isfinite(risks)).any() and np.nonzero(~(~np.isfinite(risks)).any(axis=-1))[0].any():\n",
    "        print(r\"Lr2 with nan/inf, then some lower lr2\")\n",
    "        idx=np.nonzero(~(~np.isfinite(risks)).any(axis=-1))[0][-1] + 1\n",
    "        for j in range(10):\n",
    "            if plot_nans:\n",
    "                plot_individual_run(lr, lrs[idx-j])\n",
    "            else:\n",
    "                print(lrs[idx-j])\n",
    "    else:\n",
    "        print('No nans/inf values')\n",
    "    ratios = np.array(lrs_float)/lr\n",
    "            \n",
    "    fig, ax = plt.subplots(2, 1, sharex=True)\n",
    "    \n",
    "    # Plot\n",
    "    im1 = ax[0].imshow(train_err.transpose()[::-1, :], interpolation='none', aspect='auto', vmax=vmax, vmin=0)\n",
    "    im2 = ax[1].imshow(test_err.transpose()[::-1, :], interpolation='none', aspect='auto', vmax=vmax, vmin=0)\n",
    "    fig.colorbar(im1, ax=ax[0])\n",
    "    fig.colorbar(im2, ax=ax[1])\n",
    "    \n",
    "    # Title\n",
    "    plt.suptitle(fr\"$\\eta_{{\\mathbf{{W}}}}={lr}$\")\n",
    "    \n",
    "    # Save file\n",
    "    save_dir = get_save_dir() \n",
    "        \n",
    "    figname = get_filename(lr, vmax)\n",
    "    plt.savefig(os.path.join(\"plots\", figname), bbox_inches='tight')\n",
    "    \n",
    "    plt.show()\n",
    "    return\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f2b78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for plotting a selection of curves\n",
    "\n",
    "\n",
    "def prune_files(files, wd=None, lrdecay=None, norandomflip=True, norandomcrop=True, momentum=True, \n",
    "                inv_sq_lr=False, track_weights=False):\n",
    "    \n",
    "    # TODO: clean this up\n",
    "    if not norandomflip:\n",
    "        files = [file for file in files if \"r_flip\" in file]\n",
    "        \n",
    "    if not norandomcrop:\n",
    "        files = [file for file in files if \"r_crop\" in file]\n",
    "\n",
    "    if wd is not None:\n",
    "        files = [file for file in files if f\"_wd={wd}\" in file]\n",
    "    \n",
    "    if lrdecay is not None:\n",
    "        files = [file for file in files if f\"_ld={lrdecay}\" in file]\n",
    "        \n",
    "    if track_weights:\n",
    "        files = [file for file in files if \"tw\" in file]\n",
    "\n",
    "    if not momentum:\n",
    "        files = [file for file in files if \"no_momentum\" in file]\n",
    "        \n",
    "    if inv_sq_lr:\n",
    "        files = [file for file in files if \"inv_sq_lr\" in file]\n",
    "    \n",
    "    return files\n",
    "\n",
    "def plot_individual_runs_range(lr1, lr_ratio_low, lr_ratio_high, wd=None, lrdecay=None, norandomflip=True, norandomcrop=True, \n",
    "                               momentum=True, inv_sq_lr=False, track_weights=False, running_avg=False):\n",
    "    \"\"\"Plot individual runs within range lr_ratio_low to lr_ratio_high\"\"\"\n",
    "    \n",
    "    files = get_all_files(lr1)\n",
    "    files = prune_files(files, wd, lrdecay, norandomflip, norandomcrop, momentum, inv_sq_lr, track_weights)\n",
    "            \n",
    "    f_ext = \"_log.json\"\n",
    "    lrs = [f.split('_')[1] for f in files]\n",
    "\n",
    "    # Keep runs only within range\n",
    "    lr2_low, lr2_high = lr_ratio_low * lr1, lr_ratio_high * lr1\n",
    "    files = [f for f, lr in zip(files, lrs) if float(lr) >= lr2_low and float(lr) <= lr2_high]\n",
    "    lrs = [float(lr) for lr in lrs if float(lr) >= lr2_low and float(lr) <= lr2_high]\n",
    "    lrs.sort()\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots(2, 1, sharex=True)\n",
    "    ylabels = [\"Train error\", \"Test error\"]\n",
    "    epochs = []\n",
    "    for i, lr in enumerate(lrs):\n",
    "        data = extract_data(os.path.join(RESULTS_DIR, files[i]), running_avg)       \n",
    "\n",
    "        for k in range(2):\n",
    "            if i == 0:\n",
    "                ax[k].set_xscale('log')\n",
    "                ax[k].set_ylim([0, 100])\n",
    "                ax[k].set_ylabel(ylabels[k])\n",
    "            \n",
    "            data_vec = data[k] \n",
    "            ax[k].plot(np.arange(0, data_vec.shape[0]), data_vec, lw=2)\n",
    "            \n",
    "            \n",
    "    ax[0].legend([fr\"$\\eta_{{\\mathbf{{v}}}} = {lr2}$\" for lr2 in lrs])\n",
    "    fig.suptitle(fr\"$\\eta_{{\\mathbf{{w}}}} = {lr1}$\")\n",
    "\n",
    "    save_dir = get_save_dir()\n",
    "\n",
    "    plt.savefig(os.path.join(save_dir, get_filename_range(lr1, lr2_low, lr2_high)))\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d96fc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_gradients(file_path):\n",
    "    \n",
    "    f = open(file_path)\n",
    "    data = json.load(f)\n",
    "\n",
    "    grad_dep_unperm, grad_ind_unperm, grad_dep_perm, grad_ind_perm = [], [], [], []\n",
    "\n",
    "    for i, d in enumerate(data):\n",
    "        \n",
    "        assert \"grads\" in d, \"Gradients not recorded\"\n",
    "        \n",
    "        grad_dep_unperm.append(np.array([d[\"grads\"][\"grad_dep\"][\"unperm\"][key] for key in d[\"grads\"][\"grad_dep\"][\"unperm\"]]))\n",
    "        grad_ind_unperm.append(np.array([d[\"grads\"][\"grad_ind\"][\"unperm\"][key] for key in d[\"grads\"][\"grad_ind\"][\"unperm\"]]))\n",
    "        grad_dep_perm.append(np.array([d[\"grads\"][\"grad_dep\"][\"perm\"][key] for key in d[\"grads\"][\"grad_dep\"][\"perm\"]]))\n",
    "        grad_ind_perm.append(np.array([d[\"grads\"][\"grad_ind\"][\"perm\"][key] for key in d[\"grads\"][\"grad_ind\"][\"perm\"]]))\n",
    "       \n",
    "    grad_dep_unperm, grad_ind_unperm =  np.row_stack(grad_dep_unperm), np.row_stack(grad_ind_unperm)\n",
    "    grad_dep_perm, grad_ind_perm =  np.row_stack(grad_dep_perm), np.row_stack(grad_ind_perm)\n",
    "        \n",
    "    return grad_dep_unperm, grad_ind_unperm, grad_dep_perm, grad_ind_perm\n",
    "\n",
    "\n",
    "def plot_gradients_individual_layers(lr1, lr2, wd=None, layers=None, plot_ratios=True, plot_mean=True):\n",
    "    \n",
    "    run_name = get_run_name(lr1, lr2, wd)\n",
    "    file_path = os.path.join(RESULTS_DIR, run_name + \"_log.json\")\n",
    "    \n",
    "    grad_dep_unperm, grad_ind_unperm, grad_dep_perm, grad_ind_perm = extract_gradients(file_path)\n",
    "    \n",
    "    if layers is None:\n",
    "        layers = [i for i in range(1, grad_dep_unperm.shape[-1] + 1)]\n",
    "    \n",
    "    \n",
    "    if plot_ratios:\n",
    "        data = [grad_dep_unperm / grad_ind_unperm, grad_dep_perm / grad_ind_perm, grad_dep_unperm / grad_dep_perm, \n",
    "                grad_ind_unperm / grad_ind_perm]\n",
    "        labels = [\"Unpermuted (dep/ind)\", \"Permuted (dep/ind)\", \"Dependent (unperm/perm)\", \"Independent (unperm/perm)\"]\n",
    "    else:\n",
    "        data = [grad_dep_unperm, grad_ind_unperm, grad_dep_perm, grad_ind_perm]\n",
    "        labels = [\"Dep., Unperm\", \"Ind., Unperm\", \"Dep., Perm\", \"Ind., Perm\"]\n",
    "    \n",
    "    epochs = np.arange(0, grad_dep_unperm.shape[0])\n",
    "    \n",
    "    if plot_mean:\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.set_xscale('log')\n",
    "\n",
    "        for data_vec, lab in zip(data, labels): \n",
    "            mean_vec = np.row_stack([data_vec[:, layer - 1] for layer in layers]).mean(axis=0)\n",
    "            ax.plot(epochs, mean_vec, label=lab)\n",
    "            \n",
    "        ax.legend()\n",
    "        ax.set_xlabel('epochs')\n",
    "        ax.set_ylabel('Layer mean')\n",
    "        #ax.set_ylim([0, 2])\n",
    "        \n",
    "    else:\n",
    "        fig, ax = plt.subplots(len(layers), 1, figsize=(5, int(len(layers) * 3)), sharex=True)\n",
    "            \n",
    "        for i, layer in enumerate(layers):\n",
    "            ax[i].set_xscale('log')\n",
    "            ax[i].set_ylabel(f'Layer {layer}')\n",
    "\n",
    "            for data_vec, lab in zip(data, labels): \n",
    "                ax[i].plot(epochs, data_vec[:, layer - 1], label=lab)\n",
    "        \n",
    "        ax[0].legend()\n",
    "        ax[-1].set_xlabel('epochs')\n",
    "        \n",
    "    fig.suptitle(fr\"Grad norm, $\\eta_{{\\mathbf{{W}}}} = {lr1}$, $\\eta_{{\\mathbf{{v}}}} = {lr2}$\")\n",
    "\n",
    "    save_dir = get_save_dir()\n",
    "    plt.savefig(os.path.join(save_dir, get_filename_individual(lr1, lr2, ext='_grads')))\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def plot_gradients(lr1, lr2, normalised=True):\n",
    "    file_path = os.path.join(RESULTS_DIR, f\"lr={lr1}_{lr2}_log.json\")\n",
    "    \n",
    "    grad_dep_unperm, grad_ind_unperm, grad_dep_perm, grad_ind_perm = extract_gradients(file_path)\n",
    "    \n",
    "    fig, ax = plt.subplots(4, 1, figsize=(5, 12), sharex=True)\n",
    "    \n",
    "    geo_samples = [int(i) for i in np.geomspace(1, 1000 - 1, num=700)]\n",
    "\n",
    "    \n",
    "    im = []\n",
    "    ylabels = ['Dep, unperm', 'Ind, unperm', 'Dep, perm', 'Ind, perm']\n",
    "    for i, data_mat in enumerate([grad_dep_unperm, grad_ind_unperm, grad_dep_perm, grad_ind_perm]):\n",
    "        \n",
    "        if normalised:\n",
    "            data_mat = data_mat / (data_mat.max(axis=0, keepdims=True))\n",
    "            ylabels[i] += ' (Relative)'\n",
    "            \n",
    "        im.append(ax[i].imshow(data_mat[geo_samples, :].transpose(), interpolation='none', aspect='auto'))\n",
    "        ax[i].set_ylabel(ylabels[i])\n",
    "\n",
    "        fig.colorbar(im[i], ax=ax[i])\n",
    "        \n",
    "    # TODO: Set correct x-ticks\n",
    "    ax[-1].set_xticklabels([])\n",
    "        \n",
    "    ax[-1].set_xlabel('epochs (log-scale)')\n",
    "    fig.suptitle(fr\"Grad norm, $\\eta_{{\\mathbf{{W}}}} = {lr1}$, $\\eta_{{\\mathbf{{v}}}} = {lr2}$\")\n",
    "\n",
    "    save_dir = get_save_dir()\n",
    "    \n",
    "    plt.savefig(os.path.join(save_dir, get_filename_individual(lr1, lr2, ext='_grads_img')))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd340bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_weights(file_path):\n",
    "    \n",
    "    f = open(file_path)\n",
    "    data = json.load(f)\n",
    "\n",
    "    weight_norm = []\n",
    "\n",
    "    for i, d in enumerate(data):\n",
    "        \n",
    "        assert \"w_norm\" in d, \"Weight norms not recorded\"\n",
    "        \n",
    "        weight_norm.append(np.array([d[\"w_norm\"][key] for key in d[\"w_norm\"]]))\n",
    "       \n",
    "    weight_norm = np.row_stack(weight_norm)\n",
    "    \n",
    "    return weight_norm\n",
    "\n",
    "def plot_weights(lr1, lr2, relative=False):\n",
    "    file_path = os.path.join(RESULTS_DIR, f\"lr={lr1}_{lr2}_tw_log.json\")\n",
    "    \n",
    "    weight_norm = extract_weights(file_path)\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_xlabel('epoch')\n",
    "    \n",
    "    if relative:\n",
    "        weight_norm = weight_norm / weight_norm[0, :]\n",
    "        ax.set_ylabel(f'weight norm (relative)')\n",
    "    else:\n",
    "        ax.set_ylabel(f'weight norm')\n",
    "\n",
    "    epochs = np.arange(0, weight_norm.shape[0])\n",
    "    for i in range(weight_norm.shape[-1]):\n",
    "\n",
    "        ax.plot(epochs, weight_norm[:, i], label = f'Layer {i+1}')\n",
    "        \n",
    "    ax.legend()\n",
    "    \n",
    "    save_dir = get_save_dir()\n",
    "    plt.savefig(os.path.join(save_dir, get_filename_individual(lr1, lr2, ext='_weights')))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5fa7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_individual_run(0.1, 0.1, wd=None, lrdecay=0.1, norandomflip=False, norandomcrop=False, momentum=False, inv_sq_lr=True, running_avg=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c423ffb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_individual_run(0.1, 0.001, wd=None, lrdecay=0.1, norandomflip=False, norandomcrop=False, momentum=False, inv_sq_lr=True, running_avg=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7a3ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_individual_runs_range(0.1, 0, 1000, wd=None, lrdecay=0.1, norandomflip=False, norandomcrop=False, momentum=False, inv_sq_lr=True, running_avg=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7144ff49",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_weights(0.1, 0.1, relative=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07139dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gradients_individual_layers(0.1, 0.1, layers=[1, 4, 8, 12, 18])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e428cfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gradients_individual_layers(0.1, 0.1, wd=0.0001, layers=[1, 4, 8, 12, 18])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce988a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gradients_individual_layers(0.1, 0.1, layers=[1, 4, 8, 12, 18], plot_ratios=True, plot_mean=True)\n",
    "plot_gradients_individual_layers(0.1, 0.1, wd=0.0001, layers=[1, 4, 8, 12, 18], plot_ratios=True, plot_mean=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a82ae6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
