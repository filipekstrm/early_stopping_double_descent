{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8fbc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62836500",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RESULTS_DIR = os.path.join(\"P:/early_stopping_double_descent\", \"...\") # enter folder direction here (i.e., two_layer_results)\n",
    "RESULTS_DIR = \"five_layer_results\"\n",
    "\n",
    "SMALL_SIZE = 10\n",
    "MEDIUM_SIZE = 12\n",
    "BIGGER_SIZE = 14\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('axes', titlesize=BIGGER_SIZE)    # fontsize of the figure title\n",
    "\n",
    "\n",
    "def get_all_files(lr):\n",
    "    files = os.listdir(RESULTS_DIR)\n",
    "    files = [file for file in files if file.startswith(f'lr={lr}') and file.endswith(\"log.json\")]\n",
    "\n",
    "    return files\n",
    "\n",
    "\n",
    "def get_files():\n",
    "    files = os.listdir(RESULTS_DIR)\n",
    "    files = [file for file in files if file.endswith(\"log.json\")]\n",
    "\n",
    "    \n",
    "def append_id(filename, id):\n",
    "    return \"{0}_{2}.{1}\".format(*filename.rsplit('.', 1) + [id])\n",
    "\n",
    "\n",
    "def get_filename_individual(lr1, lr2, ext=''):\n",
    "    result_path = os.path.split(RESULTS_DIR)[1]\n",
    "    result_path_split = result_path.split('_')\n",
    "    \n",
    "    name = f'lr1={lr1}_lr2={lr2}{ext}.pdf'\n",
    "    \n",
    "    return name\n",
    "\n",
    "\n",
    "def get_filename(lr, vmax):\n",
    "    result_path = os.path.split(RESULTS_DIR)[1]\n",
    "    result_path_split = result_path.split('_')\n",
    "\n",
    "    name = f'{lr}_vmax={vmax}.pdf'\n",
    "    \n",
    "    return name\n",
    "\n",
    "\n",
    "def get_filename_range(lr1, lr2_low, lr2_high):\n",
    "    result_path = os.path.split(RESULTS_DIR)[1]\n",
    "    result_path_split = result_path.split('_')\n",
    "    \n",
    "    name = f'lr1={lr1}_lr2_low={lr2_low}_lr2_high=_{lr2_high}.pdf'\n",
    "        \n",
    "    return name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ef107b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(file_path, running_avg):\n",
    "    f = open(file_path)\n",
    "    data = json.load(f)\n",
    "\n",
    "    train_acc, test_acc = [], []\n",
    "\n",
    "    for i, d in enumerate(data):\n",
    "        train_acc.append(d[\"train\"][\"acc1\"])\n",
    "        test_acc.append(d[\"test\"][\"acc1\"])\n",
    "\n",
    "    train_err, test_err =  100 - np.array(train_acc), 100 - np.array(test_acc)\n",
    "\n",
    "    if running_avg:\n",
    "        train_err, test_err = get_running_avg(train_err), get_running_avg(test_err)\n",
    "        \n",
    "    return train_err, test_err\n",
    "\n",
    "\n",
    "def get_running_avg(x, step=3):\n",
    "    cumsum = np.cumsum(x) \n",
    "    return (cumsum[step:] - cumsum[:-step]) / float(step)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239115ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_individual_run(lr1, lr2, running_avg=False):\n",
    "    file_path = os.path.join(RESULTS_DIR, f\"lr={lr1}_{lr2}_log.json\")\n",
    "    \n",
    "    data = extract_data(file_path, running_avg)\n",
    "    \n",
    "    cmap = matplotlib.colormaps['viridis']\n",
    "    colorList = [cmap(50 / 1000), cmap(350 / 1000)]\n",
    "\n",
    "    fig, ax = plt.subplots(len(data), 1, sharex=True)\n",
    "    ylabels = [\"Train error\", \"Test error\"]\n",
    "    for k in range(len(data)):\n",
    "        ax[k].set_xscale('log')\n",
    "        data_vec = data[k]\n",
    "        ax[k].plot(np.arange(0, data_vec.shape[0]), data_vec, color=colorList[k], lw=4)\n",
    "        ax[k].set_ylabel(ylabels[k])\n",
    "        \n",
    "    plt.suptitle(fr\"$\\eta_{{\\mathbf{{W}}}} = {lr1}$, $\\eta_{{\\mathbf{{v}}}} = {lr2}$\")\n",
    "    \n",
    "    save_dir = \"plots\"\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)  \n",
    "        \n",
    "    plt.savefig(os.path.join(save_dir, get_filename_individual(lr1, lr2)))\n",
    "    plt.show() \n",
    "\n",
    "\n",
    "def plot_results(lr, vmax=100, keep_nan=True, plot_nans=False):\n",
    "    \n",
    "    files = get_all_files(lr)\n",
    "\n",
    "    f_ext = \"_log.json\"\n",
    "    lrs = [f.split('_')[1] for f in files]\n",
    "    \n",
    "    print(fr'Loading {len(lrs)} files')\n",
    "    \n",
    "    #assert len(lrs) == 99, \"Something wrong with the amount of files\"\n",
    "    lrs_float = [float(l) for l in lrs]\n",
    "    lrs_float, lrs = zip(*sorted(zip(lrs_float, lrs)))\n",
    "    \n",
    "    num_its = 1000\n",
    "    train_err, test_err = np.zeros((len(lrs), num_its)), np.zeros((len(lrs), num_its))\n",
    "    for i, l in enumerate(lrs):\n",
    "        data = extract_data(os.path.join(RESULTS_DIR, f\"lr={lr}_{l}{f_ext}\"), running_avg=False)\n",
    "        train_err[i] = data[0]\n",
    "        test_err[i] = data[1]\n",
    "    if (~np.isfinite(risks)).any() and np.nonzero(~(~np.isfinite(risks)).any(axis=-1))[0].any():\n",
    "        print(r\"Lr2 with nan/inf, then some lower lr2\")\n",
    "        idx=np.nonzero(~(~np.isfinite(risks)).any(axis=-1))[0][-1] + 1\n",
    "        for j in range(10):\n",
    "            if plot_nans:\n",
    "                plot_individual_run(lr, lrs[idx-j])\n",
    "            else:\n",
    "                print(lrs[idx-j])\n",
    "    else:\n",
    "        print('No nans/inf values')\n",
    "    ratios = np.array(lrs_float)/lr\n",
    "            \n",
    "    fig, ax = plt.subplots(2, 1, sharex=True)\n",
    "    \n",
    "    # Plot\n",
    "    im1 = ax[0].imshow(train_err.transpose()[::-1, :], interpolation='none', aspect='auto', vmax=vmax, vmin=0)\n",
    "    im2 = ax[1].imshow(test_err.transpose()[::-1, :], interpolation='none', aspect='auto', vmax=vmax, vmin=0)\n",
    "    fig.colorbar(im1, ax=ax[0])\n",
    "    fig.colorbar(im2, ax=ax[1])\n",
    "    \n",
    "    # Title\n",
    "    plt.suptitle(fr\"$\\eta_{{\\mathbf{{W}}}}={lr}$\")\n",
    "    \n",
    "    # Save file\n",
    "    save_dir = \"plots\"\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)  \n",
    "        \n",
    "    figname = get_filename(lr, vmax)\n",
    "    plt.savefig(os.path.join(\"plots\", figname), bbox_inches='tight')\n",
    "    \n",
    "    plt.show()\n",
    "    return\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f2b78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for plotting a selection of curves\n",
    "\n",
    "def plot_individual_runs_range(lr1, lr_ratio_low, lr_ratio_high, running_avg=False):\n",
    "    \"\"\"Plot individual runs within range lr_ratio_low to lr_ratio_high\"\"\"\n",
    "    \n",
    "    files = get_all_files(lr1)\n",
    "        \n",
    "    f_ext = \"_log.json\"\n",
    "    lrs = [f.split('_')[1] for f in files]\n",
    "\n",
    "    # Keep runs only within range\n",
    "    lr2_low, lr2_high = lr_ratio_low * lr1, lr_ratio_high * lr1\n",
    "    files = [f for f, lr in zip(files, lrs) if float(lr) >= lr2_low and float(lr) <= lr2_high]\n",
    "    lrs = [float(lr) for lr in lrs if float(lr) >= lr2_low and float(lr) <= lr2_high]\n",
    "    lrs.sort()\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots(2, 1, sharex=True)\n",
    "    ylabels = [\"Train error\", \"Test error\"]\n",
    "    epochs = []\n",
    "    for i, lr in enumerate(lrs):\n",
    "        data = extract_data(os.path.join(RESULTS_DIR, files[i]), running_avg)       \n",
    "\n",
    "        for k in range(2):\n",
    "            if i == 0:\n",
    "                ax[k].set_xscale('log')\n",
    "                ax[k].set_ylim([0, 100])\n",
    "                ax[k].set_ylabel(ylabels[k])\n",
    "            \n",
    "            data_vec = data[k] \n",
    "            ax[k].plot(np.arange(0, data_vec.shape[0]), data_vec, lw=2)\n",
    "            \n",
    "            \n",
    "    ax[0].legend([fr\"$\\eta_{{\\mathbf{{v}}}} = {lr2}$\" for lr2 in lrs])\n",
    "    fig.suptitle(fr\"$\\eta_{{\\mathbf{{w}}}} = {lr1}$\")\n",
    "\n",
    "    save_dir = \"plots\"\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)  \n",
    "\n",
    "    plt.savefig(os.path.join(save_dir, get_filename_range(lr1, lr2_low, lr2_high)))\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d96fc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_gradients(file_path):\n",
    "    \n",
    "    f = open(file_path)\n",
    "    data = json.load(f)\n",
    "\n",
    "    grad_dep_unperm, grad_ind_unperm, grad_dep_perm, grad_ind_perm = [], [], [], []\n",
    "\n",
    "    for i, d in enumerate(data):\n",
    "        \n",
    "        assert \"grads\" in d, \"Gradients not recorded\"\n",
    "        \n",
    "        grad_dep_unperm.append(np.array([d[\"grads\"][\"grad_dep\"][\"unperm\"][key] for key in d[\"grads\"][\"grad_dep\"][\"unperm\"]]))\n",
    "        grad_ind_unperm.append(np.array([d[\"grads\"][\"grad_ind\"][\"unperm\"][key] for key in d[\"grads\"][\"grad_ind\"][\"unperm\"]]))\n",
    "        grad_dep_perm.append(np.array([d[\"grads\"][\"grad_dep\"][\"perm\"][key] for key in d[\"grads\"][\"grad_dep\"][\"perm\"]]))\n",
    "        grad_ind_perm.append(np.array([d[\"grads\"][\"grad_ind\"][\"perm\"][key] for key in d[\"grads\"][\"grad_ind\"][\"perm\"]]))\n",
    "       \n",
    "    grad_dep_unperm, grad_ind_unperm =  np.row_stack(grad_dep_unperm), np.row_stack(grad_ind_unperm)\n",
    "    grad_dep_perm, grad_ind_perm =  np.row_stack(grad_dep_perm), np.row_stack(grad_ind_perm)\n",
    "        \n",
    "    return grad_dep_unperm, grad_ind_unperm, grad_dep_perm, grad_ind_perm\n",
    "\n",
    "\n",
    "def plot_gradients_individual_layers(lr1, lr2, layers=None):\n",
    "    file_path = os.path.join(RESULTS_DIR, f\"lr={lr1}_{lr2}_log.json\")\n",
    "    \n",
    "    grad_dep_unperm, grad_ind_unperm, grad_dep_perm, grad_ind_perm = extract_gradients(file_path)\n",
    "    \n",
    "    if layers is None:\n",
    "        layers = [i for i in range(1, grad_dep_unperm.shape[-1] + 1)]\n",
    "    \n",
    "    fig, ax = plt.subplots(len(layers), 1, figsize=(5, int(len(layers) * 3)), sharex=True)\n",
    "    \n",
    "    epochs = np.arange(0, grad_dep_unperm.shape[0])\n",
    "    for i, layer in enumerate(layers):\n",
    "        ax[i].set_xscale('log')\n",
    "        ax[i].set_ylabel(f'Layer {layer}')\n",
    "        ax[i].plot(epochs, grad_dep_unperm[:, layer - 1] / grad_ind_unperm[:, layer - 1], label=\"Unpermuted (dep/ind)\")\n",
    "        ax[i].plot(epochs, grad_dep_perm[:, layer - 1] / grad_ind_perm[:, layer - 1], label=\"Permuted (dep/ind)\")\n",
    "        ax[i].plot(epochs, grad_dep_unperm[:, layer - 1] / grad_dep_perm[:, layer - 1], label=\"Dependent (unperm/perm)\")\n",
    "        ax[i].plot(epochs, grad_ind_unperm[:, layer - 1] / grad_ind_perm[:, layer - 1], label=\"Independent (unperm/perm)\")\n",
    "    \n",
    "        \n",
    "    ax[0].legend()\n",
    "    ax[-1].set_xlabel('epochs')\n",
    "    fig.suptitle(fr\"Grad norm, $\\eta_{{\\mathbf{{W}}}} = {lr1}$, $\\eta_{{\\mathbf{{v}}}} = {lr2}$\")\n",
    "\n",
    "    save_dir = \"plots\"\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)  \n",
    "\n",
    "    plt.savefig(os.path.join(save_dir, get_filename_individual(lr1, lr2, ext='_grads')))\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def plot_gradients(lr1, lr2, normalised=True):\n",
    "    file_path = os.path.join(RESULTS_DIR, f\"lr={lr1}_{lr2}_log.json\")\n",
    "    \n",
    "    grad_dep_unperm, grad_ind_unperm, grad_dep_perm, grad_ind_perm = extract_gradients(file_path)\n",
    "    \n",
    "    fig, ax = plt.subplots(4, 1, figsize=(5, 12), sharex=True)\n",
    "    \n",
    "    geo_samples = [int(i) for i in np.geomspace(1, 1000 - 1, num=700)]\n",
    "\n",
    "    \n",
    "    im = []\n",
    "    ylabels = ['Dep, unperm', 'Ind, unperm', 'Dep, perm', 'Ind, perm']\n",
    "    for i, data_mat in enumerate([grad_dep_unperm, grad_ind_unperm, grad_dep_perm, grad_ind_perm]):\n",
    "        \n",
    "        if normalised:\n",
    "            data_mat = data_mat / (data_mat.max(axis=0, keepdims=True))\n",
    "            ylabels[i] += ' (Relative)'\n",
    "            \n",
    "        im.append(ax[i].imshow(data_mat[geo_samples, :].transpose(), interpolation='none', aspect='auto'))\n",
    "        ax[i].set_ylabel(ylabels[i])\n",
    "        fig.colorbar(im[i], ax=ax[i])\n",
    "        \n",
    "    # TODO: Set correct x-ticks\n",
    "    ax[-1].set_xticklabels([])\n",
    "        \n",
    "    ax[-1].set_xlabel('epochs (log-scale)')\n",
    "    fig.suptitle(fr\"Grad norm, $\\eta_{{\\mathbf{{W}}}} = {lr1}$, $\\eta_{{\\mathbf{{v}}}} = {lr2}$\")\n",
    "\n",
    "    save_dir = \"plots\"\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)  \n",
    "\n",
    "    plt.savefig(os.path.join(save_dir, get_filename_individual(lr1, lr2, ext='_grads_img')))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020820d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gradients(0.1, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5fa7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_individual_run(0.1, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c423ffb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_individual_run(0.1, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394ba303",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_individual_run(0.1, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae7f041",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_individual_run(0.01, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4259cf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_individual_runs_range(0.1, 0.01, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7a3ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gradients_individual_layers(0.1, 0.1, layers=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7144ff49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
