{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8fbc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append('code/')\n",
    "from linear_utils import is_float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62836500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESULTS_DIR = os.path.join(\"P:/early_stopping_double_descent\", \"...\") # enter folder direction here (i.e., two_layer_results)\n",
    "RESULTS_DIR = \"results/two_layer_results_l2/transform_data/theoretical\" #five_layer_regression_results\"\n",
    "\n",
    "SMALL_SIZE = 10\n",
    "MEDIUM_SIZE = 12\n",
    "BIGGER_SIZE = 14\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('axes', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "\n",
    "\n",
    "def get_all_files(lr, batch_norm, uniform_noise, coupled_noise=None, ext='', is_lr2=False, w=None, u=None):\n",
    "    files = os.listdir(RESULTS_DIR)\n",
    "        \n",
    "    files = [file for file in files if \".csv\" in file]\n",
    "    if is_lr2:\n",
    "        # Given lr is for second layer\n",
    "        files = [file for file in files if file.split('_')[1] == f'{lr}']\n",
    "    else:\n",
    "        files = [file for file in files if file.split('_')[0] == f'lr={lr}']\n",
    "\n",
    "    if batch_norm:\n",
    "        files = [file for file in files if \"batch_norm\" in file]\n",
    "    elif uniform_noise:\n",
    "        files = [file for file in files if \"uniform_noise\" in file]    \n",
    "    else:\n",
    "        files = [file for file in files if \"batch_norm\" and \"uniform_noise\" not in file]\n",
    "\n",
    "    # Sorry, I will clean this up eventually\n",
    "    if coupled_noise is not None:\n",
    "        files = [file for file in files if f\"coupled_noise_{coupled_noise}\" in file]  \n",
    "        \n",
    "    files = [file for file in files if ext in file]\n",
    "\n",
    "    if \"samples\" not in ext:\n",
    "        files = [file for file in files if \"samples\" not in file]\n",
    "\n",
    "    if \"dim\" not in ext:\n",
    "        files = [file for file in files if \"dim\" not in file]\n",
    "    \n",
    "    if u is None and \"fixed_u\" not in ext:\n",
    "        files = [file for file in files if \"fixed_u\" not in file]\n",
    "    elif u is not None:\n",
    "        files = [file for file in files if f\"fixed_u_{u}\" in file]\n",
    "    \n",
    "    if w is None and \"w\" not in ext:\n",
    "        files = [file for file in files if \"w\" not in file]\n",
    "    elif w is not None:\n",
    "        files = [file for file in files if f\"w_{w}_{w}\" in file]\n",
    "    \n",
    "    \n",
    "    return files\n",
    "\n",
    "def get_files(batch_norm, uniform_noise, coupled_noise=None, ext=''):\n",
    "    files = os.listdir(RESULTS_DIR)\n",
    "    files = [file for file in files if file.endswith(\".csv\")]\n",
    "    if batch_norm:\n",
    "        files = [file for file in files if \"batch_norm\" in file]\n",
    "    #else:\n",
    "        #files = [file for file in files if \"batch_norm\" not in file]\n",
    "    elif uniform_noise:\n",
    "        files = [file for file in files if \"uniform_noise\" in file]\n",
    "    else:\n",
    "        files = [file for file in files if \"batch_norm\" and \"uniform_noise\" not in file]\n",
    "        \n",
    "    if coupled_noise is not None:\n",
    "        files = [file for file in files if f\"coupled_noise_{coupled_noise}\" in file]  \n",
    "        \n",
    "    files = [file for file in files if ext in file]\n",
    "    \n",
    "    return files\n",
    "\n",
    "def append_id(filename, id):\n",
    "    return \"{0}_{2}.{1}\".format(*filename.rsplit('.', 1) + [id])\n",
    "\n",
    "def get_filename_individual(lr1, lr2, batch_norm):\n",
    "    result_path = os.path.split(RESULTS_DIR)[1]\n",
    "    result_path_split = result_path.split('_')\n",
    "    linear = result_path_split[-1] == \"linear\"\n",
    "    if linear:\n",
    "        w = '_'.join(result_path_split[-3:-1])\n",
    "    else:\n",
    "        w = '_'.join(result_path_split[-2:])\n",
    "    \n",
    "    name = f'lr1={lr1}_lr2={lr2}_w={w}.pdf'\n",
    "    \n",
    "    if batch_norm:\n",
    "        name = append_id(name, \"batch_norm\")\n",
    "    if linear:\n",
    "        name = append_id(name, \"linear\")\n",
    "    return name\n",
    "\n",
    "def get_filename_range(lr1, lr2_low, lr2_high, batch_norm, uniform_noise=False):\n",
    "    result_path = os.path.split(RESULTS_DIR)[1]\n",
    "    result_path_split = result_path.split('_')\n",
    "    linear = result_path_split[-1] == \"linear\"\n",
    "    if linear:\n",
    "        w = '_'.join(result_path_split[-3:-1])\n",
    "    else:\n",
    "        w = '_'.join(result_path_split[-2:])\n",
    "    \n",
    "    name = f'lr1={lr1}_lr2_low={lr2_low}_lr2_high=_{lr2_high}_w={w}.pdf'\n",
    "    \n",
    "    if batch_norm:\n",
    "        name = append_id(name, \"batch_norm\")\n",
    "    elif uniform_noise:\n",
    "        name = append_id(name, \"uniform_noise\")\n",
    "\n",
    "    if linear:\n",
    "        name = append_id(name, \"linear\")\n",
    "        \n",
    "    return name\n",
    "\n",
    "def get_filename_range_pcs(lr1, lr2, pc_low, pc_high, batch_norm, uniform_noise=False):\n",
    "    result_path = os.path.split(RESULTS_DIR)[1]\n",
    "    result_path_split = result_path.split('_')\n",
    "    linear = result_path_split[-1] == \"linear\"\n",
    "    if linear:\n",
    "        w = '_'.join(result_path_split[-3:-1])\n",
    "    else:\n",
    "        w = '_'.join(result_path_split[-2:])\n",
    "    \n",
    "    name = f'lr1={lr1}_lr2={lr2}_pc_low={pc_low}_pc_high=_{pc_high}.pdf'\n",
    "    \n",
    "    if batch_norm:\n",
    "        name = append_id(name, \"batch_norm\")\n",
    "    elif uniform_noise:\n",
    "        name = append_id(name, \"uniform_noise\")\n",
    "\n",
    "    if linear:\n",
    "        name = append_id(name, \"linear\")\n",
    "        \n",
    "    return name\n",
    "\n",
    "def get_filename_range_misc(lr1, lr2, low, high, batch_norm, uniform_noise=False, descr=''):\n",
    "    result_path = os.path.split(RESULTS_DIR)[1]\n",
    "    result_path_split = result_path.split('_')\n",
    "    linear = result_path_split[-1] == \"linear\"\n",
    "    if linear:\n",
    "        w = '_'.join(result_path_split[-3:-1])\n",
    "    else:\n",
    "        w = '_'.join(result_path_split[-2:])\n",
    "    \n",
    "    name = f'lr1={lr1}_lr2={lr2}_{descr}_low={low}_{descr}_high=_{high}.pdf'\n",
    "    \n",
    "    if batch_norm:\n",
    "        name = append_id(name, \"batch_norm\")\n",
    "    elif uniform_noise:\n",
    "        name = append_id(name, \"uniform_noise\")\n",
    "\n",
    "    if linear:\n",
    "        name = append_id(name, \"linear\")\n",
    "        \n",
    "    return name\n",
    "\n",
    "\n",
    "def plot_individual_run(lr1, lr2, batch_norm, uniform_noise=False, coupled_noise=None, ext='', plot_extra=False, extra_labels=None):\n",
    "    \n",
    "    file_path = os.path.join(RESULTS_DIR, f\"lr={lr1}_{lr2}.csv\")\n",
    "    if batch_norm:\n",
    "        file_path = append_id(file_path, \"batch_norm\") \n",
    "    elif uniform_noise:\n",
    "        file_path = append_id(file_path, \"uniform_noise\") \n",
    "        \n",
    "    if coupled_noise is not None:\n",
    "        file_path = append_id(file_path, f\"coupled_noise_{coupled_noise}\") \n",
    "        \n",
    "    file_path = append_id(file_path, ext)\n",
    "    \n",
    "    data = pd.read_csv(file_path, header=None)\n",
    "    \n",
    "    #data = data.to_numpy()\n",
    "     \n",
    "    #data_list = [data[:, 0], data[:, 1], data[:, 2:].sum(axis=-1)]\n",
    "    #extra_labels = [\"Weight MSE\"]\n",
    "\n",
    "    #splits = np.arange(10, 100, 5)\n",
    "    #for split in splits:\n",
    "    #    data_list += [data[:, 2:(split+2)].sum(axis=-1), data[:, (split+2):].sum(axis=-1)]\n",
    "    #    extra_labels += [f\"Weight MSE, split {split}, upper\", f\"Weight MSE, split {split}, lower\"]\n",
    "        \n",
    "    #data = pd.DataFrame(np.column_stack(data_list))\n",
    "    \n",
    "    geo_samples = [int(i) for i in np.geomspace(1, len(data) - 1, num=700)]\n",
    "    cmap = matplotlib.colormaps['viridis']\n",
    "    colorList = [cmap(50 / 1000), cmap(350 / 1000)]\n",
    "    labelList = ['Test', 'Train']\n",
    "    \n",
    "    if plot_extra:\n",
    "        assert data.shape[-1] > 2, \"No extra data saved\"\n",
    "        num_vec = data.shape[-1]\n",
    "        colorList += [cmap((450 + 100 * t) / 1000) for t in range(num_vec - 2)]\n",
    "        labelList = labelList + extra_labels if extra_labels is not None else labelList + [i for i in range(num_vec - 2)]\n",
    "    else:\n",
    "        num_vec = 2\n",
    "\n",
    "    #fig = plt.figure()\n",
    "    fig, ax = plt.subplots(num_vec+1, 1, figsize=(5, num_vec * 3), sharex=True)\n",
    "    for k in range(num_vec):\n",
    "        ax[k].set_xscale('log')\n",
    "            \n",
    "        data_vec = data[k]\n",
    "        print(data_vec[0])\n",
    "        print(data_vec.min())\n",
    "        ax[k].plot(geo_samples, data_vec[geo_samples],\n",
    "            color=colorList[k],\n",
    "            label=labelList[k],\n",
    "            lw=4)\n",
    "        ax[k].set_ylabel(labelList[k])\n",
    "      \n",
    "    if plot_extra:\n",
    "        data_vec = data.iloc[:,2:].sum(axis=1)\n",
    "        ax[-1].plot(geo_samples, data_vec[geo_samples],\n",
    "                color=colorList[k],\n",
    "                label=labelList[k],\n",
    "                lw=4)\n",
    "        ax[-1].set_ylabel('Sum')\n",
    "    #ax[0].set_ylim([9, 20])\n",
    "                \n",
    "    plt.suptitle(fr\"$\\eta_{{\\mathbf{{W}}}} = {lr1}$, $\\eta_{{\\mathbf{{v}}}} = {lr2}$\")\n",
    "    \n",
    "    save_dir = \"plots\"\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)  \n",
    "        \n",
    "    plt.savefig(os.path.join(save_dir, get_filename_individual(lr1, lr2, batch_norm)))\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def get_filename(lr, vmax, batch_norm):\n",
    "    result_path = os.path.split(RESULTS_DIR)[1]\n",
    "    result_path_split = result_path.split('_')\n",
    "    linear = result_path_split[-1] == \"linear\"\n",
    "    if linear:\n",
    "        w = '_'.join(result_path_split[-3:-1])\n",
    "    else:\n",
    "        w = '_'.join(result_path_split[-2:])\n",
    "    \n",
    "    name = f'{lr}_vmax={vmax}_w={w}.pdf'\n",
    "    if batch_norm:\n",
    "        name = append_id(name, \"batch_norm\")\n",
    "    if linear:\n",
    "        name = append_id(name, \"linear\")\n",
    "        \n",
    "    return name\n",
    "\n",
    "def plot_results(lr, vmax=20, vmin=0, keep_nan=True, batch_norm=False, uniform_noise=False, coupled_noise=None, ext='', \n",
    "                 plot_nans=False, num_its=50000, fixed_lr2=False):\n",
    "    \n",
    "    files = get_all_files(lr, batch_norm, uniform_noise, coupled_noise, ext, fixed_lr2)\n",
    "\n",
    "    if not isinstance(vmax, list):\n",
    "        vmax = [vmax] * 2\n",
    "    if not isinstance(vmin, list):\n",
    "        vmin = [vmin] * 2\n",
    "    \n",
    "    if batch_norm:\n",
    "        f_ext = \"_batch_norm\"\n",
    "    elif uniform_noise:\n",
    "        f_ext = \"_uniform_noise\"\n",
    "    else:\n",
    "        f_ext = \"\"\n",
    "        \n",
    "    #if batch_norm or uniform_noise:\n",
    "    lrs = [(f.split('_')[0]).split('=')[1] for f in files] if fixed_lr2 else [f.split('_')[1] for f in files]\n",
    "    #else:\n",
    "    #    lrs = [f.split('_')[-1][:-4] for f in files]\n",
    "    \n",
    "    r_lrs = [\"1.0\", \"0.0001\", \"0.02\", \"0.1\"]\n",
    "    lrs = [l for l in lrs if l not in r_lrs]\n",
    "    \n",
    "    lrs = list(set(lrs))\n",
    "    \n",
    "    lrs = [lr for lr in lrs if float(lr) >= 1e-8]\n",
    "    \n",
    "    if coupled_noise:\n",
    "        f_ext += f\"_coupled_noise_{coupled_noise}\"\n",
    "                \n",
    "    f_ext += ext + \".csv\"\n",
    "    \n",
    "    #assert len(lrs) == 99, \"Something wrong with the amount of files\"\n",
    "    lrs_float = [float(l) for l in lrs]\n",
    "    lrs_float, lrs = zip(*sorted(zip(lrs_float, lrs)))\n",
    "    \n",
    "    \n",
    "    risks = np.zeros((len(lrs), num_its))\n",
    "    losses = np.zeros((len(lrs), num_its))\n",
    "    for i, l in enumerate(lrs):\n",
    "\n",
    "        if fixed_lr2:\n",
    "            data = pd.read_csv(os.path.join(RESULTS_DIR, f\"lr={l}_{lr}{f_ext}\"), header=None)\n",
    "        else:\n",
    "            data = pd.read_csv(os.path.join(RESULTS_DIR, f\"lr={lr}_{l}{f_ext}\"), header=None)\n",
    "        \n",
    "        risks[i] = data[0]\n",
    "        losses[i] = data[1]\n",
    "    if (~np.isfinite(risks)).any() and np.nonzero(~(~np.isfinite(risks)).any(axis=-1))[0].any():\n",
    "        print(r\"Lr2 with nan/inf, then some lower lr2\")\n",
    "        idx=np.nonzero(~(~np.isfinite(risks)).any(axis=-1))[0][-1] + 1\n",
    "        for j in range(10):\n",
    "            if plot_nans:\n",
    "                plot_individual_run(lr, lrs[idx-j], batch_norm)\n",
    "            else:\n",
    "                print(lrs[idx-j])\n",
    "    else:\n",
    "        print('No nans/inf values')\n",
    "    ratios = np.array(lrs_float)/lr\n",
    "            \n",
    "    # Subsample epochs\n",
    "    geo_samples = [int(i) for i in np.geomspace(1, num_its - 1, num=700)]\n",
    "    fig, ax = plt.subplots(2,1, sharex=True)\n",
    "    \n",
    "\n",
    "    # Plot\n",
    "    im1 = ax[0].imshow(risks[:, geo_samples].transpose()[::-1, :], interpolation='none', aspect='auto', vmax=vmax[0], vmin=vmin[0])\n",
    "    im2 = ax[1].imshow(losses[:, geo_samples].transpose()[::-1, :], interpolation='none', aspect='auto', vmax=vmax[1], vmin=vmin[1])\n",
    "    fig.colorbar(im1, ax=ax[0])\n",
    "    fig.colorbar(im2, ax=ax[1])\n",
    "    \n",
    "    # Title\n",
    "    title = fr\"$\\eta_{{\\mathbf{{v}}}}={lr}$\" if fixed_lr2 else fr\"$\\eta_{{\\mathbf{{W}}}}={lr}$\"\n",
    "    \n",
    "    if batch_norm:\n",
    "        title += \", with batch normalization\"\n",
    "    plt.suptitle(title)\n",
    "    \n",
    "    # Set correct x- and y-ticks\n",
    "    # X axis\n",
    "    min_pow = -5\n",
    "    max_pow = 6\n",
    "    ten_powers = 10.0 ** np.arange(min_pow, max_pow)\n",
    "    indices = []\n",
    "    for val in ten_powers:\n",
    "        indices += [np.argmin(np.abs(ratios-val))]\n",
    "    \n",
    "    for k in [1]:\n",
    "        ax[k].set_xticks(indices)\n",
    "        ax[k].set_xticklabels([f\"$10^{{{i}}}$\" for i in np.arange(min_pow,max_pow)])\n",
    "        ax[k].set_xlabel(r\"$\\eta_{\\mathbf{W}} / \\eta_{\\mathbf{v}}$\" if fixed_lr2 else r\"$\\eta_{\\mathbf{v}} / \\eta_{\\mathbf{W}}$\")\n",
    "    \n",
    "    # Y axis\n",
    "    ten_powers = 10.0 ** np.arange(4, 0, -1)\n",
    "    indices = []\n",
    "    for val in ten_powers:\n",
    "        indices += [np.argmin(np.abs(geo_samples-val))]\n",
    "    for k in range(2):\n",
    "        ax[k].set_yticks(indices)\n",
    "        ax[k].set_yticklabels([f\"$10^{{{i}}}$\" for i in np.arange(1, 5)])\n",
    "        ax[k].set_ylabel(r\"Iteration $t$\")\n",
    "    \n",
    "    # Save file\n",
    "    save_dir = \"plots\"\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)  \n",
    "        \n",
    "    \n",
    "    figname = get_filename(lr, vmax[0], batch_norm)\n",
    "    plt.savefig(os.path.join(\"plots\", figname), bbox_inches='tight')\n",
    "    \n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "def plot_same_lr(vmax=20, vmin=0, batch_norm=False, uniform_noise=False, coupled_noise=None, ext='', plot_nans=False, num_its=50000):\n",
    "    \n",
    "    files = get_files(batch_norm, uniform_noise, coupled_noise, ext)\n",
    "    files = [f for f in files if f.split('_')[0][3:] == f.split('_')[1]]\n",
    "\n",
    "    if not isinstance(vmax, list):\n",
    "        vmax = [vmax] * 2\n",
    "    if not isinstance(vmin, list):\n",
    "        vmin = [vmin] * 2\n",
    "    \n",
    "    if batch_norm:\n",
    "        f_ext = \"_batch_norm\"\n",
    "        lrs = [f.split('_')[1] for f in files]\n",
    "    elif uniform_noise:\n",
    "        f_ext = \"_uniform_noise\"\n",
    "        lrs = [f.split('_')[1] for f in files]        \n",
    "    else:\n",
    "        f_ext = \"\"\n",
    "        lrs = [f.split('_')[-1][:-4] for f in files]\n",
    "        \n",
    "    if coupled_noise:\n",
    "        f_ext += f\"_coupled_noise_{coupled_noise}\"\n",
    "                \n",
    "    f_ext += ext + \".csv\"\n",
    "        \n",
    "    #assert len(lrs) == 91 or len(lrs) == 99, \"Not right amount of files\"\n",
    "    lrs_float = [float(l) for l in lrs]\n",
    "    lrs_float, lrs = zip(*sorted(zip(lrs_float, lrs)))\n",
    "    risks = np.zeros((len(lrs), num_its))\n",
    "    losses = np.zeros((len(lrs), num_its))\n",
    "    for i, lr in enumerate(lrs):\n",
    "        data = pd.read_csv(os.path.join(RESULTS_DIR, f\"lr={lr}_{lr}{f_ext}\"), header=None)\n",
    "        risks[i] = data[0]\n",
    "        losses[i] = data[1]\n",
    "    # Subsample epochs\n",
    "    geo_samples = [int(i) for i in np.geomspace(1, num_its - 1, num=700)]\n",
    "    fig, ax = plt.subplots(2,1, sharex=True)\n",
    "    # Plot\n",
    "    im1 = ax[0].imshow(risks[:, geo_samples].transpose()[::-1, :], interpolation='none', aspect='auto', vmax=vmax[0], vmin=vmin[0])\n",
    "    fig.colorbar(im1, ax=ax[0])\n",
    "    im2 = ax[1].imshow(losses[:, geo_samples].transpose()[::-1, :], interpolation='none', aspect='auto', vmax=vmax[1], vmin=vmin[1])\n",
    "    fig.colorbar(im2, ax=ax[1])\n",
    "    \n",
    "    # Title\n",
    "    title = fr\"Same lr for both layers\"\n",
    "    if batch_norm:\n",
    "        title += \", with batch normalization\"\n",
    "    plt.suptitle(title)\n",
    "    \n",
    "    # Set correct x- and y-ticks\n",
    "    # X axis\n",
    "    ten_powers = 10.0 ** np.arange(-7, -1)\n",
    "    indices = []\n",
    "    for val in ten_powers:\n",
    "        indices += [np.argmin(np.abs(lrs_float-val))]\n",
    "    \n",
    "    ax[1].set_xticks(indices)\n",
    "    ax[1].set_xticklabels([f\"$10^{{{i}}}$\" for i in np.arange(-7, -1)])\n",
    "    ax[1].set_xlabel(\"lr\")\n",
    "    \n",
    "    # Y axis\n",
    "    ten_powers = 10.0 ** np.arange(4, 0, -1)\n",
    "    indices = []\n",
    "    for val in ten_powers:\n",
    "        indices += [np.argmin(np.abs(geo_samples-val))]\n",
    "    for k in range(2):\n",
    "        ax[k].set_yticks(indices)\n",
    "        ax[k].set_yticklabels([f\"$10^{{{i}}}$\" for i in np.arange(1, 5)])\n",
    "        ax[k].set_ylabel(r\"Iteration $t$\")\n",
    "    \n",
    "    figname = get_filename(lr, vmax, batch_norm)\n",
    "    plt.savefig(os.path.join(\"plots\", figname), bbox_inches='tight')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def plot_same_lr_range(lr_low, lr_high, ymin=[0, 0], ymax=[100, 100], batch_norm=False, uniform_noise=False, coupled_noise=None, ext='', plot_nans=False, num_its=50000):\n",
    "    \n",
    "    files = get_files(batch_norm, uniform_noise, coupled_noise, ext)\n",
    "    files = [f for f in files if f.split('_')[0][3:] == f.split('_')[1]]\n",
    "\n",
    "    if not isinstance(ymax, list):\n",
    "        ymax = [ymax] * 2\n",
    "    if not isinstance(ymin, list):\n",
    "        ymin = [ymin] * 2\n",
    "    \n",
    "    if batch_norm:\n",
    "        f_ext = \"_batch_norm\"\n",
    "        lrs = [f.split('_')[1] for f in files]\n",
    "    elif uniform_noise:\n",
    "        f_ext = \"_uniform_noise\"\n",
    "        lrs = [f.split('_')[1] for f in files]        \n",
    "    else:\n",
    "        f_ext = \"\"\n",
    "        lrs = [f.split('_')[-1][:-4] for f in files]\n",
    "        \n",
    "    if coupled_noise:\n",
    "        f_ext += f\"_coupled_noise_{coupled_noise}\"\n",
    "                \n",
    "    f_ext += ext + \".csv\"\n",
    "        \n",
    "    #assert len(lrs) == 91 or len(lrs) == 99, \"Not right amount of files\"\n",
    "    lrs = [l for l in lrs if float(l) >= lr_low and float(l) <= lr_high]\n",
    "    lrs_float = [float(l) for l in lrs]\n",
    "    lrs_float, lrs = zip(*sorted(zip(lrs_float, lrs)))\n",
    "    \n",
    "    \n",
    "    geo_samples = [int(i) for i in np.geomspace(1, num_its - 1, num=700)]\n",
    "    fig, ax = plt.subplots(2,1, sharex=True)\n",
    "    ylabels = [\"Test loss\", \"Training loss\"]     \n",
    "    \n",
    "    for i, lr in enumerate(lrs):\n",
    "        data = pd.read_csv(os.path.join(RESULTS_DIR, f\"lr={lr}_{lr}{f_ext}\"), header=None)\n",
    "        \n",
    "        for j in range(2):\n",
    "            if i == 0:\n",
    "                ax[j].set_xscale('log')\n",
    "                ax[j].set_ylim([ymin[j], ymax[j]])\n",
    "                ax[j].set_ylabel(ylabels[j])\n",
    "\n",
    "            data_vec = data[j] \n",
    "            ax[j].plot(geo_samples, data_vec[geo_samples],\n",
    "        #                color=colorList[k],\n",
    "                lw=2)\n",
    "\n",
    "    ax[0].legend([f\"Lr. {l}\" for l in lrs_float], loc=1)\n",
    "    #fig.suptitle(fr\"$\\eta_{{\\mathbf{{w}}}} = {lr1}, \\eta_{{\\mathbf{{v}}}} = {lr2}$\")\n",
    "\n",
    "    save_dir = \"plots\"\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)  \n",
    "\n",
    "    plt.savefig(os.path.join(save_dir, get_filename_range_misc('', '', lr_low, lr_high, batch_norm, uniform_noise, descr='lr')))\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f2b78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for plotting a selection of curves\n",
    "\n",
    "def plot_individual_runs_range(lr1, lr_ratio_low, lr_ratio_high, batch_norm=False, uniform_noise=False, coupled_noise=None, \n",
    "                               ext='', ymin=[0, 0], ymax = [50, 150000], mod=1, fixed_lr2=False):\n",
    "    \"\"\"Plot individual runs within range lr_ratio_low to lr_ratio_high\"\"\"\n",
    "    \n",
    "    files = get_all_files(lr1, batch_norm, uniform_noise, coupled_noise, ext, fixed_lr2)\n",
    "\n",
    "    if batch_norm:\n",
    "        f_ext = \"_batch_norm\"\n",
    "        #lrs = [f.split('_')[1] for f in files]\n",
    "    elif uniform_noise:\n",
    "        f_ext = \"_uniform_noise\"\n",
    "        #lrs = [f.split('_')[1] for f in files]\n",
    "    else:\n",
    "        f_ext = \"\"\n",
    "        #lrs = [f.split('_')[-1][:-4] for f in files]\n",
    "        \n",
    "    if coupled_noise:\n",
    "        f_ext += f\"_coupled_noise_{coupled_noise}\"\n",
    "                \n",
    "    f_ext += ext + \".csv\"\n",
    "    \n",
    "    lrs = [(f.split('_')[0]).split('=')[1] for f in files] if fixed_lr2 else [f.split('_')[1] for f in files]\n",
    "    lrs = list(set(lrs))\n",
    "    \n",
    "    # Keep runs only within range\n",
    "    lr2_low, lr2_high = lr_ratio_low * lr1, lr_ratio_high * lr1\n",
    "    # files = [f for f, lr in zip(files, lrs) if float(lr) >= lr2_low and float(lr) <= lr2_high]\n",
    "    lrs = [float(lr) for lr in lrs if float(lr) >= lr2_low and float(lr) <= lr2_high]\n",
    "    lrs.sort()\n",
    "    \n",
    "    lrs = [lr for i, lr in enumerate(lrs) if np.mod(i, mod) == 0]\n",
    "\n",
    "    fig, ax = plt.subplots(2, 1, sharex=True, figsize=(8,10))\n",
    "    ylabels = [\"Test loss\", \"Training loss\"]\n",
    "    for i, lr in enumerate(lrs):\n",
    "        \n",
    "        if fixed_lr2:\n",
    "            data = pd.read_csv(os.path.join(RESULTS_DIR, f\"lr={lr}_{lr1}{f_ext}\"), header=None)       \n",
    "        else:\n",
    "            data = pd.read_csv(os.path.join(RESULTS_DIR, f\"lr={lr1}_{lr}{f_ext}\"), header=None)\n",
    "            \n",
    "        geo_samples = [int(i) for i in np.geomspace(1, len(data) - 1, num=700)]\n",
    "\n",
    "        for k in range(2):\n",
    "            if i == 0:\n",
    "                ax[k].set_xscale('log')\n",
    "                ax[k].set_ylim([ymin[k], ymax[k]])\n",
    "                ax[k].set_ylabel(ylabels[k])\n",
    "            \n",
    "            data_vec = data[k] \n",
    "            ax[k].plot(geo_samples, data_vec[geo_samples],\n",
    "#                color=colorList[k],\n",
    "                lw=2)\n",
    "            \n",
    "    ax[0].legend([fr\"$\\eta_{{\\mathbf{{W}}}} = {lr2}$\" for lr2 in lrs] if fixed_lr2 else [fr\"$\\eta_{{\\mathbf{{v}}}} = {lr2}$\" for lr2 in lrs], loc=2)\n",
    "    fig.suptitle(fr\"$\\eta_{{\\mathbf{{v}}}} = {lr1}$\" if fixed_lr2 else fr\"$\\eta_{{\\mathbf{{w}}}} = {lr1}$\")\n",
    "\n",
    "    save_dir = \"plots\"\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)  \n",
    "\n",
    "    plt.savefig(os.path.join(save_dir, get_filename_range(lr1, lr2_low, lr2_high, batch_norm, uniform_noise)))\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecef626",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_individual_runs_range_pcs(lr1, lr2, pc_low, pc_high, batch_norm=False, uniform_noise=False, coupled_noise=None, ext='', ymin=[0, 0], ymax = [50, 150000]):\n",
    "    \"\"\"Plot individual runs within range lr_ratio_low to lr_ratio_high\"\"\"\n",
    "    \n",
    "    files = get_all_files(lr1, batch_norm, uniform_noise, coupled_noise, ext)\n",
    "    files = [file for file in files if file.startswith(f'lr={lr1}_{lr2}')]\n",
    "    files = [file for file in files if \"pcs\" in file]    \n",
    "\n",
    "    if batch_norm:\n",
    "        f_ext = \"_batch_norm\"\n",
    "    elif uniform_noise:\n",
    "        f_ext = \"_uniform_noise\"\n",
    "    else:\n",
    "        f_ext = \"\"\n",
    "        \n",
    "    if coupled_noise:\n",
    "        f_ext += f\"_coupled_noise_{coupled_noise}\"\n",
    "                \n",
    "    f_ext += ext \n",
    "        \n",
    "    pcs = [(f.split('_')[-1]).split('.')[0] for f in files]\n",
    "\n",
    "    # Keep runs only within range\n",
    "    # files = [f for f, lr in zip(files, lrs) if float(lr) >= lr2_low and float(lr) <= lr2_high]\n",
    "    pcs = [float(pc) for pc in pcs if float(pc) >= pc_low and float(pc) <= pc_high]\n",
    "    pcs = [pc for i, pc in enumerate(pcs) if np.mod(i, 2) == 0]\n",
    "\n",
    "    pcs.sort()\n",
    "\n",
    "    fig, ax = plt.subplots(2, 1, sharex=True, figsize=(8,10))\n",
    "    ylabels = [\"Test loss\", \"Training loss\"]\n",
    "    for i, k in enumerate(pcs):\n",
    "        data = pd.read_csv(os.path.join(RESULTS_DIR, f\"lr={lr1}_{lr2}{f_ext}_pcs_{int(k)}.csv\"), header=None)       \n",
    "        geo_samples = [int(i) for i in np.geomspace(1, len(data) - 1, num=700)]\n",
    "\n",
    "        for j in range(2):\n",
    "            if i == 0:\n",
    "                ax[j].set_xscale('log')\n",
    "                ax[j].set_ylim([ymin[j], ymax[j]])\n",
    "                ax[j].set_ylabel(ylabels[j])\n",
    "            \n",
    "            data_vec = data[j] \n",
    "            ax[j].plot(geo_samples, data_vec[geo_samples],\n",
    "#                color=colorList[k],\n",
    "                lw=2)\n",
    "\n",
    "    ax[0].legend([f\"Comp. {int(pc)}\" for pc in pcs], loc=2)\n",
    "    fig.suptitle(fr\"$\\eta_{{\\mathbf{{w}}}} = {lr1}, \\eta_{{\\mathbf{{v}}}} = {lr2}$\")\n",
    "\n",
    "    save_dir = \"plots\"\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)  \n",
    "\n",
    "    plt.savefig(os.path.join(save_dir, get_filename_range_pcs(lr1, lr2, pc_low, pc_high, batch_norm, uniform_noise)))\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def plot_results_pcs(lr1, lr2, vmax=20, vmin=0, keep_nan=True, batch_norm=False, uniform_noise=False, coupled_noise=None, ext='', num_its=50000):\n",
    "    files = get_all_files(lr1, batch_norm, uniform_noise, coupled_noise, ext)\n",
    "    files = [file for file in files if file.startswith(f'lr={lr1}_{lr2}')]\n",
    "    files = [file for file in files if \"pcs\" in file]    \n",
    "\n",
    "    \n",
    "    if not isinstance(vmax, list):\n",
    "        vmax = [vmax] * 2\n",
    "    if not isinstance(vmin, list):\n",
    "        vmin = [vmin] * 2\n",
    "    \n",
    "    if batch_norm:\n",
    "        f_ext = \"_batch_norm\"\n",
    "    elif uniform_noise:\n",
    "        f_ext = \"_uniform_noise\"\n",
    "    else:\n",
    "        f_ext = \"\"\n",
    "        \n",
    "    if coupled_noise:\n",
    "        f_ext += f\"_coupled_noise_{coupled_noise}\"\n",
    "                \n",
    "    f_ext += ext #+ \".csv\"\n",
    "    \n",
    "    #assert len(lrs) == 100, \"Something wrong with the amount of files\"\n",
    "    pcs = [(f.split('_')[-1]).split('.')[0] for f in files] \n",
    "    pcs = [float(pc) for pc in pcs]\n",
    "    pcs.sort()\n",
    "    \n",
    "    #pcs = pcs[:-1]\n",
    "\n",
    "    risks = np.zeros((len(pcs), num_its))\n",
    "    losses = np.zeros((len(pcs), num_its))\n",
    "    for i, k in enumerate(pcs):\n",
    "        data = pd.read_csv(os.path.join(RESULTS_DIR, f\"lr={lr1}_{lr2}{f_ext}_pcs_{int(k)}.csv\"), header=None)\n",
    "        risks[i] = data[0]\n",
    "        losses[i] = data[1]\n",
    "    if (~np.isfinite(risks)).any() and np.nonzero(~(~np.isfinite(risks)).any(axis=-1))[0].any():\n",
    "        print(r\"Lr2 with nan/inf, then some lower lr2\")\n",
    "        idx=np.nonzero(~(~np.isfinite(risks)).any(axis=-1))[0][-1] + 1\n",
    "        for j in range(10):\n",
    "            print(pcs[idx-j])\n",
    "    else:\n",
    "        print('No nans/inf values')\n",
    "        \n",
    "    #ratios = np.array(lrs_float)/lr\n",
    "            \n",
    "    # Subsample epochs\n",
    "    geo_samples = [int(i) for i in np.geomspace(1, num_its - 1, num=700)]\n",
    "    fig, ax = plt.subplots(2,1, sharex=True)\n",
    "\n",
    "    # Plot\n",
    "    im1 = ax[0].imshow(risks[:, geo_samples].transpose()[::-1, :], interpolation='none', aspect='auto', vmax=vmax[0], vmin=vmin[0])\n",
    "    im2 = ax[1].imshow(losses[:, geo_samples].transpose()[::-1, :], interpolation='none', aspect='auto', vmax=vmax[1], vmin=vmin[1])\n",
    "    fig.colorbar(im1, ax=ax[0])\n",
    "    fig.colorbar(im2, ax=ax[1])\n",
    "    \n",
    "    # Title\n",
    "    title = fr\"$\\eta_{{\\mathbf{{w}}}} = {lr1}, \\eta_{{\\mathbf{{v}}}} = {lr2}$\"\n",
    "    \n",
    "    if batch_norm:\n",
    "        title += \", with batch normalization\"\n",
    "    plt.suptitle(title)\n",
    "    \n",
    "    # Set correct x- and y-ticks\n",
    "    # X axis\n",
    "    #ten_powers = 10.0 ** np.arange(-5, 6)\n",
    "    #indices = []\n",
    "    #for val in ten_powers:\n",
    "    #    indices += [np.argmin(np.abs(ratios-val))]\n",
    "    \n",
    "    for k in [1]:\n",
    "        inds = np.arange(0, len(pcs), 5)\n",
    "        ax[k].set_xticks(inds)\n",
    "        ax[k].set_xticklabels([pcs[i] for i in inds])\n",
    "        ax[k].set_xlabel(\"Rank of feature matrix\")\n",
    "    \n",
    "    \n",
    "    # Y axis\n",
    "    ten_powers = 10.0 ** np.arange(4, 0, -1)\n",
    "    indices = []\n",
    "    for val in ten_powers:\n",
    "        indices += [np.argmin(np.abs(geo_samples-val))]\n",
    "    for k in range(2):\n",
    "        ax[k].set_yticks(indices)\n",
    "        ax[k].set_yticklabels([f\"$10^{{{i}}}$\" for i in np.arange(1, 5)])\n",
    "        ax[k].set_ylabel(r\"Iteration $t$\")\n",
    "    \n",
    "    # Save file\n",
    "    save_dir = \"plots\"\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)  \n",
    "        \n",
    "    \n",
    "    figname = append_id(get_filename(lr1, vmax[0], batch_norm), \"pcs\")\n",
    "    plt.savefig(os.path.join(\"plots\", figname), bbox_inches='tight')\n",
    "    \n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3835a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_individual_runs_range_kappa(lr1, lr2, kappa_low, kappa_high, batch_norm=False, uniform_noise=False, coupled_noise=None, ext='', ymin=[0, 0], ymax = [50, 150000]):\n",
    "    \"\"\"Plot individual runs within range kappa_low to kappa_high\"\"\"\n",
    "    \n",
    "    files = get_all_files(lr1, batch_norm, uniform_noise, coupled_noise, ext)\n",
    "    files = [file for file in files if file.startswith(f'lr={lr1}_{lr2}')]\n",
    "    files = [file for file in files if \"kappa\" in file]    \n",
    "\n",
    "    \n",
    "    if batch_norm:\n",
    "        f_ext = \"_batch_norm\"\n",
    "    elif uniform_noise:\n",
    "        f_ext = \"_uniform_noise\"\n",
    "    else:\n",
    "        f_ext = \"\"\n",
    "        \n",
    "    if coupled_noise:\n",
    "        f_ext += f\"_coupled_noise_{coupled_noise}\"\n",
    "        \n",
    "    f_ext += ext \n",
    "                \n",
    "        \n",
    "    kappas = [(f.split('_')[-1]).split('.csv')[0] for f in files]\n",
    "\n",
    "    # Keep runs only within range\n",
    "    # files = [f for f, lr in zip(files, lrs) if float(lr) >= lr2_low and float(lr) <= lr2_high]\n",
    "    kappas = [float(k) for k in kappas if float(k) >= kappa_low and float(k) <= kappa_high]\n",
    "    kappas = list(set(kappas))\n",
    "    kappas = [k for i, k in enumerate(kappas) if np.mod(i, 2) == 0]\n",
    "\n",
    "    kappas.sort()\n",
    "\n",
    "    fig, ax = plt.subplots(2, 1, sharex=True, figsize=(8,10))\n",
    "    ylabels = [\"Test loss\", \"Training loss\"]\n",
    "    for i, k in enumerate(kappas):\n",
    "        data = pd.read_csv(os.path.join(RESULTS_DIR, f\"lr={lr1}_{lr2}{f_ext}_kappa_{k}.csv\"), header=None)       \n",
    "        geo_samples = [int(i) for i in np.geomspace(1, len(data) - 1, num=700)]\n",
    "\n",
    "        for j in range(2):\n",
    "            if i == 0:\n",
    "                ax[j].set_xscale('log')\n",
    "                ax[j].set_ylim([ymin[j], ymax[j]])\n",
    "                ax[j].set_ylabel(ylabels[j])\n",
    "            \n",
    "            data_vec = data[j] \n",
    "            ax[j].plot(geo_samples, data_vec[geo_samples],\n",
    "#                color=colorList[k],\n",
    "                lw=2)\n",
    "            \n",
    "    ax[0].legend([fr\"$\\kappa =$ {k}\" for k in kappas], loc=2)\n",
    "    fig.suptitle(fr\"$\\eta_{{\\mathbf{{w}}}} = {lr1}, \\eta_{{\\mathbf{{v}}}} = {lr2}$\")\n",
    "\n",
    "    save_dir = \"plots\"\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)  \n",
    "\n",
    "    plt.savefig(os.path.join(save_dir, get_filename_range_misc(lr1, lr2, kappa_low, kappa_high, batch_norm, uniform_noise, descr='kappa')))\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def plot_results_kappa(lr1, lr2, vmax=20, vmin=0, keep_nan=True, batch_norm=False, uniform_noise=False, coupled_noise=None, ext='', w=None, u=None, num_its=50000):\n",
    "    files = get_all_files(lr1, batch_norm, uniform_noise, coupled_noise, ext, w=w, u=u)\n",
    "    files = [file for file in files if file.startswith(f'lr={lr1}_{lr2}')]\n",
    "    \n",
    "    #print(files)\n",
    "    files = [file for file in files if \"kappa\" in file]  \n",
    "        \n",
    "    if not isinstance(vmax, list):\n",
    "        vmax = [vmax] * 2\n",
    "    if not isinstance(vmin, list):\n",
    "        vmin = [vmin] * 2\n",
    "    \n",
    "    if batch_norm:\n",
    "        f_ext = \"_batch_norm\"\n",
    "    elif uniform_noise:\n",
    "        f_ext = \"_uniform_noise\"\n",
    "    else:\n",
    "        f_ext = \"\"\n",
    "        \n",
    "    if coupled_noise:\n",
    "        f_ext += f\"_coupled_noise_{coupled_noise}\"\n",
    "                \n",
    "    f_ext += ext #+ \".csv\"\n",
    "    \n",
    "    if w is None and u is None:\n",
    "        kappas = [float((f.split('_')[-1]).split('.csv')[0]) for f in files]\n",
    "        f_ext_2 = \"\"\n",
    "    elif w is not None:\n",
    "        print(files)\n",
    "        kappas = [float((f.split('_w_')[0]).split('_')[-1]) for f in files]\n",
    "        f_ext_2 = f\"_w_{w}_{w}\"\n",
    "    elif u is not None:\n",
    "        kappas = [float((f.split('_fixed_u_')[0]).split('_')[-1]) for f in files]\n",
    "        f_ext_2 = f\"_fixed_u_{u}\"\n",
    "        \n",
    "        \n",
    "    kappas = list(set(kappas))\n",
    "\n",
    "    #assert len(lrs) == 100, \"Something wrong with the amount of files\"\n",
    "    #kappas = [k for i, k in enumerate(kappas) if np.mod(i, 2) == 0]\n",
    "    kappas.sort()\n",
    "\n",
    "    risks = np.zeros((len(kappas), num_its))\n",
    "    losses = np.zeros((len(kappas), num_its))\n",
    "    for i, k in enumerate(kappas):\n",
    "        \n",
    "        try:     \n",
    "            data = pd.read_csv(os.path.join(RESULTS_DIR, f\"lr={lr1}_{lr2}{f_ext}_kappa_{k}{f_ext_2}.csv\"), header=None)\n",
    "\n",
    "            risks[i] = data[0]\n",
    "            losses[i] = data[1]\n",
    "        except:\n",
    "            risks[i] = np.zeros((num_its))\n",
    "            losses[i] = np.zeros((num_its))\n",
    "            \n",
    "    if (~np.isfinite(risks)).any() and np.nonzero(~(~np.isfinite(risks)).any(axis=-1))[0].any():\n",
    "        print(r\"Lr2 with nan/inf, then some lower kappa\")\n",
    "        idx=np.nonzero(~(~np.isfinite(risks)).any(axis=-1))[0][-1] + 1\n",
    "        for j in range(10):\n",
    "            print(kappas[idx-j])\n",
    "    else:\n",
    "        print('No nans/inf values')\n",
    "        \n",
    "    #ratios = np.array(lrs_float)/lr\n",
    "            \n",
    "    # Subsample epochs\n",
    "    geo_samples = [int(i) for i in np.geomspace(1, num_its - 1, num=700)]\n",
    "    fig, ax = plt.subplots(2,1, sharex=True)\n",
    "\n",
    "    # Plot\n",
    "    im1 = ax[0].imshow(risks[:, geo_samples].transpose()[::-1, :], interpolation='none', aspect='auto', vmax=vmax[0], vmin=vmin[0])\n",
    "    im2 = ax[1].imshow(losses[:, geo_samples].transpose()[::-1, :], interpolation='none', aspect='auto', vmax=vmax[1], vmin=vmin[1])\n",
    "    fig.colorbar(im1, ax=ax[0])\n",
    "    fig.colorbar(im2, ax=ax[1])\n",
    "    \n",
    "    # Title\n",
    "    title = fr\"$\\eta_{{\\mathbf{{w}}}} = {lr1}, \\eta_{{\\mathbf{{v}}}} = {lr2}$\"\n",
    "    \n",
    "    if batch_norm:\n",
    "        title += \", with batch normalization\"\n",
    "    plt.suptitle(title)\n",
    "    \n",
    "    # Set correct x- and y-ticks\n",
    "    # X axis\n",
    "    #ten_powers = 10.0 ** np.arange(-5, 6)\n",
    "    #indices = []\n",
    "    #for val in ten_powers:\n",
    "    #    indices += [np.argmin(np.abs(ratios-val))]\n",
    "    \n",
    "    for k in [1]:\n",
    "        inds = np.arange(0, len(kappas), 5)\n",
    "        ax[k].set_xticks(inds)\n",
    "        ax[k].set_xticklabels([round(kappas[i], 2) for i in inds])\n",
    "        ax[k].set_xlabel(\"Eigenvalue ratio\")\n",
    "    \n",
    "    \n",
    "    # Y axis\n",
    "    ten_powers = 10.0 ** np.arange(4, 0, -1)\n",
    "    indices = []\n",
    "    for val in ten_powers:\n",
    "        indices += [np.argmin(np.abs(geo_samples-val))]\n",
    "    for k in range(2):\n",
    "        ax[k].set_yticks(indices)\n",
    "        ax[k].set_yticklabels([f\"$10^{{{i}}}$\" for i in np.arange(1, 5)])\n",
    "        ax[k].set_ylabel(r\"Iteration $t$\")\n",
    "    \n",
    "    # Save file\n",
    "    save_dir = \"plots\"\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)  \n",
    "        \n",
    "    \n",
    "    figname = append_id(get_filename(lr1, vmax[0], batch_norm), \"kappas\")\n",
    "    plt.savefig(os.path.join(\"plots\", figname), bbox_inches='tight')\n",
    "    \n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8c9b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_individual_runs_range_sigma(lr1, lr2, sigma_low, sigma_high, batch_norm=False, uniform_noise=False, coupled_noise='', ext='', ymin=[0, 0], ymax = [50, 150000]):\n",
    "    \"\"\"Plot individual runs within range sigma_low to sigma_high\"\"\"\n",
    "    \n",
    "    files = get_all_files(lr1, batch_norm, uniform_noise, coupled_noise, ext)\n",
    "    files = [file for file in files if file.startswith(f'lr={lr1}_{lr2}')]\n",
    "    \n",
    "    if batch_norm:\n",
    "        f_ext = \"_batch_norm\"\n",
    "    elif uniform_noise:\n",
    "        f_ext = \"_uniform_noise\"\n",
    "    else:\n",
    "        f_ext = \"\"\n",
    "        \n",
    "    if coupled_noise:\n",
    "        f_ext += \"_coupled_noise\"\n",
    "        \n",
    "    #f_ext += ext \n",
    "                \n",
    "    sigmas = [(f.split(f_ext)[-1]).split('_')[1] for f in files]\n",
    "\n",
    "    # Keep runs only within range\n",
    "    # files = [f for f, lr in zip(files, lrs) if float(lr) >= lr2_low and float(lr) <= lr2_high]\n",
    "    sigmas = [float(s) for s in sigmas if float(s) >= sigma_low and float(s) <= sigma_high]\n",
    "\n",
    "    sigmas = list(set(sigmas))\n",
    "\n",
    "    sigmas.sort()\n",
    "    \n",
    "    sigmas = [s for i, s in enumerate(sigmas) if np.mod(i, 3) == 0]\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots(2, 1, sharex=True, figsize=(8,10))\n",
    "    ylabels = [\"Test loss\", \"Training loss\"]\n",
    "    for i, s in enumerate(sigmas):\n",
    "        data = pd.read_csv(os.path.join(RESULTS_DIR, f\"lr={lr1}_{lr2}{f_ext}_{s}{ext}.csv\"), header=None)       \n",
    "        geo_samples = [int(i) for i in np.geomspace(1, len(data) - 1, num=700)]\n",
    "\n",
    "        for j in range(2):\n",
    "            if i == 0:\n",
    "                ax[j].set_xscale('log')\n",
    "                ax[j].set_ylim([ymin[j], ymax[j]])\n",
    "                ax[j].set_ylabel(ylabels[j])\n",
    "            \n",
    "            data_vec = data[j] \n",
    "            ax[j].plot(geo_samples, data_vec[geo_samples], # - s**2,\n",
    "#                color=colorList[k],\n",
    "                lw=2)\n",
    "            \n",
    "    ax[0].legend([fr\"$\\sigma =$ {s}\" for s in sigmas], loc=2)\n",
    "    fig.suptitle(fr\"$\\eta_{{\\mathbf{{w}}}} = {lr1}, \\eta_{{\\mathbf{{v}}}} = {lr2}$\")\n",
    "\n",
    "    save_dir = \"plots\"\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)  \n",
    "\n",
    "    plt.savefig(os.path.join(save_dir, get_filename_range_misc(lr1, lr2, sigma_low, sigma_high, batch_norm, uniform_noise, descr='sigma')))\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def plot_results_sigma(lr1, lr2, vmax=20, vmin=0, keep_nan=True, batch_norm=False, uniform_noise=False, coupled_noise=None, ext='', num_its=50000):\n",
    "    files = get_all_files(lr1, batch_norm, uniform_noise, coupled_noise, ext)\n",
    "    files = [file for file in files if file.startswith(f'lr={lr1}_{lr2}')]\n",
    "        \n",
    "    if not isinstance(vmax, list):\n",
    "        vmax = [vmax] * 2\n",
    "    if not isinstance(vmin, list):\n",
    "        vmin = [vmin] * 2\n",
    "    \n",
    "    if batch_norm:\n",
    "        f_ext = \"_batch_norm\"\n",
    "    elif uniform_noise:\n",
    "        f_ext = \"_uniform_noise\"\n",
    "    else:\n",
    "        f_ext = \"\"\n",
    "        \n",
    "    if coupled_noise:\n",
    "        f_ext += \"_coupled_noise\"\n",
    "    \n",
    "            \n",
    "    #f_ext += ext #+ \".csv\"\n",
    "    \n",
    "    sigmas = [float((f.split(f_ext)[-1]).split('_')[1]) for f in files]\n",
    "    sigmas = list(set(sigmas))\n",
    "    \n",
    "    sigmas.sort()\n",
    "\n",
    "    risks = np.zeros((len(sigmas), num_its))\n",
    "    losses = np.zeros((len(sigmas), num_its))\n",
    "    for i, s in enumerate(sigmas):\n",
    "        \n",
    "        try:\n",
    "            data = pd.read_csv(os.path.join(RESULTS_DIR, f\"lr={lr1}_{lr2}{f_ext}_{s}{ext}.csv\"), header=None)\n",
    "            risks[i] = data[0] - s**2\n",
    "            losses[i] = data[1] - s**2\n",
    "        except:\n",
    "            risks[i] = np.zeros((num_its))\n",
    "            losses[i] = np.zeros((num_its))\n",
    "            \n",
    "    if (~np.isfinite(risks)).any() and np.nonzero(~(~np.isfinite(risks)).any(axis=-1))[0].any():\n",
    "        print(r\"Lr2 with nan/inf, then some lower sigma\")\n",
    "        idx=np.nonzero(~(~np.isfinite(risks)).any(axis=-1))[0][-1] + 1\n",
    "        for j in range(10):\n",
    "            print(sigmas[idx-j])\n",
    "    else:\n",
    "        print('No nans/inf values')\n",
    "        \n",
    "    #ratios = np.array(lrs_float)/lr\n",
    "            \n",
    "    # Subsample epochs\n",
    "    geo_samples = [int(i) for i in np.geomspace(1, num_its - 1, num=700)]\n",
    "    fig, ax = plt.subplots(2,1, sharex=True)\n",
    "\n",
    "    # Plot\n",
    "    im1 = ax[0].imshow(risks[:, geo_samples].transpose()[::-1, :], interpolation='none', aspect='auto', vmax=vmax[0], vmin=vmin[0])\n",
    "    im2 = ax[1].imshow(losses[:, geo_samples].transpose()[::-1, :], interpolation='none', aspect='auto', vmax=vmax[1], vmin=vmin[1])\n",
    "    fig.colorbar(im1, ax=ax[0])\n",
    "    fig.colorbar(im2, ax=ax[1])\n",
    "    \n",
    "    # Title\n",
    "    title = fr\"$\\eta_{{\\mathbf{{w}}}} = {lr1}, \\eta_{{\\mathbf{{v}}}} = {lr2}$\"\n",
    "    \n",
    "    if batch_norm:\n",
    "        title += \", with batch normalization\"\n",
    "    plt.suptitle(title)\n",
    "    \n",
    "    # Set correct x- and y-ticks\n",
    "    # X axis\n",
    "    #ten_powers = 10.0 ** np.arange(-5, 6)\n",
    "    #indices = []\n",
    "    #for val in ten_powers:\n",
    "    #    indices += [np.argmin(np.abs(ratios-val))]\n",
    "    \n",
    "    for k in [1]:\n",
    "        inds = np.arange(0, len(sigmas), 5)\n",
    "        ax[k].set_xticks(inds)\n",
    "        ax[k].set_xticklabels([round(sigmas[i], 2) for i in inds])\n",
    "        ax[k].set_xlabel(\"Output variance\")\n",
    "    \n",
    "    \n",
    "    # Y axis\n",
    "    ten_powers = 10.0 ** np.arange(4, 0, -1)\n",
    "    indices = []\n",
    "    for val in ten_powers:\n",
    "        indices += [np.argmin(np.abs(geo_samples-val))]\n",
    "    for k in range(2):\n",
    "        ax[k].set_yticks(indices)\n",
    "        ax[k].set_yticklabels([f\"$10^{{{i}}}$\" for i in np.arange(1, 5)])\n",
    "        ax[k].set_ylabel(r\"Iteration $t$\")\n",
    "    \n",
    "    # Save file\n",
    "    save_dir = \"plots\"\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)  \n",
    "        \n",
    "    \n",
    "    figname = append_id(get_filename(lr1, vmax[0], batch_norm), \"sigmas\")\n",
    "    plt.savefig(os.path.join(\"plots\", figname), bbox_inches='tight')\n",
    "    \n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13328534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: these two functions should eventually replace many of the other functions\n",
    "def plot_individual_runs_range_u(lr1, lr2, u_low, u_high, key=\"\", batch_norm=False, uniform_noise=False, coupled_noise=None, ext='', ymin=[0, 0], ymax = [50, 150000]):\n",
    "    \"\"\"Plot individual runs within range u_low to u_high\"\"\"\n",
    "    \n",
    "    files = get_all_files(lr1, batch_norm, uniform_noise, coupled_noise, ext)\n",
    "    files = [file for file in files if file.startswith(f'lr={lr1}_{lr2}')]\n",
    "    files = [file for file in files if \"fixed_u\" in file]    \n",
    "\n",
    "    \n",
    "    if batch_norm:\n",
    "        f_ext = \"_batch_norm\"\n",
    "    elif uniform_noise:\n",
    "        f_ext = \"_uniform_noise\"\n",
    "    else:\n",
    "        f_ext = \"\"\n",
    "        \n",
    "    if coupled_noise:\n",
    "        f_ext += f\"_coupled_noise_{coupled_noise}\"\n",
    "        \n",
    "    f_ext += ext \n",
    "                \n",
    "        \n",
    "    us = [(f.split('_')[-1]).split('.csv')[0] for f in files]\n",
    "\n",
    "    # Keep runs only within range\n",
    "    # files = [f for f, lr in zip(files, lrs) if float(lr) >= lr2_low and float(lr) <= lr2_high]\n",
    "    us = [float(u) for u in us if float(u) >= u_low and float(u) <= u_high]\n",
    "    us = list(set(us))\n",
    "    #us = [u for i, u in enumerate(us) if np.mod(i, 2) == 0]\n",
    "\n",
    "    us.sort()\n",
    "\n",
    "    fig, ax = plt.subplots(2, 1, sharex=True, figsize=(8,10))\n",
    "    ylabels = [\"Test loss\", \"Training loss\"]\n",
    "    for i, k in enumerate(us):\n",
    "        data = pd.read_csv(os.path.join(RESULTS_DIR, f\"lr={lr1}_{lr2}{f_ext}_fixed_u_{k}.csv\"), header=None)       \n",
    "        geo_samples = [int(i) for i in np.geomspace(1, len(data) - 1, num=700)]\n",
    "\n",
    "        for j in range(2):\n",
    "            if i == 0:\n",
    "                ax[j].set_xscale('log')\n",
    "                ax[j].set_ylim([ymin[j], ymax[j]])\n",
    "                ax[j].set_ylabel(ylabels[j])\n",
    "            \n",
    "            data_vec = data[j] \n",
    "            ax[j].plot(geo_samples, data_vec[geo_samples],\n",
    "#                color=colorList[k],\n",
    "                lw=2)\n",
    "            \n",
    "    ax[0].legend([fr\"$u =$ {u}\" for u in us], loc=2)\n",
    "    fig.suptitle(fr\"$\\eta_{{\\mathbf{{w}}}} = {lr1}, \\eta_{{\\mathbf{{v}}}} = {lr2}$\")\n",
    "\n",
    "    save_dir = \"plots\"\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)  \n",
    "\n",
    "    plt.savefig(os.path.join(save_dir, get_filename_range_misc(lr1, lr2, u_low, u_high, batch_norm, uniform_noise, descr='fixed_u')))\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def plot_results_u(lr1, lr2, vmax=20, vmin=0, keep_nan=True, batch_norm=False, uniform_noise=False, coupled_noise=None, ext='', num_its=50000):\n",
    "    files = get_all_files(lr1, batch_norm, uniform_noise, coupled_noise, ext)\n",
    "    files = [file for file in files if file.startswith(f'lr={lr1}_{lr2}')]\n",
    "    files = [file for file in files if \"fixed_u\" in file]  \n",
    "        \n",
    "    if not isinstance(vmax, list):\n",
    "        vmax = [vmax] * 2\n",
    "    if not isinstance(vmin, list):\n",
    "        vmin = [vmin] * 2\n",
    "    \n",
    "    if batch_norm:\n",
    "        f_ext = \"_batch_norm\"\n",
    "    elif uniform_noise:\n",
    "        f_ext = \"_uniform_noise\"\n",
    "    else:\n",
    "        f_ext = \"\"\n",
    "        \n",
    "    if coupled_noise:\n",
    "        f_ext += f\"_coupled_noise_{coupled_noise}\"\n",
    "                \n",
    "    f_ext += ext #+ \".csv\"\n",
    "    \n",
    "    \n",
    "    us = [float((f.split('_')[-1]).split('.csv')[0]) for f in files]\n",
    "    us = list(set(us))\n",
    "\n",
    "    #assert len(lrs) == 100, \"Something wrong with the amount of files\"\n",
    "    #us = [u for i, u in enumerate(us) if np.mod(i, 2) == 0]\n",
    "    us.sort()\n",
    "\n",
    "    risks = np.zeros((len(us), num_its))\n",
    "    losses = np.zeros((len(us), num_its))\n",
    "    for i, k in enumerate(us):\n",
    "        \n",
    "        try:\n",
    "            data = pd.read_csv(os.path.join(RESULTS_DIR, f\"lr={lr1}_{lr2}{f_ext}_fixed_u_{k}.csv\"), header=None)\n",
    "            risks[i] = data[0]\n",
    "            losses[i] = data[1]\n",
    "        except:\n",
    "            risks[i] = np.zeros((num_its))\n",
    "            losses[i] = np.zeros((num_its))\n",
    "            \n",
    "    if (~np.isfinite(risks)).any() and np.nonzero(~(~np.isfinite(risks)).any(axis=-1))[0].any():\n",
    "        print(r\"Lr2 with nan/inf, then some lower u\")\n",
    "        idx=np.nonzero(~(~np.isfinite(risks)).any(axis=-1))[0][-1] + 1\n",
    "        for j in range(10):\n",
    "            print(us[idx-j])\n",
    "    else:\n",
    "        print('No nans/inf values')\n",
    "        \n",
    "    #ratios = np.array(lrs_float)/lr\n",
    "            \n",
    "    # Subsample epochs\n",
    "    geo_samples = [int(i) for i in np.geomspace(1, num_its - 1, num=700)]\n",
    "    fig, ax = plt.subplots(2,1, sharex=True)\n",
    "\n",
    "    # Plot\n",
    "    im1 = ax[0].imshow(risks[:, geo_samples].transpose()[::-1, :], interpolation='none', aspect='auto', vmax=vmax[0], vmin=vmin[0])\n",
    "    im2 = ax[1].imshow(losses[:, geo_samples].transpose()[::-1, :], interpolation='none', aspect='auto', vmax=vmax[1], vmin=vmin[1])\n",
    "    fig.colorbar(im1, ax=ax[0])\n",
    "    fig.colorbar(im2, ax=ax[1])\n",
    "    \n",
    "    # Title\n",
    "    title = fr\"$\\eta_{{\\mathbf{{w}}}} = {lr1}, \\eta_{{\\mathbf{{v}}}} = {lr2}$\"\n",
    "    \n",
    "    if batch_norm:\n",
    "        title += \", with batch normalization\"\n",
    "    plt.suptitle(title)\n",
    "    \n",
    "    # Set correct x- and y-ticks\n",
    "    # X axis\n",
    "    ten_powers = 10.0 ** np.arange(-8, 3)\n",
    "    indices = []\n",
    "    for val in ten_powers:\n",
    "        indices += [np.argmin(np.abs(us-val))]\n",
    "    \n",
    "    for k in [1]:\n",
    "        #inds = np.arange(0, len(us), 5)\n",
    "        ax[k].set_xticks(indices)\n",
    "        ax[k].set_xticklabels([f\"$10^{{{i}}}$\" for i in np.arange(-5, 6)])\n",
    "        ax[k].set_xlabel(\"Interaction term (u)\")\n",
    "    \n",
    "    \n",
    "    # Y axis\n",
    "    ten_powers = 10.0 ** np.arange(4, 0, -1)\n",
    "    indices = []\n",
    "    for val in ten_powers:\n",
    "        indices += [np.argmin(np.abs(geo_samples-val))]\n",
    "    for k in range(2):\n",
    "        ax[k].set_yticks(indices)\n",
    "        ax[k].set_yticklabels([f\"$10^{{{i}}}$\" for i in np.arange(1, 5)])\n",
    "        ax[k].set_ylabel(r\"Iteration $t$\")\n",
    "    \n",
    "    # Save file\n",
    "    save_dir = \"plots\"\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)  \n",
    "        \n",
    "    \n",
    "    figname = append_id(get_filename(lr1, vmax[0], batch_norm), \"fixed_u\")\n",
    "    plt.savefig(os.path.join(\"plots\", figname), bbox_inches='tight')\n",
    "    \n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735c50ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results_weight_eval(lr, vmax=20, vmin=0, keep_nan=True, batch_norm=False, uniform_noise=False, coupled_noise=None, ext='', \n",
    "                             plot_nans=False, num_its=50000, fixed_lr2=False, plot_extra=False, step=0, gs=None):\n",
    "    \n",
    "    files = get_all_files(lr, batch_norm, uniform_noise, coupled_noise, ext, fixed_lr2)\n",
    "\n",
    "    if not isinstance(vmax, list):\n",
    "        vmax = [vmax] * 2\n",
    "    if not isinstance(vmin, list):\n",
    "        vmin = [vmin] * 2\n",
    "    \n",
    "    if batch_norm:\n",
    "        f_ext = \"_batch_norm\"\n",
    "    elif uniform_noise:\n",
    "        f_ext = \"_uniform_noise\"\n",
    "    else:\n",
    "        f_ext = \"\"\n",
    "        \n",
    "    r_lrs = [\"1.0\", \"0.0001\", \"0.02\", \"0.1\", \"0.002\"]\n",
    "        \n",
    "    #if batch_norm or uniform_noise:\n",
    "    lrs = [(f.split('_')[0]).split('=')[1] for f in files] if fixed_lr2 else [f.split('_')[1] for f in files]\n",
    "    #else:\n",
    "    #    lrs = [f.split('_')[-1][:-4] for f in files]\n",
    "    \n",
    "    lrs = [l for l in lrs if l not in r_lrs]\n",
    "\n",
    "    lrs = list(set(lrs))\n",
    "    \n",
    "    lrs = [lr for lr in lrs if float(lr) >= 1e-8]\n",
    "    \n",
    "    if coupled_noise:\n",
    "        f_ext += f\"_coupled_noise_{coupled_noise}\"\n",
    "                \n",
    "    f_ext += ext + \".csv\"\n",
    "    \n",
    "    #assert len(lrs) == 99, \"Something wrong with the amount of files\"\n",
    "    lrs_float = [float(l) for l in lrs]\n",
    "    lrs_float, lrs = zip(*sorted(zip(lrs_float, lrs)))\n",
    "      \n",
    "    if gs is None:\n",
    "        gs = float((ext.split(\"dim_\")[-1]).split('_')[0]) if \"dim\" in ext else 50\n",
    "\n",
    "    mse_group_1 = np.zeros((len(lrs), num_its))\n",
    "    mse_group_2 = np.zeros((len(lrs), num_its))\n",
    "    for i, l in enumerate(lrs):\n",
    "        if fixed_lr2:\n",
    "            data = pd.read_csv(os.path.join(RESULTS_DIR, f\"lr={l}_{lr}{f_ext}\"), header=None)\n",
    "        else:\n",
    "            data = pd.read_csv(os.path.join(RESULTS_DIR, f\"lr={lr}_{l}{f_ext}\"), header=None)\n",
    "\n",
    "        if gs > 2:\n",
    "            mse_group_1[i] = np.column_stack([data[i] for i in range(2 + step, int(gs/2) + step)]).mean(axis=-1) #data[data.columns[2:int(dim/2)]].mean(axis=-1)\n",
    "            mse_group_2[i] = np.column_stack([data[i] for i in range(int(gs/2) + step, int(gs) + step)]).mean(axis=-1) #data[data.columns[int(dim/2):int(dim)]].mean(axis=-1)\n",
    "        else:\n",
    "            mse_group_1[i] = data[2 + step]\n",
    "            mse_group_2[i] = data[3 + step]\n",
    "    \n",
    "    if (~np.isfinite(mse_group_1)).any() and np.nonzero(~(~np.isfinite(mse_group_1)).any(axis=-1))[0].any():\n",
    "        print(l)\n",
    "        print(os.path.getctime(os.path.join(RESULTS_DIR, f\"lr={l}_{lr}{f_ext}\")))\n",
    "\n",
    "        print(r\"Lr2 with nan/inf, then some lower lr2\")\n",
    "        idx=np.nonzero(~(~np.isfinite(mse_group_1)).any(axis=-1))[0][-1] + 1\n",
    "        for j in range(10):\n",
    "            if plot_nans:\n",
    "                plot_individual_run(lr, lrs[idx-j], batch_norm)\n",
    "            else:\n",
    "                print(lrs[idx-j])\n",
    "    else:\n",
    "        print('No nans/inf values')\n",
    "    ratios = np.array(lrs_float)/lr\n",
    "            \n",
    "    # Subsample epochs\n",
    "    geo_samples = [int(i) for i in np.geomspace(1, num_its - 1, num=700)]\n",
    "    fig, ax = plt.subplots(2,1, sharex=True)\n",
    "    \n",
    "\n",
    "    # Plot\n",
    "    im1 = ax[0].imshow(mse_group_1[:, geo_samples].transpose()[::-1, :], interpolation='none', aspect='auto', vmax=vmax[0], vmin=vmin[0])\n",
    "    im2 = ax[1].imshow(mse_group_2[:, geo_samples].transpose()[::-1, :], interpolation='none', aspect='auto', vmax=vmax[1], vmin=vmin[1])\n",
    "    fig.colorbar(im1, ax=ax[0])\n",
    "    fig.colorbar(im2, ax=ax[1])\n",
    "    \n",
    "    # Title\n",
    "    title = fr\"$\\eta_{{\\mathbf{{v}}}}={lr}$\" if fixed_lr2 else fr\"$\\eta_{{\\mathbf{{W}}}}={lr}$\"\n",
    "    \n",
    "    if batch_norm:\n",
    "        title += \", with batch normalization\"\n",
    "    plt.suptitle(title)\n",
    "    \n",
    "    # Set correct x- and y-ticks\n",
    "    # X axis\n",
    "    min_pow = -5\n",
    "    max_pow = 6\n",
    "    ten_powers = 10.0 ** np.arange(min_pow, max_pow)\n",
    "    indices = []\n",
    "    for val in ten_powers:\n",
    "        indices += [np.argmin(np.abs(ratios-val))]\n",
    "    \n",
    "    for k in [1]:\n",
    "        ax[k].set_xticks(indices)\n",
    "        ax[k].set_xticklabels([f\"$10^{{{i}}}$\" for i in np.arange(min_pow,max_pow)])\n",
    "        ax[k].set_xlabel(r\"$\\eta_{\\mathbf{W}} / \\eta_{\\mathbf{v}}$\" if fixed_lr2 else r\"$\\eta_{\\mathbf{v}} / \\eta_{\\mathbf{W}}$\")\n",
    "    \n",
    "    # Y axis\n",
    "    ten_powers = 10.0 ** np.arange(4, 0, -1)\n",
    "    indices = []\n",
    "    for val in ten_powers:\n",
    "        indices += [np.argmin(np.abs(geo_samples-val))]\n",
    "    for k in range(2):\n",
    "        ax[k].set_yticks(indices)\n",
    "        ax[k].set_yticklabels([f\"$10^{{{i}}}$\" for i in np.arange(1, 5)])\n",
    "        ax[k].set_ylabel(r\"Iteration $t$\")\n",
    "    \n",
    "    # Save file\n",
    "    save_dir = \"plots\"\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)  \n",
    "        \n",
    "    \n",
    "    figname = get_filename(lr, vmax[0], batch_norm)\n",
    "    plt.savefig(os.path.join(\"plots\", figname), bbox_inches='tight')\n",
    "    \n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4259cf64",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_individual_run(0.001, 0.001, batch_norm=False, uniform_noise=True, coupled_noise=None, ext='1.0_dim_2_samples_10_linear_kappa_3.0', plot_extra=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d527183",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_individual_runs_range_kappa(0.001, 0.001, 1, 5, batch_norm=False, uniform_noise=True, coupled_noise=None, ext='_1.0_dim_10', ymin=[0, 0], ymax=[200, 120])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c38964",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results_kappa(0.001, 0.001, vmax=[25, 110], vmin=[5, 80], batch_norm=False, uniform_noise=True, coupled_noise=None, ext='_1.0_dim_10_linear', u=1.0, num_its=100001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16602ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_individual_runs_range_sigma(0.001, 0.001, 0.01, 2, batch_norm=False, uniform_noise=True, coupled_noise=None, ext='_dim_2_linear_kappa_3.0', ymin=[0, 0], ymax=[12, 20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b9ad54",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results_sigma(0.001, 0.001, vmax=[15, 60], vmin=[0, 0], batch_norm=False, uniform_noise=True, coupled_noise=None, ext='_dim_2_linear_kappa_3.0', num_its=100001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fddf5253",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_individual_runs_range(0.001, 1e-7, 9e-6, batch_norm=False, uniform_noise=True, coupled_noise=None, ext='_1.0_dim_10_linear_kappa_3.0_w_0.1_0.1', ymin=[8, 88], ymax=[15, 102], fixed_lr2=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef2991c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_results(0.001,  vmax=[340, 250], vmin=[260, 0], batch_norm=False, uniform_noise=True, coupled_noise=None, ext='_1.0_dim_100_samples_150_linear_kappa_5.0', num_its=100001, fixed_lr2=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64c008f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_individual_runs_range_pcs(0.0001, 0.0001, 0, 100, batch_norm=False, uniform_noise=True, coupled_noise=10.0, ext='_10.0_dim_100', ymin=[9e3, 0], ymax=[2e4, 10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fce8b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results_pcs(0.0001, 0.0001, vmax=[9.5e5, 10000], vmin=[9e5, 0], batch_norm=False, uniform_noise=True, coupled_noise=100.0, ext='_10.0_dim_100', num_its=100001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5d46fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for eta_w in [1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2]:\n",
    "    plot_results(eta_w, 20, plot_nans=False, batch_norm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f71162",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_same_lr_range(0.01, 0.03, ymin=[5, 80], ymax=[20, 100], batch_norm=False, uniform_noise=True, coupled_noise=None, ext='_1.0_dim_10_linear_kappa_3.0', plot_nans=False, num_its=100001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2e2fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_same_lr(vmax=[20, 100], vmin=[5, 80], batch_norm=False, uniform_noise=True, coupled_noise=None, ext='_1.0_dim_10_linear_kappa_3.0', plot_nans=False, num_its=100001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef500930",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_individual_runs_range_u(0.001, 0.001, 1, 10, batch_norm=False, uniform_noise=True, coupled_noise=None, ext='_1.0_dim_100_samples_150_linear_kappa_5.0_w_0.1_0.1', ymin=[250, 30], ymax=[480, 300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b19de0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results_u(0.001, 0.001, vmax=[480, 300], vmin=[250, 30], batch_norm=False, uniform_noise=True, coupled_noise=None, ext='_1.0_dim_100_samples_150_linear_kappa_5.0_w_0.1_0.1', num_its=100001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefa93c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results_weight_eval(0.001, vmax=[0.4, 0.8], vmin=[0, 0], batch_norm=False, uniform_noise=True, coupled_noise=None, ext='_1.0_dim_10_linear_kappa_3.0_w_0.1_0.1', num_its=100001, fixed_lr2=False, step=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c36808c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
