{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Double descent in one layer neural network - loss surfaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import cm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import datetime\n",
    "import pathlib\n",
    "import random\n",
    "import json\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import torch\n",
    "\n",
    "import sys\n",
    "sys.path.append('../code/')\n",
    "from linear_utils import linear_model\n",
    "from train_utils import save_config, prune_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# argument written in command line format\n",
    "cli_args = '--seed 12 --save-results --jacobian --risk-loss L2 -d 2 -n 10 --sigmas geo --s-range 0.5 0.5 --beta 5.0 5.0 --sigma_noise 5.0 --num-layers 1 --no-bias'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='CLI parameters for training')\n",
    "parser.add_argument('--config', type=str, default='', metavar='CONFIG',\n",
    "                    help='Config file')\n",
    "parser.add_argument('--root', type=str, default='', metavar='DIR',\n",
    "                    help='Root directory')\n",
    "parser.add_argument('-t', '--iterations', type=int, default=1e4, metavar='ITERATIONS',\n",
    "                    help='Iterations (default: 1e4)')\n",
    "parser.add_argument('-n', '--samples', type=int, default=100, metavar='N',\n",
    "                    help='Number of samples (default: 100)')\n",
    "parser.add_argument('--print-freq', type=int, default=100,\n",
    "                    help='CLI output printing frequency (default: 1000)')\n",
    "parser.add_argument('--gpu', type=int, default=None,\n",
    "                    help='Number of GPUS to use')\n",
    "parser.add_argument('--disable-cuda', action='store_true', default=False,\n",
    "                    help='Disable CUDA')\n",
    "parser.add_argument('--seed', type=int, default=None,\n",
    "                    help='Random seed')\n",
    "parser.add_argument('-d', '--dim', type=int, default=50, metavar='DIMENSION',\n",
    "                    help='Feature dimension (default: 50)')\n",
    "parser.add_argument('--hidden', type=int, default=200, metavar='DIMENSION',\n",
    "                    help='Hidden layer dimension (default: 200)')\n",
    "parser.add_argument('--batch-norm', action='store_true', default=False,\n",
    "                    help='Use batch norm')\n",
    "parser.add_argument('--no-bias', action='store_true', default=False,\n",
    "                    help='Do not use bias')\n",
    "parser.add_argument('--linear', action='store_true', default=False,\n",
    "                    help='Linear activation function')\n",
    "parser.add_argument('--sigmas', type=str, default=None,\n",
    "                    help='Sigmas')\n",
    "parser.add_argument('--sigma_noise', nargs='*', type=float, default=0.0,\n",
    "                    help='Output noise.')\n",
    "parser.add_argument('--beta', nargs='*', type=float, default=None,\n",
    "                    help='True model parameters.')\n",
    "parser.add_argument('--coupled_noise', action='store_true', default=False,\n",
    "                    help='Couple noise in output to large eigenvalues.')\n",
    "parser.add_argument('-r', '--s-range', nargs='*', type=float,\n",
    "                    help='Range for sigmas')\n",
    "parser.add_argument('-w', '--scales', nargs='*', type=float,\n",
    "                    help='scale of the weights')\n",
    "parser.add_argument('--first_layer_lr', type=float, default=1e-4, metavar='FIRST LR',\n",
    "                    help='First layer lr')\n",
    "parser.add_argument('--lr_factor', type=float, default=1e-4, metavar='LR RATIO',\n",
    "                    help='Factor with which first layer lr i multiplied to obtain second layer lr')\n",
    "parser.add_argument('--normalized', action='store_true', default=False,\n",
    "                    help='normalize sample norm across features')\n",
    "parser.add_argument('--risk-loss', type=str, default='MSE', metavar='LOSS',\n",
    "                    help='Loss for validation')\n",
    "parser.add_argument('--jacobian', action='store_true', default=False,\n",
    "                    help='compute the SVD of the jacobian of the network')\n",
    "parser.add_argument('--save-results', action='store_true', default=False,\n",
    "                    help='Save the results for plots')\n",
    "parser.add_argument('--plot', action='store_true', default=False,\n",
    "                    help='Plot the results')\n",
    "parser.add_argument('--eigen', action='store_true', default=False,\n",
    "                    help='Compute eigenvalue')\n",
    "parser.add_argument('--pcs', type=int, default=None, \n",
    "                    help='Number of PCs to use in data.')\n",
    "parser.add_argument('--transform-data', action='store_true', default=False, \n",
    "                    help='Use data in transformed space')\n",
    "parser.add_argument('--low-rank-eval', action='store_true', default=False, \n",
    "                    help='Evaluate performance of low-rank train data.')\n",
    "parser.add_argument('--weight-eval', action='store_true', default=False, \n",
    "                    help='Evaluate MSE of weights (linear model).')\n",
    "parser.add_argument('--details', type=str, metavar='N',\n",
    "                    default='no_detail_given',\n",
    "                    help='details about the experimental setup')\n",
    "parser.add_argument('--num-layers', type=int, default=2, \n",
    "                    help='number of model layers (1, 2 or 5)')\n",
    "parser.add_argument('--freeze-layer', type=int, default=None, \n",
    "                    help='Freezing model layer.')\n",
    "parser.add_argument('--scaling-layer', action='store_true', default=False,\n",
    "                    help='Use ScalingLayer as last layer (for analysis).')\n",
    "\n",
    "args = parser.parse_args(cli_args.split())\n",
    "\n",
    "# directories\n",
    "root = pathlib.Path(args.root) if args.root else pathlib.Path.cwd().parent\n",
    "\n",
    "current_date = str(datetime.datetime.today().strftime('%Y-%m-%d-%H-%M-%S'))\n",
    "args.outpath = (pathlib.Path.cwd().parent / 'results' / 'two_layer_nn' / current_date)\n",
    "\n",
    "if args.save_results:\n",
    "    args.outpath.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "if args.seed is not None:\n",
    "    random.seed(args.seed)\n",
    "    torch.manual_seed(args.seed)\n",
    "    np.random.seed(args.seed)\n",
    "\n",
    "args.device = 'cuda' if (not args.disable_cuda and torch.cuda.is_available()) else 'cpu'\n",
    "print(args.device)\n",
    "\n",
    "args.lr = [args.first_layer_lr, args.first_layer_lr*args.lr_factor]\n",
    "\n",
    "if len(args.sigma_noise) == 1:\n",
    "    args.sigma_noise = args.sigma_noise[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(args, return_weights=False):\n",
    "    # sample training set from the linear model\n",
    "    \n",
    "    if args.beta is not None:\n",
    "        args.beta = np.array(args.beta)\n",
    "    \n",
    "    lin_model = linear_model(args.dim, sigma_noise=args.sigma_noise, beta=args.beta, normalized=False, sigmas=args.sigmas, s_range=args.s_range, coupled_noise=args.coupled_noise, transform_data=args.transform_data)\n",
    "    Xs, ys = lin_model.sample(args.samples, train=True)\n",
    "    Xs = torch.Tensor(Xs).to(args.device)\n",
    "    ys = torch.Tensor(ys.reshape((-1, 1))).to(args.device)\n",
    "\n",
    "    # sample the set for empirical risk calculation\n",
    "    Xt, yt = lin_model.sample(args.samples, train=False) # * 1000\n",
    "    Xt = torch.Tensor(Xt).to(args.device)\n",
    "    yt = torch.Tensor(yt.reshape((-1, 1))).to(args.device)\n",
    "    \n",
    "    if return_weights:\n",
    "        return Xs, ys, Xt, yt, lin_model.beta\n",
    "    else:\n",
    "        return Xs, ys, Xt, yt\n",
    "    \n",
    "    \n",
    "def get_model(args):\n",
    "    model = torch.nn.Sequential(\n",
    "        torch.nn.Linear(args.dim, 1, bias=not args.no_bias),\n",
    "    ).to(args.device)\n",
    "    \n",
    "    return model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Xs, ys, Xt, yt, ws = get_dataset(args, return_weights=True)\n",
    "\n",
    "u, s, vh = np.linalg.svd(Xs)\n",
    "print(s)\n",
    "    \n",
    "model = get_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss functions\n",
    "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "risk_fn = torch.nn.L1Loss(reduction='mean') if args.risk_loss == 'L1' else loss_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_min, w_max, w_step = -10.0, 10.0, 0.1\n",
    "u, v = np.arange(w_min, w_max, w_step), np.arange(w_min, w_max, w_step)\n",
    "U, V = np.meshgrid(u, v)\n",
    "\n",
    "U, V = U.astype(np.float32), V.astype(np.float32)\n",
    "\n",
    "nu, nv = u.shape[0], v.shape[0]\n",
    "losses, risks = np.zeros((nv, nu)), np.zeros((nv, nu))\n",
    "for i in range(nu):\n",
    "    for j in range(nv):\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            \n",
    "            # Set model weights\n",
    "            model[0].weight = torch.nn.Parameter(torch.tensor([[U[j, i], V[j, i]]]))\n",
    "            \n",
    "            # Train\n",
    "            y_pred = model(Xs)\n",
    "            losses[j, i] = loss_fn(y_pred, ys)\n",
    "            \n",
    "            # Test\n",
    "            yt_pred = model(Xt)\n",
    "            risks[j, i] = risk_fn(yt_pred, yt)\n",
    "\n",
    "            #MSE for weights?\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_DIR = \"../results/one_layer_results_l2\"\n",
    "\n",
    "sup = ''\n",
    "if args.transform_data:\n",
    "    RESULTS_DIR += \"/transform_data\"\n",
    "    sup = \"transformed_data\"\n",
    "\n",
    "def append_id(filename, id):\n",
    "    return \"{0}_{2}.{1}\".format(*filename.rsplit('.', 1) + [id])\n",
    "\n",
    "def get_run(lr1, lr2, batch_norm, uniform_noise=False, coupled_noise=None, ext=''):\n",
    "    file_path = os.path.join(RESULTS_DIR, f\"lr={lr1}_{lr2}.csv\")\n",
    "    if batch_norm:\n",
    "        file_path = append_id(file_path, \"batch_norm\") \n",
    "    elif uniform_noise:\n",
    "        file_path = append_id(file_path, \"uniform_noise\") \n",
    "\n",
    "    if coupled_noise is not None:\n",
    "        file_path = append_id(file_path, f\"coupled_noise_{coupled_noise}\") \n",
    "\n",
    "    file_path = append_id(file_path, ext)\n",
    "\n",
    "    data = pd.read_csv(file_path, header=None)\n",
    "    \n",
    "    return data[0], data[1], data[4], data[5] # This is a bit \"arbitrary\"\n",
    "    \n",
    "risk_sample, loss_sample, u_sample, v_sample = get_run(0.001, 0.001, batch_norm=False, uniform_noise=False, coupled_noise=None, ext='5.0_dim_2_samples_10_linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(10, 3))#, subplot_kw={\"projection\": \"3d\"})\n",
    "\n",
    "# Surfaces\n",
    "im1 = ax[0].imshow(losses)\n",
    "im2 = ax[1].imshow(risks)\n",
    "ax[0].plot()\n",
    "fig.colorbar(im1, ax=ax[0])\n",
    "fig.colorbar(im2, ax=ax[1])\n",
    "\n",
    "tick_step = int(nu / 4)\n",
    "for k in range(ax.shape[0]):\n",
    "    ax[k].set_xticks([i for i in range(nu + 1) if np.mod(i, tick_step) == 0])\n",
    "    ax[k].set_xticklabels([w_min + i * (w_max - w_min) / nu for i in range(nu + 1) if np.mod(i, tick_step) == 0])\n",
    "    ax[k].set_xlabel(\"u\")\n",
    "    \n",
    "    ax[k].set_yticks([i for i in range(nv + 1) if np.mod(i, tick_step) == 0])\n",
    "    ax[k].set_yticklabels([w_min + i * (w_max - w_min) / nu for i in range(nv + 1) if np.mod(i, tick_step) == 0])\n",
    "    ax[k].set_ylabel(\"v\")\n",
    "\n",
    "# Sampled path\n",
    "ax[0].plot((u_sample - w_min) * nu / (w_max - w_min), (v_sample - w_min) * nv / (w_max - w_min), '*', color='r', markersize=1)\n",
    "ax[1].plot((u_sample - w_min) * nu / (w_max - w_min), (v_sample - w_min) * nv / (w_max - w_min), '*', color='r', markersize=1)\n",
    "\n",
    "# Start\n",
    "ax[0].plot((u_sample[0] - w_min) * nu / (w_max - w_min), (v_sample[0] - w_min) * nv / (w_max - w_min), '*', color='g')\n",
    "ax[1].plot((u_sample[0] - w_min) * nu / (w_max - w_min), (v_sample[0] - w_min) * nv / (w_max - w_min), '*', color='g')\n",
    "\n",
    "# End\n",
    "ax[0].plot((u_sample[100000] - w_min) * nu / (w_max - w_min), (v_sample[100000] - w_min) * nv / (w_max - w_min), '*', color='r')\n",
    "ax[1].plot((u_sample[100000] - w_min) * nu / (w_max - w_min), (v_sample[100000] - w_min) * nv / (w_max - w_min), '*', color='r')\n",
    "    \n",
    "plt.savefig(\"../plots/one_layer_loss_surface_\" + sup + \"_seed_\" + str(args.seed))\n",
    "#surf = ax[0].plot_surface(U, V, losses, cmap=cm.coolwarm, linewidth=0, antialiased=False)\n",
    "#surf = ax[1].plot_surface(U, V, risks, cmap=cm.coolwarm, linewidth=0, antialiased=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.set_xscale('log')\n",
    "ax.plot(risk_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
