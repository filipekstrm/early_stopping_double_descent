{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High-dimensional dynamics of generalization error in neural networks\n",
    "\n",
    "Attempt to reproduce Figure 5B in the paper and reproduce double descent.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import datetime\n",
    "import pathlib\n",
    "import random\n",
    "import json\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append('../code/')\n",
    "from linear_utils import linear_model, get_modulation_matrix\n",
    "from train_utils import save_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# argument written in command line format\n",
    "# Mot-exempel ES-artikel (?)\n",
    "#cli_args = '--seed 12 --save-results --risk-loss L2 -t 200000 -w 0.1 0.001 --lr 0.00001 0.00001 -d 50 -n 100 --hidden 250 --sigmas 1 --kappa 10.0'\n",
    "cli_args = '--seed 12 --save-results --risk-loss L2 -t 100000 -w 0.01 0.01 --lr 0.001 0.001 -d 2 -n 10 --hidden 50 --sigmas 1 --kappa 10.0'\n",
    "sigma_noise = 1.0\n",
    "transform_data = True\n",
    "cont_eigs = False\n",
    "\n",
    "#cli_args = '--seed 12 --save-results --jacobian --risk-loss L2 -t 20000 -w 0.1 0.1 --lr 0.00001 -d 50 -n 1000 --hidden 50 --sigmas 1 --kappa 3'\n",
    "#sigma_noise = 1.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# get CLI parameters\n",
    "parser = argparse.ArgumentParser(description='CLI parameters for training')\n",
    "parser.add_argument('--root', type=str, default='', metavar='DIR',\n",
    "                    help='Root directory')\n",
    "parser.add_argument('-t', '--iterations', type=int, default=1e4, metavar='ITERATIONS',\n",
    "                    help='Iterations (default: 1e4)')\n",
    "parser.add_argument('-n', '--samples', type=int, default=100, metavar='N',\n",
    "                    help='Number of samples (default: 100)')\n",
    "parser.add_argument('--print-freq', type=int, default=1000,\n",
    "                    help='CLI output printing frequency (default: 1000)')\n",
    "parser.add_argument('--gpu', type=int, default=None,\n",
    "                    help='Number of GPUS to use')\n",
    "parser.add_argument('--seed', type=int, default=None,\n",
    "                    help='Random seed')                        \n",
    "parser.add_argument('-d', '--dim', type=int, default=50, metavar='DIMENSION',\n",
    "                    help='Feature dimension (default: 50)')\n",
    "parser.add_argument('--hidden', type=int, default=200, metavar='DIMENSION',\n",
    "                    help='Hidden layer dimension (default: 200)')\n",
    "parser.add_argument('--sigmas', type=str, default=None,\n",
    "                    help='Sigmas')     \n",
    "parser.add_argument('-r','--s-range', nargs='*', type=float,\n",
    "                    help='Range for sigmas')\n",
    "parser.add_argument('--kappa', type=float,\n",
    "                    help='Eigenvalue ratio')\n",
    "parser.add_argument('-w','--scales', nargs='*', type=float,\n",
    "                    help='scale of the weights')\n",
    "parser.add_argument('--lr', type=float, default=1e-4, nargs='*', metavar='LR',\n",
    "                    help='learning rate (default: 1e-4)')              \n",
    "parser.add_argument('--normalized', action='store_true', default=False,\n",
    "                    help='normalize sample norm across features')\n",
    "parser.add_argument('--risk-loss', type=str, default='MSE', metavar='LOSS',\n",
    "                    help='Loss for validation')\n",
    "parser.add_argument('--jacobian', action='store_true', default=False,\n",
    "                    help='compute the SVD of the jacobian of the network')\n",
    "parser.add_argument('--save-results', action='store_true', default=False,\n",
    "                    help='Save the results for plots')\n",
    "parser.add_argument('--details', type=str, metavar='N',\n",
    "                    default='no_detail_given',\n",
    "                    help='details about the experimental setup')\n",
    "\n",
    "\n",
    "args = parser.parse_args(cli_args.split())\n",
    "\n",
    "# directories\n",
    "root = pathlib.Path(args.root) if args.root else pathlib.Path.cwd().parent\n",
    "\n",
    "current_date = str(datetime.datetime.today().strftime('%Y-%m-%d-%H-%M-%S'))\n",
    "args.outpath = (pathlib.Path.cwd().parent / 'results' / 'two_layer_nn' /  current_date)\n",
    "\n",
    "if args.save_results:\n",
    "    args.outpath.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "if args.seed is not None:\n",
    "    random.seed(args.seed)\n",
    "    torch.manual_seed(args.seed)\n",
    "    np.random.seed(args.seed)\n",
    "    \n",
    "device = torch.device('cpu')\n",
    "# device = torch.device('cuda') # Uncomment this to run on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_jacobian_two_layer(X, y, model, crit):\n",
    "    \n",
    "    grads = []\n",
    "    for cx, cy in zip(X, y):\n",
    "\n",
    "        cur_grads = []\n",
    "        model.zero_grad()\n",
    "        co = model(cx)\n",
    "        co.backward(torch.ones(len(cy)))\n",
    "\n",
    "        for p in model.parameters():\n",
    "            if p.grad is not None and len(p.data.shape)>1:\n",
    "                cur_grads.append(p.grad.data.numpy().flatten())\n",
    "        grads.append(np.concatenate(cur_grads))\n",
    "    return np.array(grads)\n",
    "\n",
    "\n",
    "def compute_jacobian(Xs, ys, model, loss_fn, args):\n",
    "    J = get_jacobian_two_layer(Xs, ys, model, loss_fn)\n",
    "    uv, sv, vtv = np.linalg.svd(J)\n",
    "\n",
    "    v1 = []\n",
    "    v2 = []\n",
    "    for i in range(sv.shape[0]):\n",
    "        v1.append(np.linalg.norm(vtv[i,:][:np.prod([args.hidden, args.dim])]))\n",
    "        v2.append(np.linalg.norm(vtv[i,:][-np.prod([1, args.hidden]):]))\n",
    "    v1 = np.array(v1)\n",
    "    v2 = np.array(v2)\n",
    "    vTrec = np.linalg.norm(np.stack((v1, v2)), axis=0)\n",
    "\n",
    "\n",
    "    return sv, v1, v2, vTrec\n",
    "\n",
    "\n",
    "def plot_jacobian(sv, v1, v2, vTrec):\n",
    "    weights = [{'w': 0.01, 'v': 1}, {'w': 1, 'v': 1}, {'w': 1, 'v': 0.01}]\n",
    "    cmap = matplotlib.cm.get_cmap('viridis')\n",
    "    colorList = [cmap(50/1000), cmap(350/1000), cmap(650/1000)]\n",
    "    labelList = [r'$W$', r'$v$', r'$W + v$']\n",
    "\n",
    "    fig = plt.figure(figsize=(12,8))\n",
    "\n",
    "    ax_list = [plt.subplot(111)]\n",
    "\n",
    "    ax_list[0].scatter(sv, v1, \n",
    "                    color=colorList[0], \n",
    "                    label=labelList[0],\n",
    "                    lw=4)\n",
    "    ax_list[0].scatter(sv, v2, \n",
    "                    color=colorList[1], \n",
    "                    label=labelList[1],\n",
    "    #                 ls='dashed',\n",
    "                    lw=4)\n",
    "    ax_list[0].scatter(sv, vTrec, \n",
    "                    color=colorList[2], \n",
    "                    label=labelList[2],\n",
    "    #                 ls='dashed',\n",
    "                    lw=2)\n",
    "\n",
    "    ax_list[-1].legend(loc=0, bbox_to_anchor=(1, 0.5), fontsize='x-large',\n",
    "                       frameon=True, fancybox=True, shadow=True, ncol=1)\n",
    "    ax_list[0].set_ylabel(r'$\\Vert v \\Vert_2^2$')\n",
    "\n",
    "    # for i, ax in enumerate(ax_list): ax.set_title(r'$w = $' + str(weights[i]['w']) + \n",
    "    #                                               r';$v = $' + str(weights[i]['v']))\n",
    "    for ax in ax_list: ax.set_xlabel(r'$\\sigma_i$')\n",
    "    for ax in ax_list: ax.set_xscale('log')\n",
    "    for ax in ax_list: ax.set_yscale('log')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_eigs = 0 if args.samples >= args.dim else (args.dim - args.samples)\n",
    "p = int(np.ceil((args.dim - zero_eigs) / 2))\n",
    "#k = args.kappa\n",
    "#F = get_modulation_matrix(args.dim, p, k)\n",
    "\n",
    "beta = np.ones((args.dim,))# * 0.01\n",
    "#beta[1] *= -1.0\n",
    "print(beta)\n",
    "\n",
    "# Set to False if you want to transform after data sampling\n",
    "scale_beta = False\n",
    "\n",
    "d_out = 1      # dimension of y\n",
    "\n",
    "# sample training set from the linear model\n",
    "lin_model = linear_model(args.dim, sigma_noise=sigma_noise, beta=beta, scale_beta=scale_beta, normalized=False, sigmas=args.sigmas, s_range=args.s_range, coupled_noise=False, transform_data=transform_data, kappa=args.kappa, p=p, cont_eigs=cont_eigs, zero_eigs=zero_eigs)\n",
    "Xs, ys = lin_model.sample(args.samples, train=True)\n",
    "\n",
    "# sample the set for empirical risk calculation\n",
    "Xt, yt = lin_model.sample(args.samples * 100, train=False) # 1000\n",
    "beta = lin_model.beta.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Xt = (Xt - Xs.mean(axis=0)) / Xs.std(axis=0)\n",
    "Xs = (Xs - Xs.mean(axis=0)) / Xs.std(axis=0)\n",
    "\n",
    "U, S, Vh = np.linalg.svd(Xs)\n",
    "print(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform data (masking)\n",
    "\n",
    "\n",
    "# Uncomment if you want to transform after data sampling\n",
    "#Xs = Xs @ F\n",
    "#Xt = Xt @ F\n",
    "\n",
    "#_, Ss, Vh = np.linalg.svd(Xs)\n",
    "#_, St, _ = np.linalg.svd(np.transpose(Xt) @ Xt)\n",
    "\n",
    "#print(\"train\")\n",
    "#print(Ss)\n",
    "#print(\"test\")\n",
    "#print(St)\n",
    "\n",
    "# Uncomment if you transform_data=False, but you want to decouple features\n",
    "#Xs = Xs @ np.transpose(Vh)\n",
    "#Xt = Xt @ np.transpose(Vh)\n",
    "\n",
    "#beta = np.linalg.inv(F) @ beta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, Sxy, _ = np.linalg.svd(ys.T@Xs)\n",
    "print(Sxy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs = torch.tensor(Xs, dtype=torch.float32).to(device)\n",
    "ys = torch.tensor(ys.reshape((-1,1)), dtype=torch.float32).to(device)\n",
    "\n",
    "Xt = torch.tensor(Xt, dtype=torch.float32).to(device)\n",
    "yt = torch.tensor(yt.reshape((-1,1)), dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss functions\n",
    "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "risk_fn = torch.nn.L1Loss(reduction='sum') if args.risk_loss == 'L1' else torch.nn.MSELoss(reduction='sum')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Empirical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(\n",
    "           torch.nn.Linear(args.dim, args.hidden, bias=False),\n",
    "           #torch.nn.ReLU(),\n",
    "           torch.nn.Linear(args.hidden, d_out, bias=False),\n",
    "         ).to(device)      \n",
    " \n",
    "\n",
    "fixed_init = True\n",
    "scale_factor = 1.0\n",
    "\n",
    "if args.scales:\n",
    "    i = 0\n",
    "    with torch.no_grad():\n",
    "        for m in model:\n",
    "            if type(m) == torch.nn.Linear:\n",
    "                if i == 0:\n",
    "                    if fixed_init:\n",
    "                        m.weight.data = torch.ones(m.weight.data.shape) * args.scales[0] \n",
    "                        m.weight.data[:, p:] = m.weight.data[:, p:] * scale_factor\n",
    "                    else:\n",
    "                        torch.nn.init.kaiming_normal_(m.weight, a=math.sqrt(5))\n",
    "                        m.weight.data = torch.mul(m.weight.data, args.scales[0])\n",
    "                if i == 1:\n",
    "                    if fixed_init:\n",
    "                        m.weight.data = torch.ones(m.weight.data.shape) * args.scales[1]\n",
    "                    else:\n",
    "                        torch.nn.init.kaiming_uniform_(m.weight, a=math.sqrt(5))\n",
    "                        m.weight.data = torch.mul(m.weight.data, args.scales[1])\n",
    "                i += 1\n",
    "                \n",
    "\n",
    "# use same learning rate for the two layers\n",
    "#if isinstance(args.lr, list):\n",
    "#    stepsize = [max(args.lr)] * 2\n",
    "stepsize = args.lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model[0].weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Zs = torch.nn.ReLU()(Xs @ torch.transpose(model[0].weight.data, 0, 1))\n",
    "plt.plot(Zs, '*')\n",
    "plt.show()\n",
    "\n",
    "print(Zs.shape)\n",
    "\n",
    "_, S, _ = np.linalg.svd(Zs)\n",
    "print(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if args.samples >= args.dim:\n",
    "    w_min = np.linalg.solve(np.transpose(Xs)@Xs, np.transpose(Xs)@ys).squeeze()\n",
    "else:\n",
    "    w_min = (np.transpose(Xs)@np.linalg.inv(Xs@np.transpose(Xs))@ys).squeeze()\n",
    "    \n",
    "print(w_min)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U, S, Vh= np.linalg.svd(Xs)\n",
    "plt.plot(S, torch.norm(model[0].weight.data @ np.transpose(Vh), dim=0), '*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Uz, Sz, Vzh = np.linalg.svd(Zs)\n",
    "plt.plot(np.concatenate((Sz, np.zeros((int(Zs.shape[-1] - Sz.shape[0]),)))), \n",
    "         torch.norm(model[2].weight.data @ np.transpose(Vzh), dim=0), '*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sv, v1, v2, vTrec = compute_jacobian(Xs, ys, model, loss_fn, args)\n",
    "plot_jacobian(sv, v1, v2, vTrec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the network\n",
    "losses_emp = []\n",
    "risks_emp = []\n",
    "mse_weights_emp = []\n",
    "weight_norms_emp = []\n",
    "for t in range(int(args.iterations)):\n",
    "    y_pred = model(Xs)\n",
    "\n",
    "    loss = loss_fn(y_pred, ys)\n",
    "    losses_emp.append(loss.item())\n",
    "\n",
    "    if not t % args.print_freq:\n",
    "        print(t, loss.item())\n",
    "        \n",
    "    if t in []:#0, 100, 1000, 10000]: #, 1000, 1500, 3000, 4500, 7500, 13000, 20000, 35000, 60000]:\n",
    "        print(fr\"Eigenvalue association at iteration {t}:\")\n",
    "        sv, v1, v2, vTrec = compute_jacobian(Xs, ys, model, loss_fn, args)\n",
    "        plot_jacobian(sv, v1, v2, vTrec)\n",
    "        \n",
    "    if t in []:#[0, 10, 100, 1000, 10000, 50000, 100000, 150000]:\n",
    "        print(\"Connection first layer - input:\")\n",
    "        U, S, Vh = np.linalg.svd(Xs)\n",
    "        plt.plot(np.concatenate((S, np.zeros((int(Xs.shape[-1] - S.shape[0]),)))), \n",
    "         torch.norm(model[0].weight.data @ np.transpose(Vh), dim=0), '*')\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"Connection second layer - latent repr.:\")\n",
    "        Zs = torch.nn.ReLU()(Xs @ torch.transpose(model[0].weight.data, 0, 1))\n",
    "        Uz, Sz, Vzh = np.linalg.svd(Zs)\n",
    "        plt.plot(np.concatenate((Sz, np.zeros((int(Zs.shape[-1] - Sz.shape[0]),)))), \n",
    "         torch.norm(model[2].weight.data @ np.transpose(Vzh), dim=0), '*')\n",
    "        plt.show()\n",
    "\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        i = 0\n",
    "        w_tot = torch.diag(torch.ones(args.dim)) #[]\n",
    "        weight_norms_it = []\n",
    "        for param in model.parameters():\n",
    "            param.data -= stepsize[i] * param.grad\n",
    "            #w_tot.append(param.data.t().numpy().copy().reshape(1, -1)) #\n",
    "            w_tot = w_tot @ param.data.t()\n",
    "            \n",
    "            if len(param.shape) > 1:\n",
    "                weight_norms_it.append(float(torch.norm(param.data.flatten())))\n",
    "                \n",
    "                if i == 0:\n",
    "                    weight_norms_it.append(float(torch.norm(param.data[:, :p].flatten())))\n",
    "                    weight_norms_it.append(float(torch.norm(param.data[:, p:].flatten())))\n",
    "\n",
    "                \n",
    "                i += 1\n",
    "                \n",
    "        weight_norms_emp.append(weight_norms_it)\n",
    "                \n",
    "        #w_tot = np.column_stack(w_tot)\n",
    "        w_tot = w_tot.squeeze()\n",
    "        assert w_tot.shape == beta.shape\n",
    "        mse_weights_emp.append(((w_tot.numpy()-beta) / beta)**2) #w_tot\n",
    "                \n",
    "            \n",
    "    with torch.no_grad():\n",
    "        yt_pred = model(Xt)\n",
    "        \n",
    "        risk = risk_fn(yt_pred, yt)\n",
    "        risks_emp.append(risk.item())\n",
    "\n",
    "        if not t % args.print_freq:\n",
    "            print(t, risk.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sv, v1, v2, vTrec = compute_jacobian(Xs, ys, model, loss_fn, args)\n",
    "plot_jacobian(sv, v1, v2, vTrec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U, S, Vh = np.linalg.svd(Xs)\n",
    "plt.plot(np.concatenate((S, np.zeros((int(Xs.shape[-1] - S.shape[0]),)))), \n",
    " torch.norm(model[0].weight.data @ np.transpose(Vh), dim=0), '*')\n",
    "plt.show()\n",
    "\n",
    "Zs = torch.nn.ReLU()(Xs @ torch.transpose(model[0].weight.data, 0, 1))\n",
    "Uz, Sz, Vzh = np.linalg.svd(Zs)\n",
    "plt.plot(np.concatenate((Sz, np.zeros((int(Zs.shape[-1] - Sz.shape[0]),)))), \n",
    " torch.norm(model[2].weight.data @ np.transpose(Vzh), dim=0), '*')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_samples = [int(i) for i in np.geomspace(1, args.iterations-1, num=700)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "risks = np.array(risks_emp)\n",
    "losses = np.array(losses_emp)\n",
    "risks_w = np.row_stack(mse_weights_emp)\n",
    "weight_norms = np.row_stack(weight_norms_emp)\n",
    "\n",
    "cmap = matplotlib.cm.get_cmap('viridis')\n",
    "colorList = [cmap(50/1000), cmap(350/1000), cmap(700/1000)]\n",
    "labelList = ['empirical', 'theoretical']\n",
    "\n",
    "plot_all_dims = False\n",
    "\n",
    "extra_axs = 0\n",
    "if plot_all_dims:\n",
    "    extra_axs = risks_w.shape[-1] #args.dim\n",
    "\n",
    "num_axs = 5 + extra_axs\n",
    "fig, ax = plt.subplots(num_axs, 1, figsize=(16, 4 * num_axs))\n",
    "\n",
    "ax[0].set_xscale('log')\n",
    "ax[0].plot(geo_samples, risks[geo_samples], \n",
    "        color=colorList[1], \n",
    "        label=labelList[0],\n",
    "        lw=4)\n",
    "\n",
    "ax[0].legend(loc=1, bbox_to_anchor=(1, 1), fontsize='x-large',\n",
    "    frameon=False, fancybox=True, shadow=True, ncol=1)\n",
    "ax[0].set_ylabel('risk')\n",
    "ax[0].set_xlabel(r'$t$ iterations')\n",
    "\n",
    "ax[1].set_xscale('log')\n",
    "ax[1].plot(geo_samples, losses[geo_samples], \n",
    "        color=colorList[1], \n",
    "        label=labelList[0],\n",
    "        lw=4)\n",
    "\n",
    "ax[1].set_ylabel('loss')\n",
    "ax[1].set_xlabel(r'$t$ iterations')\n",
    "\n",
    "if plot_all_dims:\n",
    "    for i in range(risks_w.shape[-1]):\n",
    "        ax[2+i].set_xscale('log')\n",
    "        ax[2+i].plot(geo_samples, risks_w[geo_samples, i], \n",
    "                color=colorList[2], \n",
    "                label=labelList[0],\n",
    "                lw=4)\n",
    "\n",
    "        ax[2+i].set_ylabel('MSE weights, ' + str(i))\n",
    "        ax[2+i].set_xlabel(r'$t$ iterations')\n",
    "\n",
    "\n",
    "ax[-3].set_ylabel('Weight norm') # (SCALED BY INIT!)\n",
    "ax[-3].set_xlabel(r'$t$ iterations')\n",
    "\n",
    "ax[-3].set_xscale('log')\n",
    "ax[-3].plot(geo_samples, weight_norms[geo_samples, 0], # / weight_norms[0, 0], \n",
    "        color=colorList[1], \n",
    "        label=\"Layer 1\",\n",
    "        lw=4)\n",
    "\n",
    "ax[-3].plot(geo_samples, weight_norms[geo_samples, 3], # / weight_norms[0, 3], \n",
    "        color=colorList[2], \n",
    "        label=\"Layer 2\",\n",
    "        lw=4)\n",
    "\n",
    "ax[-3].legend()\n",
    "\n",
    "\n",
    "ax[-2].set_ylabel('Weight norm') # (SCALED BY INIT!)\n",
    "ax[-2].set_xlabel(r'$t$ iterations')\n",
    "\n",
    "ax[-2].set_xscale('log')\n",
    "ax[-2].plot(geo_samples, weight_norms[geo_samples, 0], # / weight_norms[0, 0], \n",
    "        color=colorList[1], \n",
    "        label=\"Layer 1\",\n",
    "        lw=4)\n",
    "\n",
    "ax[-2].plot(geo_samples, weight_norms[geo_samples, 1], # / weight_norms[0, 1], \n",
    "        color=colorList[0], \n",
    "        label=\"Layer 1, large\",\n",
    "        lw=4)\n",
    "\n",
    "ax[-2].plot(geo_samples, weight_norms[geo_samples, 2], # / weight_norms[0, 2], \n",
    "        color=colorList[2], \n",
    "        label=\"Layer 1, small\",\n",
    "        lw=4)\n",
    "\n",
    "ax[-2].legend()\n",
    "\n",
    "\n",
    "ax[-1].plot(geo_samples, risks_w[geo_samples, :].mean(axis=-1), \n",
    "        color=colorList[2], \n",
    "        label=labelList[0],\n",
    "        lw=4)\n",
    "\n",
    "ax[-1].set_ylabel('MSE weights')\n",
    "ax[-1].set_xlabel(r'$t$ iterations')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "risks = np.array(risks_emp)\n",
    "losses = np.array(losses_emp)\n",
    "risks_w = np.row_stack(mse_weights_emp)\n",
    "\n",
    "cmap = matplotlib.cm.get_cmap('viridis')\n",
    "colorList = [cmap(50/1000), cmap(350/1000), cmap(700/1000)]\n",
    "labelList = ['empirical', 'theoretical']\n",
    "\n",
    "extra_axs = 2\n",
    "fig, ax = plt.subplots(3 + extra_axs, 1, figsize=(12,12 + 4 * extra_axs))\n",
    "\n",
    "ax[0].set_xscale('log')\n",
    "ax[0].plot(geo_samples, risks[geo_samples], \n",
    "        color=colorList[1], \n",
    "        label=labelList[0],\n",
    "        lw=4)\n",
    "\n",
    "ax[0].legend(loc=1, bbox_to_anchor=(1, 1), fontsize='x-large',\n",
    "    frameon=False, fancybox=True, shadow=True, ncol=1)\n",
    "ax[0].set_ylabel('risk')\n",
    "ax[0].set_xlabel(r'$t$ iterations')\n",
    "\n",
    "ax[1].set_xscale('log')\n",
    "ax[1].plot(geo_samples, losses[geo_samples], \n",
    "        color=colorList[1], \n",
    "        label=labelList[0],\n",
    "        lw=4)\n",
    "\n",
    "ax[1].set_ylabel('loss')\n",
    "ax[1].set_xlabel(r'$t$ iterations')\n",
    "\n",
    "p = int(args.dim / 2)\n",
    "ax[2].set_xscale('log')\n",
    "ax[2].plot(geo_samples, risks_w[geo_samples, :p].mean(axis=-1), \n",
    "        color=colorList[2], \n",
    "        label=labelList[0],\n",
    "        lw=4)\n",
    "\n",
    "ax[2].set_ylabel('MSE weights, large')\n",
    "ax[2].set_xlabel(r'$t$ iterations')\n",
    "\n",
    "ax[3].set_xscale('log')\n",
    "ax[3].plot(geo_samples, risks_w[geo_samples, p:].mean(axis=-1), \n",
    "        color=colorList[2], \n",
    "        label=labelList[0],\n",
    "        lw=4)\n",
    "\n",
    "ax[3].set_ylabel('MSE weights, small')\n",
    "ax[3].set_xlabel(r'$t$ iterations')\n",
    "\n",
    "\n",
    "ax[-1].set_xscale('log')\n",
    "ax[-1].plot(geo_samples, risks_w[geo_samples, :].mean(axis=-1), \n",
    "        color=colorList[2], \n",
    "        label=labelList[0],\n",
    "        lw=4)\n",
    "\n",
    "ax[-1].set_ylabel('MSE weights')\n",
    "ax[-1].set_xlabel(r'$t$ iterations')\n",
    "\n",
    "\n",
    "#ax[0].set_ylim([9, 13])\n",
    "#ax[1].set_ylim([80, 105])\n",
    "#ax[2].set_ylim([1, 2.55])\n",
    "#ax[3].set_ylim([0.35, 1.05])\n",
    "#ax[4].set_ylim([0.9, 1.6])\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax  = plt.subplots()\n",
    "\n",
    "min_x, max_x = 3000, 10000-1\n",
    "plt.plot(np.arange(min_x, max_x), risks[min_x:max_x])\n",
    "print(risks.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 1, figsize=(5, 15))\n",
    "\n",
    "ax[0].plot(np.arange(min_x, max_x), weight_norms[min_x:max_x, 0])\n",
    "ax[1].plot(np.arange(min_x, max_x), risks[min_x:max_x])\n",
    "ax[2].plot(np.arange(min_x, max_x), losses[min_x:max_x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Empirical, one rank init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_one_init(model, g_cpu, args):\n",
    "    i = 0\n",
    "    with torch.no_grad(): \n",
    "        p, q, u = 0, 0, 0\n",
    "        for m in model:\n",
    "            if type(m) == torch.nn.Linear:\n",
    "                                \n",
    "                if i == 0:\n",
    "                    #q = torch.ones((m.weight.data.shape[1], 1)) * args.scales[0] \n",
    "                    q = torch.normal(mean=0, std=args.scales[0], size=(m.weight.data.shape[1], 1), generator=g_cpu)\n",
    "                    z = q.clone()\n",
    "                    u = 1\n",
    "                else:\n",
    "                    q = p.clone()\n",
    "                    \n",
    "                    if i == 1:\n",
    "                        #u = torch.tensor(args.scales[1])\n",
    "                        u = torch.normal(mean=0, std=args.scales[1], size=(), generator=g_cpu)\n",
    "                    \n",
    "                p = torch.normal(mean=0, std=1, size=(m.weight.data.shape[0], 1), generator=g_cpu)\n",
    "                p /= torch.norm(p, dim=0) # = (-)1 for last layer\n",
    "\n",
    "                m.weight.data = u * torch.matmul(p, q.T)\n",
    "               \n",
    "                i += 1\n",
    "   \n",
    "    return model, u.clone(), z "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(\n",
    "           torch.nn.Linear(args.dim, args.hidden, bias=False),\n",
    "           #torch.nn.ReLU(),\n",
    "           torch.nn.Linear(args.hidden, d_out, bias=False),\n",
    "         ).to(device)      \n",
    "                \n",
    "# use rank one initialization \n",
    "g_cpu = torch.Generator()\n",
    "g_cpu.manual_seed(args.seed)\n",
    "model, u_init, z_init = rank_one_init(model, g_cpu, args)\n",
    " \n",
    "print(u_init)\n",
    "print(z_init)\n",
    "\n",
    "# use same learning rate for the two layers\n",
    "#if isinstance(args.lr, list):\n",
    "#    stepsize = [max(args.lr)] * 2\n",
    "stepsize = args.lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Wtot = torch.diag(torch.ones(args.dim))\n",
    "for param in model.parameters():\n",
    "    if len(param.shape) > 1:\n",
    "        Wtot = Wtot @ param.data.t()\n",
    "        \n",
    "print(Wtot)\n",
    "print(u_init * z_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the network\n",
    "losses_emp = []\n",
    "risks_emp = []\n",
    "mse_weights_emp = []\n",
    "grad_norms_emp = []\n",
    "weights_rank = []\n",
    "for t in range(int(args.iterations)):\n",
    "    y_pred = model(Xs)\n",
    "\n",
    "    loss = loss_fn(y_pred, ys)\n",
    "    losses_emp.append(loss.item())\n",
    "\n",
    "    if not t % args.print_freq:\n",
    "        print(t, loss.item())\n",
    "        \n",
    "    if not t % 1000 and t <= 10000:\n",
    "        print(fr\"Eigenvalue association at iteration {t}:\")\n",
    "        sv, v1, v2, vTrec = compute_jacobian(Xs, ys, model, loss_fn)\n",
    "        plot_jacobian(sv, v1, v2, vTrec)\n",
    "    \n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "    \n",
    "    grad_norms_it = []\n",
    "    weights_rank_it = []\n",
    "    with torch.no_grad():\n",
    "        i = 0\n",
    "        w_tot = torch.diag(torch.ones(args.dim)) #[]\n",
    "        for param in model.parameters():\n",
    "            \n",
    "            if len(param.shape) > 1:\n",
    "                grad_norms_it.append(float(torch.norm(param.grad.flatten())))\n",
    "            \n",
    "            weights_rank_it.append(torch.linalg.matrix_rank(param.data))\n",
    "                \n",
    "            param.data -= stepsize[i] * param.grad\n",
    "            #w_tot.append(param.data.t().numpy().copy().reshape(1, -1)) #\n",
    "            w_tot = w_tot @ param.data.t()\n",
    "            \n",
    "            if len(param.shape) > 1:\n",
    "                i += 1\n",
    "                \n",
    "        grad_norms_emp.append(grad_norms_it)\n",
    "        weights_rank.append(weights_rank_it)\n",
    "        \n",
    "        #w_tot = np.column_stack(w_tot)\n",
    "        w_tot = w_tot.squeeze()\n",
    "        assert w_tot.shape == beta.shape\n",
    "        mse_weights_emp.append(((w_tot-beta.squeeze()) / beta)**2) #w_tot\n",
    "                \n",
    "            \n",
    "    with torch.no_grad():\n",
    "        yt_pred = model(Xt)\n",
    "        \n",
    "        risk = risk_fn(yt_pred, yt)\n",
    "        risks_emp.append(risk.item())\n",
    "\n",
    "        if not t % args.print_freq:\n",
    "            print(t, risk.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_samples = [int(i) for i in np.geomspace(1, len(risks_emp)-1, num=700)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "risks = np.array(risks_emp)\n",
    "losses = np.array(losses_emp)\n",
    "risks_w = np.row_stack(mse_weights_emp)\n",
    "grad_norms = np.row_stack(grad_norms_emp)\n",
    "print(grad_norms[0])\n",
    "weights_rank = np.row_stack(weights_rank)\n",
    "\n",
    "cmap = matplotlib.cm.get_cmap('viridis')\n",
    "colorList = [cmap(50/1000), cmap(350/1000), cmap(700/1000)]\n",
    "labelList = ['empirical', 'theoretical']\n",
    "\n",
    "plot_all_dims = False\n",
    "\n",
    "extra_axs = 0\n",
    "if plot_all_dims:\n",
    "    extra_axs = risks_w.shape[-1] #args.dim\n",
    "\n",
    "fig, ax = plt.subplots(5 + extra_axs, 1, figsize=(12,20 + 4 * extra_axs))\n",
    "\n",
    "ax[0].set_xscale('log')\n",
    "ax[0].plot(geo_samples, risks[geo_samples], \n",
    "        color=colorList[1], \n",
    "        label=labelList[0],\n",
    "        lw=4)\n",
    "\n",
    "ax[0].legend(loc=1, bbox_to_anchor=(1, 1), fontsize='x-large',\n",
    "    frameon=False, fancybox=True, shadow=True, ncol=1)\n",
    "ax[0].set_ylabel('risk')\n",
    "ax[0].set_xlabel(r'$t$ iterations')\n",
    "\n",
    "ax[1].set_xscale('log')\n",
    "ax[1].plot(geo_samples, losses[geo_samples], \n",
    "        color=colorList[1], \n",
    "        label=labelList[0],\n",
    "        lw=4)\n",
    "\n",
    "ax[1].set_ylabel('loss')\n",
    "ax[1].set_xlabel(r'$t$ iterations')\n",
    "\n",
    "ax[2].set_xscale('log')\n",
    "\n",
    "for i in range(grad_norms.shape[-1]):\n",
    "    ax[2].plot(geo_samples, grad_norms[geo_samples, i], \n",
    "            color=colorList[1], \n",
    "            label=labelList[0],\n",
    "            lw=4)\n",
    "\n",
    "ax[2].set_ylabel('gradient norms')\n",
    "ax[2].set_xlabel(r'$t$ iterations')\n",
    "\n",
    "if plot_all_dims:\n",
    "    for i in range(risks_w.shape[-1]):\n",
    "        ax[3+i].set_xscale('log')\n",
    "        ax[3+i].plot(geo_samples, risks_w[geo_samples, i], \n",
    "                color=colorList[2], \n",
    "                label=labelList[0],\n",
    "                lw=4)\n",
    "\n",
    "        ax[3+i].set_ylabel('MSE weights, ' + str(i))\n",
    "        ax[3+i].set_xlabel(r'$t$ iterations')\n",
    "\n",
    "\n",
    "ax[-2].set_xscale('log')\n",
    "ax[-2].plot(geo_samples, risks_w[geo_samples, :].mean(axis=-1), \n",
    "        color=colorList[2], \n",
    "        label=labelList[0],\n",
    "        lw=4)\n",
    "\n",
    "ax[-2].set_ylabel('MSE weights')\n",
    "ax[-2].set_xlabel(r'$t$ iterations')\n",
    "\n",
    "ax[-1].set_xscale('log')\n",
    "\n",
    "for i in range(weights_rank.shape[-1]):\n",
    "    ax[-1].plot(geo_samples, weights_rank[geo_samples, i], \n",
    "            color=colorList[i], \n",
    "            label=labelList[0],\n",
    "            lw=4)\n",
    "\n",
    "ax[-1].set_ylabel('rank of weights')\n",
    "ax[-1].set_xlabel(r'$t$ iterations')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(weights_rank[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "risks = np.array(risks_emp)\n",
    "losses = np.array(losses_emp)\n",
    "risks_w = np.row_stack(mse_weights_emp)\n",
    "\n",
    "cmap = matplotlib.cm.get_cmap('viridis')\n",
    "colorList = [cmap(50/1000), cmap(350/1000), cmap(700/1000)]\n",
    "labelList = ['empirical', 'theoretical']\n",
    "\n",
    "extra_axs = 2\n",
    "fig, ax = plt.subplots(3 + extra_axs, 1, figsize=(12, 12 + 4 * extra_axs))\n",
    "\n",
    "ax[0].set_xscale('log')\n",
    "ax[0].plot(geo_samples, risks[geo_samples], \n",
    "        color=colorList[1], \n",
    "        label=labelList[0],\n",
    "        lw=4)\n",
    "\n",
    "ax[0].legend(loc=1, bbox_to_anchor=(1, 1), fontsize='x-large',\n",
    "    frameon=False, fancybox=True, shadow=True, ncol=1)\n",
    "ax[0].set_ylabel('risk')\n",
    "ax[0].set_xlabel(r'$t$ iterations')\n",
    "\n",
    "ax[1].set_xscale('log')\n",
    "ax[1].plot(geo_samples, losses[geo_samples], \n",
    "        color=colorList[1], \n",
    "        label=labelList[0],\n",
    "        lw=4)\n",
    "\n",
    "ax[1].set_ylabel('loss')\n",
    "ax[1].set_xlabel(r'$t$ iterations')\n",
    "\n",
    "p = int(args.dim / 2)\n",
    "ax[2].set_xscale('log')\n",
    "ax[2].plot(geo_samples, risks_w[geo_samples, :p].mean(axis=-1), \n",
    "        color=colorList[2], \n",
    "        label=labelList[0],\n",
    "        lw=4)\n",
    "\n",
    "ax[2].set_ylabel('MSE weights, large')\n",
    "ax[2].set_xlabel(r'$t$ iterations')\n",
    "\n",
    "ax[3].set_xscale('log')\n",
    "ax[3].plot(geo_samples, risks_w[geo_samples, p:].mean(axis=-1), \n",
    "        color=colorList[2], \n",
    "        label=labelList[0],\n",
    "        lw=4)\n",
    "\n",
    "ax[3].set_ylabel('MSE weights, small')\n",
    "ax[3].set_xlabel(r'$t$ iterations')\n",
    "\n",
    "\n",
    "ax[-1].set_xscale('log')\n",
    "ax[-1].plot(geo_samples, risks_w[geo_samples, :].mean(axis=-1), \n",
    "        color=colorList[2], \n",
    "        label=labelList[0],\n",
    "        lw=4)\n",
    "\n",
    "ax[-1].set_ylabel('MSE weights')\n",
    "ax[-1].set_xlabel(r'$t$ iterations')\n",
    "\n",
    "\n",
    "#ax[0].set_ylim([9, 13])\n",
    "#ax[1].set_ylim([80, 105])\n",
    "#ax[2].set_ylim([1, 2.55])\n",
    "#ax[3].set_ylim([0.35, 1.05])\n",
    "#ax[4].set_ylim([0.9, 1.6])\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theoretical "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With actual input data\n",
    "def dt(u, z, S, St):\n",
    "    assert S.shape == z.shape\n",
    "    return (St - u * z * S)\n",
    "\n",
    "\n",
    "def dzdt(u, z, S, St):\n",
    "    return 2 * u * dt(u, z, S, St)\n",
    "\n",
    "\n",
    "def dudt(u, z, S, St):\n",
    "    return 2 * (dt(u, z, S, St) @ z.T).squeeze()\n",
    "\n",
    "\n",
    "# Sampling only noise in output (and assuming that we know the true weights)\n",
    "def dt_s(u, z, S, beta, eps):\n",
    "    assert S.shape == z.shape\n",
    "    return (beta - u * z) * S + eps * S**0.5\n",
    "\n",
    "\n",
    "def dzdt_s(u, z, S, beta, eps):\n",
    "    return 2 * u * dt_s(u, z, S, beta, eps)\n",
    "\n",
    "\n",
    "def dudt_s(u, z, S, beta, eps):\n",
    "    return 2 * (dt_s(u, z, S, beta, eps) @ z.T).squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the sake of not messing anything up\n",
    "Xs_t, ys_t, Xt_t, yt_t = Xs.T, ys.T, Xt.T, yt.T\n",
    "\n",
    "if transform_data:\n",
    "    V = np.eye(args.dim)\n",
    "    Uh = np.transpose(lin_model.left_singular_vecs)\n",
    "    _, s, _ = np.linalg.svd(Xs_t.numpy(), full_matrices=True)\n",
    "else:\n",
    "    V, s, Uh = np.linalg.svd(Xs_t.numpy(), full_matrices=True)\n",
    "\n",
    "V_tensor, Uh_tensor = torch.tensor(V, dtype=torch.float32), torch.tensor(Uh, dtype=torch.float32)\n",
    "S = torch.tensor(np.concatenate((s**2, np.zeros(args.dim - s.shape[0]))).reshape(1, -1), dtype=torch.float32)\n",
    "print(S.shape)\n",
    "\n",
    "#eps_tensor = (torch.randn(size=(1, args.dim)) * sigma_noise)# @ torch.tensor(Uh).T)[:, :args.dim]).reshape(1, -1) #OBS: nu beror denna av input också\n",
    "\n",
    "beta_tensor = torch.tensor(beta, dtype=torch.float32).reshape(1, -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "St = ys_t @ Xs_t.T @ V_tensor\n",
    "eps_tensor_0 = ((ys_t - beta_tensor @ Xs_t) @ Uh_tensor.T)[:, :args.dim]\n",
    "eps_tensor = torch.concat((eps_tensor_0, torch.zeros((1, args.dim - s.shape[0]))), dim=-1)\n",
    "St2 = beta_tensor * S + eps_tensor * S**0.5\n",
    "\n",
    "print(St)\n",
    "print(St2)\n",
    "\n",
    "\n",
    "print(torch.abs(St - St2))\n",
    "\n",
    "u = 2.0\n",
    "\n",
    "print((St - u * z * S))\n",
    "print((beta_tensor * S).shape)\n",
    "print((eps_tensor * S**0.5).shape)\n",
    "print((u * z * S).shape)\n",
    "\n",
    "# TODO: Detta nedan bör vara exakt samma?? Är det någon precisionsgrej? Tror det, för ser bättre ut för större u\n",
    "print(beta_tensor * S + eps_tensor * S**0.5 - u * z * S)\n",
    "print(beta_tensor * S - u * z * S + eps_tensor * S**0.5 )\n",
    "print((beta_tensor  - u * z) * S + eps_tensor * S**0.5 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation\n",
    "g_cpu = torch.Generator()\n",
    "g_cpu.manual_seed(args.seed)\n",
    "\n",
    "w_init = args.scales[0] \n",
    "u = torch.tensor(args.scales[1]) #torch.normal(0, torch.tensor(w_init), generator=g_cpu) # u_init.clone()  \n",
    "z = torch.ones((1, args.dim)) * torch.tensor(args.scales[0]) #torch.normal(0, torch.tensor(w_init), size=(1, args.dim), generator=g_cpu) # z_init.T.clone()\n",
    "#z[0, 1] *= -1999.0\n",
    "print(u)\n",
    "print(z)\n",
    "print(u*z)\n",
    "\n",
    "u_track, z_track = [], []\n",
    "u_track.append(u)\n",
    "z_track.append(z)\n",
    "\n",
    "grad_u_track = []\n",
    "grad_z_track = []\n",
    "\n",
    "losses_teo = []\n",
    "risks_teo = []\n",
    "mse_weights_teo = []\n",
    "\n",
    "for t in range(int(args.iterations)):\n",
    "    \n",
    "    grad_u = dudt_s(u_track[-1], z_track[-1], S, beta_tensor, eps_tensor)\n",
    "    grad_z = dzdt_s(u_track[-1], z_track[-1], S, beta_tensor, eps_tensor)\n",
    "    \n",
    "    u = u + args.lr[1] * grad_u #dudt(u, z, S, St)\n",
    "    z = z + args.lr[0] * grad_z #dzdt(u, z, S, St) \n",
    "    #u = (S.max() - S.min()) * z.mean()\n",
    "    \n",
    "    grad_u_track.append(torch.norm(grad_u))\n",
    "    grad_z_track.append(torch.norm(grad_z))\n",
    "    \n",
    "    u_track.append(u)\n",
    "    z_track.append(z)\n",
    "    \n",
    "    Wtot = u * z @ V_tensor.T\n",
    "\n",
    "    y_pred = Wtot @ Xs_t\n",
    "\n",
    "    loss = loss_fn(y_pred.T, ys_t.T)\n",
    "    losses_teo.append(loss.item())\n",
    "\n",
    "    mse_weights_teo.append((((Wtot.squeeze()-beta_tensor.squeeze()) / beta_tensor.squeeze())**2))\n",
    "\n",
    "    if not t % args.print_freq:\n",
    "        print(t, loss.item())\n",
    "        \n",
    "    yt_pred = Wtot @ Xt_t\n",
    "\n",
    "    risk = risk_fn(yt_pred.T, yt_t.T)\n",
    "    risks_teo.append(risk.item())\n",
    "\n",
    "    if not t % args.print_freq:\n",
    "        print(t, risk.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_samples = [int(i) for i in np.geomspace(1, len(risks_teo)-1, num=700)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "risks = np.array(risks_teo)\n",
    "losses = np.array(losses_teo)\n",
    "risks_w = np.row_stack(mse_weights_teo)\n",
    "path_u = np.array(u_track)\n",
    "path_z = np.row_stack(z_track)\n",
    "grad_norm_u = np.array(grad_u_track)\n",
    "grad_norm_z = np.array(grad_z_track)\n",
    "print(grad_norm_u[0])\n",
    "print(grad_norm_z[0])\n",
    "\n",
    "cmap = matplotlib.cm.get_cmap('viridis')\n",
    "colorList = [cmap(50/1000), cmap(350/1000), cmap(700/1000)]\n",
    "labelList = ['empirical', 'theoretical']\n",
    "\n",
    "plot_all_dims = True\n",
    "\n",
    "extra_axs = 0\n",
    "if plot_all_dims:\n",
    "    extra_axs = args.dim\n",
    "\n",
    "fig, ax = plt.subplots(4 + extra_axs, 1, figsize=(12, 16 + 4 * extra_axs))\n",
    "ax[0].set_xscale('log')\n",
    "\n",
    "ax[0].plot(geo_samples, risks[geo_samples], \n",
    "        color=colorList[1], \n",
    "        label=labelList[1],\n",
    "        lw=4)\n",
    "\n",
    "ax[0].legend(loc=1, bbox_to_anchor=(1, 1), fontsize='x-large',\n",
    "    frameon=False, fancybox=True, shadow=True, ncol=1)\n",
    "ax[0].set_ylabel('risk')\n",
    "ax[0].set_xlabel(r'$t$ iterations')\n",
    "\n",
    "ax[1].set_xscale('log')\n",
    "ax[1].plot(geo_samples, losses[geo_samples], \n",
    "        color=colorList[1], \n",
    "        label=labelList[1],\n",
    "        lw=4)\n",
    "\n",
    "ax[1].set_ylabel('loss')\n",
    "ax[1].set_xlabel(r'$t$ iterations')\n",
    "\n",
    "ax[2].set_xscale('log')\n",
    "ax[2].plot(geo_samples, grad_norm_u[geo_samples], lw=4)\n",
    "ax[2].plot(geo_samples, grad_norm_z[geo_samples], lw=4)\n",
    "ax[2].set_ylabel('gradient norms')\n",
    "ax[2].set_xlabel(r'$t$ iterations')\n",
    "\n",
    "\n",
    "if plot_all_dims:\n",
    "    for i in range(args.dim):\n",
    "        ax[3+i].set_xscale('log')\n",
    "        ax[3+i].plot(geo_samples, risks_w[geo_samples, i], \n",
    "                color=colorList[2], \n",
    "                label=labelList[1],\n",
    "                lw=4)\n",
    "\n",
    "        ax[3+i].set_ylabel('MSE weights, ' + str(i))\n",
    "        ax[3+i].set_xlabel(r'$t$ iterations')\n",
    "\n",
    "\n",
    "ax[-1].set_xscale('log')\n",
    "ax[-1].plot(geo_samples, risks_w[geo_samples, :].mean(axis=-1), \n",
    "        color=colorList[2], \n",
    "        label=labelList[1],\n",
    "        lw=4)\n",
    "\n",
    "ax[-1].set_ylabel('MSE weights')\n",
    "ax[-1].set_xlabel(r'$t$ iterations')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_norm_z[geo_samples] / grad_norms[geo_samples, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_track = np.array(u_track)\n",
    "z_track = np.row_stack(z_track)\n",
    "grad_u_track = np.array(grad_u_track)\n",
    "grad_z_track = np.row_stack(grad_z_track)\n",
    "\n",
    "fig, ax = plt.subplots(2, 1, figsize=(12, 8))\n",
    "\n",
    "ax[0].set_xscale('log')\n",
    "ax[0].plot(geo_samples, u_track[geo_samples], label=\"u\")\n",
    "#ax[0].plot(geo_samples, risks_w[geo_samples, :].mean(axis=-1), label=\"risk\")\n",
    "ax[0].set_ylabel('u')\n",
    "ax[0].set_xlabel(r'$t$ iterations')\n",
    "\n",
    "\n",
    "#ax[0].plot(geo_samples, losses[geo_samples] )\n",
    "\n",
    "\n",
    "ax[1].set_xscale('log')\n",
    "\n",
    "mean_z = True\n",
    "if mean_z:\n",
    "    ax[1].plot(geo_samples, z_track[geo_samples, :int(args.dim/2)].mean(axis=-1), label=\"z, large\")\n",
    "    ax[1].plot(geo_samples, z_track[geo_samples, int(args.dim/2):].mean(axis=-1), label=\"z, small\")\n",
    "    \n",
    "else:\n",
    "    for i in range(args.dim):\n",
    "        ax[1].plot(geo_samples, z_track[geo_samples, i], label=fr\"$z_{i}$\")\n",
    "    \n",
    "ax[1].legend()\n",
    "ax[1].set_ylabel('z')\n",
    "ax[1].set_xlabel(r'$t$ iterations')\n",
    "\n",
    "# Interaktionen ökar med tiden? Trenden följer lossen (eller lossen följer u)?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "risks = np.array(risks_teo)\n",
    "losses = np.array(losses_teo)\n",
    "risks_w = np.row_stack(mse_weights_teo)\n",
    "\n",
    "cmap = matplotlib.cm.get_cmap('viridis')\n",
    "colorList = [cmap(50/1000), cmap(350/1000), cmap(700/1000)]\n",
    "labelList = ['empirical', 'theoretical']\n",
    "\n",
    "extra_axs = 2\n",
    "fig, ax = plt.subplots(3 + extra_axs, 1, figsize=(12,12 + 4 * extra_axs))\n",
    "\n",
    "ax[0].set_xscale('log')\n",
    "ax[0].plot(geo_samples, risks[geo_samples], \n",
    "        color=colorList[1], \n",
    "        label=labelList[1],\n",
    "        lw=4)\n",
    "\n",
    "ax[0].legend(loc=1, bbox_to_anchor=(1, 1), fontsize='x-large',\n",
    "    frameon=False, fancybox=True, shadow=True, ncol=1)\n",
    "ax[0].set_ylabel('risk')\n",
    "ax[0].set_xlabel(r'$t$ iterations')\n",
    "\n",
    "ax[1].set_xscale('log')\n",
    "ax[1].plot(geo_samples, losses[geo_samples], \n",
    "        color=colorList[1], \n",
    "        label=labelList[1],\n",
    "        lw=4)\n",
    "\n",
    "ax[1].set_ylabel('loss')\n",
    "ax[1].set_xlabel(r'$t$ iterations')\n",
    "\n",
    "p = int(args.dim / 2)\n",
    "ax[2].set_xscale('log')\n",
    "ax[2].plot(geo_samples, risks_w[geo_samples, :p].mean(axis=-1), \n",
    "        color=colorList[2], \n",
    "        label=labelList[1],\n",
    "        lw=4)\n",
    "\n",
    "ax[2].set_ylabel('MSE weights, large')\n",
    "ax[2].set_xlabel(r'$t$ iterations')\n",
    "\n",
    "ax[3].set_xscale('log')\n",
    "ax[3].plot(geo_samples, risks_w[geo_samples, p:].mean(axis=-1), \n",
    "        color=colorList[2], \n",
    "        label=labelList[1],\n",
    "        lw=4)\n",
    "\n",
    "ax[3].set_ylabel('MSE weights, small')\n",
    "ax[3].set_xlabel(r'$t$ iterations')\n",
    "\n",
    "\n",
    "ax[-1].set_xscale('log')\n",
    "ax[-1].plot(geo_samples, risks_w[geo_samples, :].mean(axis=-1), \n",
    "        color=colorList[2], \n",
    "        label=labelList[1],\n",
    "        lw=4)\n",
    "\n",
    "ax[-1].set_ylabel('MSE weights')\n",
    "ax[-1].set_xlabel(r'$t$ iterations')\n",
    "\n",
    "\n",
    "#ax[0].set_ylim([9, 13])\n",
    "#ax[1].set_ylim([80, 105])\n",
    "#ax[2].set_ylim([1, 2.55])\n",
    "#ax[3].set_ylim([0.35, 1.05])\n",
    "#ax[4].set_ylim([1, 1.6])\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(risks_teo[-2000:-1]) #MIIIIIHHH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(beta_tensor + eps_tensor * S**(-0.5)) @ (z**(-1)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.row_stack(mse_weights_teo[-2000:-1]).mean(axis=-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VECTOR FIELD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "v_min, v_max = -10, 10\n",
    "grid_size = 20\n",
    "x, y1 = np.meshgrid(np.linspace(v_min, v_max, grid_size),\n",
    "                    np.linspace(v_min, v_max, grid_size))\n",
    "\n",
    "# Example 1\n",
    "y2_1 = 1\n",
    "\n",
    "eps_0 = ys_t.numpy() - beta @ Xs_t.numpy()\n",
    "eps = (eps_0 @ np.transpose(Uh)).squeeze()\n",
    "\n",
    "d1 = (beta[0] - x * y1) * S[0, 0].numpy() + eps[0] * S[0, 0].numpy()**0.5  #St[0, 0].numpy() - x * y1 * S[0, 0].numpy()\n",
    "d2 = (beta[1] - x * y2_1) * S[0, 1].numpy() + eps[1] * S[0, 1].numpy()**0.5  #St[0, 1].numpy() - x * y2_1 * S[0, 1].numpy()\n",
    "\n",
    "v = d1 * y1 + d2 * y2_1\n",
    "w1 = d1 * x\n",
    "\n",
    "ax[0].quiver(x, y1, v, w1)\n",
    "\n",
    "ax[0].set_xlabel(\"u\")\n",
    "ax[0].set_ylabel(fr\"$z_1$\")\n",
    "ax[0].set_title(f\"$z_2$ = {y2_1}\")\n",
    "\n",
    "\n",
    "# Example 2\n",
    "y2_2 = 5\n",
    "d2_2 = (beta[1] - x * y2_2) * S[0, 1].numpy() + eps[1] * S[0, 1].numpy()**0.5  #St[0, 1].numpy() - x * y2_2 * S[0, 1].numpy()\n",
    "\n",
    "v_2 = d1 * y1 + d2_2 * y2_2\n",
    "\n",
    "ax[1].quiver(x, y1, v_2, w1)\n",
    "\n",
    "ax[1].set_xlabel(\"u\")\n",
    "ax[1].set_ylabel(fr\"$z_1$\")\n",
    "\n",
    "ax[1].set_title(f\"$z_2$ = {y2_2}\")\n",
    "\n",
    "\n",
    "# Example 3\n",
    "y2_3 = 10\n",
    "d2_3 = (beta[1] - x * y2_3) * S[0, 1].numpy() + eps[1] * S[0, 1].numpy()**0.5  #St[0, 1].numpy() - x * y2_2 * S[0, 1].numpy()\n",
    "\n",
    "v_3 = d1 * y1 + d2_3 * y2_3\n",
    "\n",
    "ax[2].quiver(x, y1, v_3, w1)\n",
    "\n",
    "ax[2].set_xlabel(\"u\")\n",
    "ax[2].set_ylabel(fr\"$z_1$\")\n",
    "\n",
    "ax[2].set_title(f\"$z_2$ = {y2_3}\")\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "v_min, v_max = -10, 10\n",
    "grid_size = 20\n",
    "x, y2 = np.meshgrid(np.linspace(v_min, v_max, grid_size),\n",
    "                    np.linspace(v_min, v_max, grid_size))\n",
    "\n",
    "# Example 1\n",
    "y1_1 = 1\n",
    "\n",
    "d1 = (beta[0] - x * y1_1) * S[0, 0].numpy() + eps[0] * S[0, 0].numpy()**0.5 # St[0, 0].numpy() - x * y2 * S[0, 0].numpy()\n",
    "d2 = (beta[1] - x * y2) * S[0, 1].numpy() + eps[1] * S[0, 1].numpy()**0.5  #St[0, 1].numpy() - x * y1_1 * S[0, 1].numpy()\n",
    "\n",
    "v = d1 * y1_1 + d2 * y2\n",
    "w2 = d2 * x\n",
    "\n",
    "ax[0].quiver(x, y2, v, w2)\n",
    "\n",
    "ax[0].set_xlabel(\"u\")\n",
    "ax[0].set_ylabel(fr\"$z_2$\")\n",
    "ax[0].set_title(f\"$z_1$ = {y1_1}\")\n",
    "\n",
    "\n",
    "# Example 2\n",
    "y1_2 = 2\n",
    "d1_2 = (beta[0] - x * y1_2) * S[0, 0].numpy() + eps[0] * S[0, 0].numpy()**0.5 # St[0, 0].numpy() - x * y1_2 * S[0, 0].numpy()\n",
    "\n",
    "v_2 = d1_2 * y1_2 + d2 * y2\n",
    "\n",
    "ax[1].quiver(x, y2, v_2, w2)\n",
    "\n",
    "ax[1].set_xlabel(\"u\")\n",
    "ax[1].set_ylabel(fr\"$z_2$\")\n",
    "\n",
    "ax[1].set_title(f\"$z_1$ = {y1_2}\")\n",
    "\n",
    "\n",
    "# Example 3\n",
    "y1_3 = 10\n",
    "d1_3 = (beta[0] - x * y1_2) * S[0, 0].numpy() + eps[0] * S[0, 0].numpy()**0.5 # St[0, 0].numpy() - x * y1_2 * S[0, 0].numpy()\n",
    "\n",
    "v_3 = d1_3 * y1_3 + d2 * y2\n",
    "\n",
    "ax[2].quiver(x, y2, v_3, w2)\n",
    "\n",
    "ax[2].set_xlabel(\"u\")\n",
    "ax[2].set_ylabel(fr\"$z_2$\")\n",
    "\n",
    "ax[2].set_title(f\"$z_1$ = {y1_3}\")\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "v_min, v_max = -20, 20\n",
    "grid_size = 20\n",
    "y1, y2 = np.meshgrid(np.linspace(v_min, v_max, grid_size),\n",
    "                    np.linspace(v_min, v_max, grid_size))\n",
    "\n",
    "\n",
    "# Example 1\n",
    "x_1 = 0.1\n",
    "d1 = (beta[0] - x_1 * y1) * S[0, 0].numpy() + eps[0] * S[0, 0].numpy()**0.5 #St[0, 0].numpy() - x * y1 * S[0, 0].numpy()\n",
    "d2 = (beta[1] - x_1 * y2) * S[0, 1].numpy() + eps[1] * S[0, 1].numpy()**0.5 #St[0, 1].numpy() - x * y2_1 * S[0, 1].numpy()\n",
    "\n",
    "w1 = d1 * x_1\n",
    "w2 = d2 * x_1\n",
    "\n",
    "ax[0].quiver(y1, y2, w1, w2)\n",
    "\n",
    "ax[0].set_xlabel(fr\"$z_1$\")\n",
    "ax[0].set_ylabel(fr\"$z_2$\")\n",
    "ax[0].set_title(f\"u = {x_1}\")\n",
    "\n",
    "\n",
    "# Example 2\n",
    "x_2 = 1\n",
    "d1_2 = (beta[0] - x_2 * y1) * S[0, 0].numpy() + eps_0[0, 0] * S[0, 0].numpy()**0.5 #St[0, 0].numpy() - x_2 * y1 * S[0, 0].numpy()\n",
    "d2_2 = (beta[1] - x_2 * y2) * S[0, 1].numpy() + eps_0[0, 1] * S[0, 1].numpy()**0.5 #St[0, 1].numpy() - x_2 * y2 * S[0, 1].numpy()\n",
    "\n",
    "w1_2 = d1_2 * x_2\n",
    "w2_2 = d2_2 * x_2\n",
    "\n",
    "ax[1].quiver(y1, y2, w1_2, w2_2)\n",
    "\n",
    "ax[1].set_xlabel(fr\"$z_1$\")\n",
    "ax[1].set_ylabel(fr\"$z_2$\")\n",
    "ax[1].set_title(f\"u = {x_2}\")\n",
    "\n",
    "\n",
    "# Example 3\n",
    "x_3 = 10\n",
    "\n",
    "d1_3 = (beta[0] - x_3 * y1) * S[0, 0].numpy() + eps[0] * S[0, 0].numpy()**0.5 #St[0, 0].numpy() - x_2 * y1 * S[0, 0].numpy()\n",
    "d2_3 = (beta[1] - x_3 * y2) * S[0, 1].numpy() + eps[1] * S[0, 1].numpy()**0.5 #St[0, 1].numpy() - x_2 * y2 * S[0, 1].numpy()\n",
    "\n",
    "w1_3 = d1_3 * x_3\n",
    "w2_3 = d2_3 * x_3\n",
    "\n",
    "ax[2].quiver(y1, y2, w1_3, w2_3)\n",
    "\n",
    "ax[2].set_xlabel(fr\"$z_1$\")\n",
    "ax[2].set_ylabel(fr\"$z_2$\")\n",
    "ax[2].set_title(f\"u = {x_3}\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# För kappa > 1 så rör vi oss främst i z1-riktning, men stort u jämnar ut skillnaderna?\n",
    "# Vi bör se att vi rör oss längre ifrån de sanna vikterna vid något tillfälle; men vet inte om vi ser det?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "v_min, v_max = -20, 20\n",
    "grid_size = 20\n",
    "y1, y2 = np.meshgrid(np.linspace(v_min, v_max, grid_size),\n",
    "                    np.linspace(v_min, v_max, grid_size))\n",
    "\n",
    "\n",
    "# Example 1\n",
    "x_1 = 0.1\n",
    "d1 = (beta[0] - x_1 * y1) * S[0, 0].numpy() + eps[0] * S[0, 0].numpy()**0.5 #St[0, 0].numpy() - x * y1 * S[0, 0].numpy()\n",
    "d2 = (beta[1] - x_1 * y2) * S[0, 1].numpy() + eps[1] * S[0, 1].numpy()**0.5 #St[0, 1].numpy() - x * y2_1 * S[0, 1].numpy()\n",
    "\n",
    "w1 = d1 * x_1**2 + (d1 * y1 + d2 * y2) * y1  \n",
    "w2 = d2 * x_1**2 + (d1 * y1 + d2 * y2) * y2\n",
    "\n",
    "ax[0].quiver(y1, y2, w1, w2)\n",
    "\n",
    "ax[0].set_xlabel(fr\"$uz_1$\")\n",
    "ax[0].set_ylabel(fr\"$uz_2$\")\n",
    "ax[0].set_title(f\"u = {x_1}\")\n",
    "\n",
    "\n",
    "# Example 2\n",
    "x_2 = 1.0\n",
    "d1_2 = (beta[0] - x_2 * y1) * S[0, 0].numpy() + eps_0[0, 0] * S[0, 0].numpy()**0.5 #St[0, 0].numpy() - x_2 * y1 * S[0, 0].numpy()\n",
    "d2_2 = (beta[1] - x_2 * y2) * S[0, 1].numpy() + eps_0[0, 1] * S[0, 1].numpy()**0.5 #St[0, 1].numpy() - x_2 * y2 * S[0, 1].numpy()\n",
    "\n",
    "w1_2 = d1_2 * x_2**2 + (d1_2 * y1 + d2_2 * y2) * y1  \n",
    "w2_2 = d2_2 * x_2**2 + (d1_2 * y1 + d2_2 * y2) * y2\n",
    "\n",
    "ax[1].quiver(y1, y2, w1_2, w2_2)\n",
    "\n",
    "ax[1].set_xlabel(fr\"$z_1$\")\n",
    "ax[1].set_ylabel(fr\"$z_2$\")\n",
    "ax[1].set_title(f\"u = {x_2}\")\n",
    "\n",
    "\n",
    "# Example 3\n",
    "x_3 = 10\n",
    "\n",
    "d1_3 = (beta[0] - x_3 * y1) * S[0, 0].numpy() + eps[0] * S[0, 0].numpy()**0.5 #St[0, 0].numpy() - x_2 * y1 * S[0, 0].numpy()\n",
    "d2_3 = (beta[1] - x_3 * y2) * S[0, 1].numpy() + eps[1] * S[0, 1].numpy()**0.5 #St[0, 1].numpy() - x_2 * y2 * S[0, 1].numpy()\n",
    "\n",
    "w1_3 = d1_3 * x_2**2 + (d1_3 * y1 + d2_3 * y2) * y1  \n",
    "w2_3 = d2_3 * x_3**2 + (d1_3 * y1 + d2_3 * y2) * y2\n",
    "\n",
    "ax[2].quiver(y1, y2, w1_3, w2_3)\n",
    "\n",
    "ax[2].set_xlabel(fr\"$z_1$\")\n",
    "ax[2].set_ylabel(fr\"$z_2$\")\n",
    "ax[2].set_title(f\"u = {x_3}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=plt.figaspect(0.5))\n",
    "ax = fig.add_subplot(1, 2, 1, projection='3d')\n",
    "\n",
    "v_min, v_max = -20, 20\n",
    "grid_size = 10\n",
    "x, y1, y2 = np.meshgrid(np.linspace(v_min, v_max, grid_size),\n",
    "                        np.linspace(v_min, v_max, grid_size),\n",
    "                        np.linspace(v_min, v_max, grid_size))\n",
    "\n",
    "\n",
    "d1 = (beta[0] - x * y1) * S[0, 0].numpy() + eps[0] * S[0, 0].numpy()**0.5 #St[0, 0].numpy() - x * y1 * S[0, 0].numpy()\n",
    "d2 = (beta[1] - x * y2) * S[0, 1].numpy() + eps[1] * S[0, 1].numpy()**0.5 #St[0, 1].numpy() - x * y2 * S[0, 1].numpy()\n",
    "\n",
    "v = d1 * y1 + d2 * y2\n",
    "w1 = d1 * x\n",
    "w2 = d2 * x\n",
    "\n",
    "ax.quiver(x, y1, y2, v, w1, w2, length=0.0001)\n",
    "\n",
    "ax.set_xlabel(fr\"$u$\")\n",
    "ax.set_ylabel(fr\"$z_1$\")\n",
    "ax.set_zlabel(fr\"$z_2$\")\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wtot\n",
    "\n",
    "fig, ax = plt.subplots(1, 5, figsize=(20, 4))\n",
    "\n",
    "\n",
    "# u fixed, #1\n",
    "v_min, v_max = -20, 20\n",
    "grid_size = 10\n",
    "x = 1\n",
    "y1, y2 = np.meshgrid(np.linspace(v_min, v_max, grid_size),\n",
    "                     np.linspace(v_min, v_max, grid_size))\n",
    "\n",
    "\n",
    "d1 = (beta[0] - x * y1) * S[0, 0].numpy() + eps[0] * S[0, 0].numpy()**0.5 #St[0, 0].numpy() - x * y1 * S[0, 0].numpy()\n",
    "d2 = (beta[1] - x * y2) * S[0, 1].numpy() + eps[1] * S[0, 1].numpy()**0.5 #St[0, 1].numpy() - x * y2 * S[0, 1].numpy()\n",
    "\n",
    "v = d1 * y1 + d2 * y2\n",
    "w1 = d1 * x\n",
    "w2 = d2 * x\n",
    "\n",
    "# Total weights \n",
    "p1 = x * y1\n",
    "p2 = x * y2\n",
    "\n",
    "q1 = v * y1 + w1 * x\n",
    "q2 = v * y2 + w2 * x\n",
    "\n",
    "ax[0].quiver(p1, p2, q1, q2)\n",
    "\n",
    "ax[0].set_xlabel(fr\"$w_1$\")\n",
    "ax[0].set_ylabel(fr\"$w_2$\")\n",
    "ax[0].set_title(f\"u = {x}\")\n",
    "\n",
    "\n",
    "# u fixed, #2\n",
    "v_min, v_max = -20, 20\n",
    "grid_size = 10\n",
    "x = 5\n",
    "y1, y2 = np.meshgrid(np.linspace(v_min, v_max, grid_size),\n",
    "                     np.linspace(v_min, v_max, grid_size))\n",
    "\n",
    "\n",
    "d1 = (beta[0] - x * y1) * S[0, 0].numpy() + eps[0] * S[0, 0].numpy()**0.5 #St[0, 0].numpy() - x * y1 * S[0, 0].numpy()\n",
    "d2 = (beta[1] - x * y2) * S[0, 1].numpy() + eps[1] * S[0, 1].numpy()**0.5 #St[0, 1].numpy() - x * y2 * S[0, 1].numpy()\n",
    "\n",
    "v = d1 * y1 + d2 * y2\n",
    "w1 = d1 * x\n",
    "w2 = d2 * x\n",
    "\n",
    "# Total weights \n",
    "p1 = x * y1\n",
    "p2 = x * y2\n",
    "\n",
    "q1 = v * y1 + w1 * x\n",
    "q2 = v * y2 + w2 * x\n",
    "\n",
    "ax[1].quiver(p1, p2, q1, q2)\n",
    "\n",
    "ax[1].set_xlabel(fr\"$w_1$\")\n",
    "ax[1].set_ylabel(fr\"$w_2$\")\n",
    "ax[1].set_title(f\"u = {x}\")\n",
    "\n",
    "\n",
    "# u fixed, #3\n",
    "v_min, v_max = -20, 20\n",
    "grid_size = 10\n",
    "x = 10\n",
    "y1, y2 = np.meshgrid(np.linspace(v_min, v_max, grid_size),\n",
    "                     np.linspace(v_min, v_max, grid_size))\n",
    "\n",
    "\n",
    "d1 = (beta[0] - x * y1) * S[0, 0].numpy() + eps[0] * S[0, 0].numpy()**0.5 #St[0, 0].numpy() - x * y1 * S[0, 0].numpy()\n",
    "d2 = (beta[1] - x * y2) * S[0, 1].numpy() + eps[1] * S[0, 1].numpy()**0.5 #St[0, 1].numpy() - x * y2 * S[0, 1].numpy()\n",
    "\n",
    "v = d1 * y1 + d2 * y2\n",
    "w1 = d1 * x\n",
    "w2 = d2 * x\n",
    "\n",
    "# Total weights \n",
    "p1 = x * y1\n",
    "p2 = x * y2\n",
    "\n",
    "q1 = v * y1 + w1 * x\n",
    "q2 = v * y2 + w2 * x\n",
    "\n",
    "ax[2].quiver(p1, p2, q1, q2)\n",
    "\n",
    "ax[2].set_xlabel(fr\"$w_1$\")\n",
    "ax[2].set_ylabel(fr\"$w_2$\")\n",
    "ax[2].set_title(f\"u = {x}\")\n",
    "\n",
    "\n",
    "# z_1 fixed \n",
    "y1 = 5\n",
    "x, y2 = np.meshgrid(np.linspace(v_min, v_max, grid_size),\n",
    "                    np.linspace(v_min, v_max, grid_size))\n",
    "\n",
    "\n",
    "d1 = (beta[0] - x * y1) * S[0, 0].numpy() + eps[0] * S[0, 0].numpy()**0.5 #St[0, 0].numpy() - x * y1 * S[0, 0].numpy()\n",
    "d2 = (beta[1] - x * y2) * S[0, 1].numpy() + eps[1] * S[0, 1].numpy()**0.5 #St[0, 1].numpy() - x * y2 * S[0, 1].numpy()\n",
    "\n",
    "v = d1 * y1 + d2 * y2\n",
    "w1 = d1 * x\n",
    "w2 = d2 * x\n",
    "\n",
    "# Total weights \n",
    "p1 = x * y1\n",
    "p2 = x * y2\n",
    "\n",
    "q1 = v * y1 + w1 * x\n",
    "q2 = v * y2 + w2 * x\n",
    "\n",
    "ax[3].quiver(p1, p2, q1, q2)\n",
    "\n",
    "ax[3].set_xlabel(fr\"$w_1$\")\n",
    "ax[3].set_ylabel(fr\"$w_2$\")\n",
    "ax[3].set_title(f\"$z_1$ = {y1}\")\n",
    "\n",
    "\n",
    "\n",
    "# z_2 fixed \n",
    "y2 = 5\n",
    "x, y1 = np.meshgrid(np.linspace(v_min, v_max, grid_size),\n",
    "                    np.linspace(v_min, v_max, grid_size))\n",
    "\n",
    "\n",
    "d1 = (beta[0] - x * y1) * S[0, 0].numpy() + eps[0] * S[0, 0].numpy()**0.5 #St[0, 0].numpy() - x * y1 * S[0, 0].numpy()\n",
    "d2 = (beta[1] - x * y2) * S[0, 1].numpy() + eps[1] * S[0, 1].numpy()**0.5 #St[0, 1].numpy() - x * y2 * S[0, 1].numpy()\n",
    "\n",
    "v = d1 * y1 + d2 * y2\n",
    "w1 = d1 * x\n",
    "w2 = d2 * x\n",
    "\n",
    "# Total weights \n",
    "p1 = x * y1\n",
    "p2 = x * y2\n",
    "\n",
    "q1 = v * y1 + w1 * x\n",
    "q2 = v * y2 + w2 * x\n",
    "\n",
    "ax[4].quiver(p1, p2, q1, q2)\n",
    "\n",
    "ax[4].set_xlabel(fr\"$w_1$\")\n",
    "ax[4].set_ylabel(fr\"$w_2$\")\n",
    "ax[4].set_title(f\"$z_2$ = {y2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSE\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "\n",
    "# u fixed \n",
    "v_min, v_max = -5, 5\n",
    "grid_size = 10\n",
    "x = 5\n",
    "y1, y2 = np.meshgrid(np.linspace(v_min, v_max, grid_size),\n",
    "                     np.linspace(v_min, v_max, grid_size))\n",
    "\n",
    "\n",
    "d1 = (beta[0] - x * y1) * S[0, 0].numpy() + eps[0] * S[0, 0].numpy()**0.5 #St[0, 0].numpy() - x * y1 * S[0, 0].numpy()\n",
    "d2 = (beta[1] - x * y2) * S[0, 1].numpy() + eps[1] * S[0, 1].numpy()**0.5 #St[0, 1].numpy() - x * y2 * S[0, 1].numpy()\n",
    "\n",
    "v = d1 * y1 + d2 * y2\n",
    "w1 = d1 * x\n",
    "w2 = d2 * x\n",
    "\n",
    "# Total weights \n",
    "p1 = x * y1\n",
    "p2 = x * y2\n",
    "\n",
    "q1 = v * y1 + w1 * x\n",
    "q2 = v * y2 + w2 * x\n",
    "\n",
    "r = (beta[0] - p1)**2 + (beta[1] - p2)**2 \n",
    "\n",
    "beta_v = beta @ np.transpose(V)  # TODO: do all other equations assume V=I or does it not matter?\n",
    "rm = (x * y1 - beta_v[0]) * q1 + (x * y2 - beta_v[1]) * q2 \n",
    "\n",
    "ax[0].quiver(y1, r, w1, rm)\n",
    "\n",
    "ax[0].set_xlabel(fr\"$z_1$\")\n",
    "ax[0].set_ylabel(fr\"$L$\")\n",
    "ax[0].set_title(f\"u = {x}\")\n",
    "\n",
    "\n",
    "# z_1 fixed \n",
    "y1 = 5\n",
    "x, y2 = np.meshgrid(np.linspace(v_min, v_max, grid_size),\n",
    "                    np.linspace(v_min, v_max, grid_size))\n",
    "\n",
    "\n",
    "d1 = (beta[0] - x * y1) * S[0, 0].numpy() + eps[0] * S[0, 0].numpy()**0.5 #St[0, 0].numpy() - x * y1 * S[0, 0].numpy()\n",
    "d2 = (beta[1] - x * y2) * S[0, 1].numpy() + eps[1] * S[0, 1].numpy()**0.5 #St[0, 1].numpy() - x * y2 * S[0, 1].numpy()\n",
    "\n",
    "v = d1 * y1 + d2 * y2\n",
    "w1 = d1 * x\n",
    "w2 = d2 * x\n",
    "\n",
    "# Total weights \n",
    "p1 = x * y1\n",
    "p2 = x * y2\n",
    "\n",
    "q1 = v * y1 + w1 * x\n",
    "q2 = v * y2 + w2 * x\n",
    "\n",
    "r = (beta[0] - p1)**2 + (beta[1] - p2)**2 # Tar V ut sig självt?\n",
    "\n",
    "beta_v = beta @ np.transpose(V)  # TODO: do all other equations assume V=I or does it not matter?\n",
    "rm = (x * y1 - beta_v[0]) * q1 + (x * y2 - beta_v[1]) * q2 \n",
    "\n",
    "ax[1].quiver(y2, r, w2, rm)\n",
    "\n",
    "ax[1].set_xlabel(fr\"$z_2$\")\n",
    "ax[1].set_ylabel(fr\"$L$\")\n",
    "ax[1].set_title(f\"$z_1$ = {y1}\")\n",
    "\n",
    "\n",
    "\n",
    "# z_2 fixed \n",
    "y2 = 5\n",
    "x, y1 = np.meshgrid(np.linspace(v_min, v_max, grid_size),\n",
    "                    np.linspace(v_min, v_max, grid_size))\n",
    "\n",
    "\n",
    "d1 = (beta[0] - x * y1) * S[0, 0].numpy() + eps[0] * S[0, 0].numpy()**0.5 #St[0, 0].numpy() - x * y1 * S[0, 0].numpy()\n",
    "d2 = (beta[1] - x * y2) * S[0, 1].numpy() + eps[1] * S[0, 1].numpy()**0.5 #St[0, 1].numpy() - x * y2 * S[0, 1].numpy()\n",
    "\n",
    "v = d1 * y1 + d2 * y2\n",
    "w1 = d1 * x\n",
    "w2 = d2 * x\n",
    "\n",
    "# Total weights \n",
    "p1 = x * y1\n",
    "p2 = x * y2\n",
    "\n",
    "q1 = v * y1 + w1 * x\n",
    "q2 = v * y2 + w2 * x\n",
    "\n",
    "r = (beta[0] - p1)**2 + (beta[1] - p2)**2 # Tar V ut sig självt?\n",
    "\n",
    "beta_v = beta @ np.transpose(V)  # TODO: do all other equations assume V=I or does it not matter? Se logg 22/11 09:42.\n",
    "rm = (x * y1 - beta_v[0]) * q1 + (x * y2 - beta_v[1]) * q2 \n",
    "\n",
    "ax[2].quiver(y1, r, w1, rm)\n",
    "\n",
    "ax[2].set_xlabel(fr\"$z_1$\")\n",
    "ax[2].set_ylabel(fr\"$L$\")\n",
    "ax[2].set_title(f\"$z_2$ = {y2}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison linear model\n",
    "\n",
    "# Two-layer model\n",
    "w_init = args.scales[0]\n",
    "u = torch.normal(0, torch.tensor(w_init)) #, generator=g_cpu) # u_init.clone() \n",
    "z = torch.normal(0, torch.tensor(w_init), size=(1, args.dim)) #, generator=g_cpu) # z_init.T.clone()\n",
    "\n",
    "grad_u = dudt_s(u, z, S, beta_tensor, eps_tensor)\n",
    "grad_z = dzdt_s(u, z, S, beta_tensor, eps_tensor)\n",
    "\n",
    "grad_w_tot = grad_u * z + u * grad_z\n",
    "diff_w = grad_w_tot[0, 0] - grad_w_tot[0, 1]\n",
    "print(diff_w)\n",
    "\n",
    "# One-layer model\n",
    "grad_w_tot_comp = dzdt_s(1.0, z, S, beta_tensor, eps_tensor)\n",
    "diff_w_comp = grad_w_tot_comp[0, 0] - grad_w_tot_comp[0, 1]\n",
    "print(diff_w_comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison linear model\n",
    "\n",
    "# Two-layer model\n",
    "u = torch.normal(0, torch.tensor(w_init)) #, generator=g_cpu) # u_init.clone() \n",
    "z = torch.normal(0, torch.tensor(w_init), size=(1, args.dim)) #, generator=g_cpu) # z_init.T.clone()\n",
    "\n",
    "grad_u = dudt_s(u, z, S, beta_tensor, eps_tensor)\n",
    "grad_z = dzdt_s(u, z, S, beta_tensor, eps_tensor)\n",
    "\n",
    "grad_w_tot = grad_u * z + u * grad_z\n",
    "\n",
    "\n",
    "# One-layer model\n",
    "grad_w_tot_comp = dzdt_s(1.0, z, S, beta_tensor, eps_tensor)\n",
    "\n",
    "diff_l = grad_w_tot[0, 0] - grad_w_tot_comp[0, 0]\n",
    "diff_s = grad_w_tot[0, 1] - grad_w_tot_comp[0, 1]\n",
    "\n",
    "\n",
    "print(grad_w_tot)\n",
    "print(grad_w_tot_comp)\n",
    "\n",
    "# men här är det ju att gradienten är större för den linjära modellen...\n",
    "\n",
    "print(diff_l)\n",
    "print(diff_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
