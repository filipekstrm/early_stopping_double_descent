{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High-dimensional dynamics of generalization error in neural networks\n",
    "\n",
    "Attempt to reproduce Figure 5B in the paper and reproduce double descent.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import datetime\n",
    "import pathlib\n",
    "import random\n",
    "import json\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append('../code/')\n",
    "from linear_utils import linear_model, get_modulation_matrix\n",
    "from train_utils import save_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# argument written in command line format\n",
    "cli_args = '--seed 12 --save-results --risk-loss L2 -t 100000 -w 1 1 --lr 0.001 0.001 -d 10 -n 100 --hidden 50 --sigmas 1 --kappa 3.0'\n",
    "sigma_noise = 1.0\n",
    "transform_data = True\n",
    "cont_eigs = False\n",
    "\n",
    "#cli_args = '--seed 12 --save-results --jacobian --risk-loss L2 -t 20000 -w 0.1 0.1 --lr 0.00001 -d 50 -n 1000 --hidden 50 --sigmas 1 --kappa 3'\n",
    "#sigma_noise = 1.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "A fully-connected network with one hidden layer, trained to predict y from x\n",
    "by minimizing the MSE loss.\n",
    "\"\"\"\n",
    "\n",
    "# get CLI parameters\n",
    "parser = argparse.ArgumentParser(description='CLI parameters for training')\n",
    "parser.add_argument('--root', type=str, default='', metavar='DIR',\n",
    "                    help='Root directory')\n",
    "parser.add_argument('-t', '--iterations', type=int, default=1e4, metavar='ITERATIONS',\n",
    "                    help='Iterations (default: 1e4)')\n",
    "parser.add_argument('-n', '--samples', type=int, default=100, metavar='N',\n",
    "                    help='Number of samples (default: 100)')\n",
    "parser.add_argument('--print-freq', type=int, default=1000,\n",
    "                    help='CLI output printing frequency (default: 1000)')\n",
    "parser.add_argument('--gpu', type=int, default=None,\n",
    "                    help='Number of GPUS to use')\n",
    "parser.add_argument('--seed', type=int, default=None,\n",
    "                    help='Random seed')                        \n",
    "parser.add_argument('-d', '--dim', type=int, default=50, metavar='DIMENSION',\n",
    "                    help='Feature dimension (default: 50)')\n",
    "parser.add_argument('--hidden', type=int, default=200, metavar='DIMENSION',\n",
    "                    help='Hidden layer dimension (default: 200)')\n",
    "parser.add_argument('--sigmas', type=str, default=None,\n",
    "                    help='Sigmas')     \n",
    "parser.add_argument('-r','--s-range', nargs='*', type=float,\n",
    "                    help='Range for sigmas')\n",
    "parser.add_argument('--kappa', type=float,\n",
    "                    help='Eigenvalue ratio')\n",
    "parser.add_argument('-w','--scales', nargs='*', type=float,\n",
    "                    help='scale of the weights')\n",
    "parser.add_argument('--lr', type=float, default=1e-4, nargs='*', metavar='LR',\n",
    "                    help='learning rate (default: 1e-4)')              \n",
    "parser.add_argument('--normalized', action='store_true', default=False,\n",
    "                    help='normalize sample norm across features')\n",
    "parser.add_argument('--risk-loss', type=str, default='MSE', metavar='LOSS',\n",
    "                    help='Loss for validation')\n",
    "parser.add_argument('--jacobian', action='store_true', default=False,\n",
    "                    help='compute the SVD of the jacobian of the network')\n",
    "parser.add_argument('--save-results', action='store_true', default=False,\n",
    "                    help='Save the results for plots')\n",
    "parser.add_argument('--details', type=str, metavar='N',\n",
    "                    default='no_detail_given',\n",
    "                    help='details about the experimental setup')\n",
    "\n",
    "\n",
    "args = parser.parse_args(cli_args.split())\n",
    "\n",
    "# directories\n",
    "root = pathlib.Path(args.root) if args.root else pathlib.Path.cwd().parent\n",
    "\n",
    "current_date = str(datetime.datetime.today().strftime('%Y-%m-%d-%H-%M-%S'))\n",
    "args.outpath = (pathlib.Path.cwd().parent / 'results' / 'two_layer_nn' /  current_date)\n",
    "\n",
    "if args.save_results:\n",
    "    args.outpath.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "if args.seed is not None:\n",
    "    random.seed(args.seed)\n",
    "    torch.manual_seed(args.seed)\n",
    "    np.random.seed(args.seed)\n",
    "    \n",
    "device = torch.device('cpu')\n",
    "# device = torch.device('cuda') # Uncomment this to run on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = int(np.ceil(args.dim / 2))\n",
    "#k = args.kappa\n",
    "#F = get_modulation_matrix(args.dim, p, k)\n",
    "\n",
    "beta = np.ones((args.dim,))\n",
    "\n",
    "# Set to False if you want to transform after data sampling\n",
    "scale_beta=True\n",
    "\n",
    "d_out = 1      # dimension of y\n",
    "\n",
    "# sample training set from the linear model\n",
    "lin_model = linear_model(args.dim, sigma_noise=sigma_noise, beta=beta, scale_beta=scale_beta, normalized=False, sigmas=args.sigmas, s_range=args.s_range, coupled_noise=False, transform_data=transform_data, kappa=args.kappa, p=p, cont_eigs=cont_eigs, masked_input=False)\n",
    "Xs, ys = lin_model.sample(args.samples, train=True)\n",
    "\n",
    "# sample the set for empirical risk calculation\n",
    "Xt, yt = lin_model.sample(args.samples, train=False) # 1000\n",
    "beta = lin_model.beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform data (masking)\n",
    "\n",
    "\n",
    "# Uncomment if you want to transform after data sampling\n",
    "#Xs = Xs @ F\n",
    "#Xt = Xt @ F\n",
    "\n",
    "#_, Ss, Vh = np.linalg.svd(Xs)\n",
    "#_, St, _ = np.linalg.svd(np.transpose(Xt) @ Xt)\n",
    "\n",
    "#print(\"train\")\n",
    "#print(Ss)\n",
    "#print(\"test\")\n",
    "#print(St)\n",
    "\n",
    "# Uncomment if you transform_data=False, but you want to decouple features\n",
    "#Xs = Xs @ np.transpose(Vh)\n",
    "#Xt = Xt @ np.transpose(Vh)\n",
    "\n",
    "#beta = np.linalg.inv(F) @ beta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs = torch.tensor(Xs, dtype=torch.float32).to(device)\n",
    "ys = torch.tensor(ys.reshape((-1,1)), dtype=torch.float32).to(device)\n",
    "\n",
    "Xt = torch.tensor(Xt, dtype=torch.float32).to(device)\n",
    "yt = torch.tensor(yt.reshape((-1,1)), dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss functions\n",
    "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "risk_fn = torch.nn.L1Loss(reduction='mean') if args.risk_loss == 'L1' else torch.nn.MSELoss(reduction='sum')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Empirical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(\n",
    "           torch.nn.Linear(args.dim, args.hidden, bias=False),\n",
    "           #torch.nn.ReLU(),\n",
    "           torch.nn.Linear(args.hidden, d_out, bias=False),\n",
    "         ).to(device)      \n",
    "                \n",
    "# use kaiming initialization                \n",
    "if args.scales:\n",
    "    i = 0\n",
    "    with torch.no_grad():\n",
    "        for m in model:\n",
    "            if type(m) == torch.nn.Linear:\n",
    "                if i == 0:\n",
    "                    torch.nn.init.kaiming_normal_(m.weight, a=math.sqrt(5))\n",
    "                    m.weight.data = torch.mul(m.weight.data, args.scales[0])\n",
    "                if i == 1:\n",
    "                    torch.nn.init.kaiming_uniform_(m.weight, a=math.sqrt(5))\n",
    "                    m.weight.data = torch.mul(m.weight.data, args.scales[1])\n",
    "                i += 1\n",
    "                \n",
    "\n",
    "# use same learning rate for the two layers\n",
    "#if isinstance(args.lr, list):\n",
    "#    stepsize = [max(args.lr)] * 2\n",
    "stepsize = args.lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_min = np.linalg.solve(np.transpose(Xs)@Xs, np.transpose(Xs)@ys).squeeze()\n",
    "print(w_min)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the network\n",
    "losses_emp = []\n",
    "risks_emp = []\n",
    "mse_weights_emp = []\n",
    "for t in range(int(args.iterations)):\n",
    "    y_pred = model(Xs)\n",
    "\n",
    "    loss = loss_fn(y_pred, ys)\n",
    "    losses_emp.append(loss.item())\n",
    "\n",
    "    if not t % args.print_freq:\n",
    "        print(t, loss.item())\n",
    "\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        i = 0\n",
    "        w_tot = torch.diag(torch.ones(args.dim)) #[]\n",
    "        for param in model.parameters():\n",
    "            param.data -= stepsize[i] * param.grad\n",
    "            #w_tot.append(param.data.t().numpy().copy().reshape(1, -1)) #\n",
    "            w_tot = w_tot @ param.data.t()\n",
    "            \n",
    "            if len(param.shape) > 1:\n",
    "                i += 1\n",
    "                \n",
    "        \n",
    "        #w_tot = np.column_stack(w_tot)\n",
    "        w_tot = w_tot.squeeze()\n",
    "        assert w_tot.shape == beta.shape\n",
    "        mse_weights_emp.append(((w_tot.numpy()-w_min) / w_min)**2) #w_tot\n",
    "                \n",
    "            \n",
    "    with torch.no_grad():\n",
    "        yt_pred = model(Xt)\n",
    "        \n",
    "        risk = risk_fn(yt_pred, yt)\n",
    "        risks_emp.append(risk.item())\n",
    "\n",
    "        if not t % args.print_freq:\n",
    "            print(t, risk.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_samples = [int(i) for i in np.geomspace(1, len(risks_emp)-1, num=700)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "risks = np.array(risks_emp)\n",
    "losses = np.array(losses_emp)\n",
    "risks_w = np.row_stack(mse_weights_emp)\n",
    "\n",
    "cmap = matplotlib.cm.get_cmap('viridis')\n",
    "colorList = [cmap(50/1000), cmap(350/1000), cmap(700/1000)]\n",
    "labelList = ['empirical', 'theoretical']\n",
    "\n",
    "plot_all_dims = True\n",
    "\n",
    "extra_axs = 0\n",
    "if plot_all_dims:\n",
    "    extra_axs = risks_w.shape[-1] #args.dim\n",
    "\n",
    "fig, ax = plt.subplots(3 + extra_axs, 1, figsize=(12,12 + 4 * extra_axs))\n",
    "\n",
    "ax[0].set_xscale('log')\n",
    "ax[0].plot(geo_samples, risks[geo_samples], \n",
    "        color=colorList[1], \n",
    "        label=labelList[0],\n",
    "        lw=4)\n",
    "\n",
    "ax[0].legend(loc=1, bbox_to_anchor=(1, 1), fontsize='x-large',\n",
    "    frameon=False, fancybox=True, shadow=True, ncol=1)\n",
    "ax[0].set_ylabel('risk')\n",
    "ax[0].set_xlabel(r'$t$ iterations')\n",
    "\n",
    "ax[1].set_xscale('log')\n",
    "ax[1].plot(geo_samples, losses[geo_samples], \n",
    "        color=colorList[1], \n",
    "        label=labelList[0],\n",
    "        lw=4)\n",
    "\n",
    "ax[1].set_ylabel('loss')\n",
    "ax[1].set_xlabel(r'$t$ iterations')\n",
    "\n",
    "if plot_all_dims:\n",
    "    for i in range(risks_w.shape[-1]):\n",
    "        ax[2+i].set_xscale('log')\n",
    "        ax[2+i].plot(geo_samples, risks_w[geo_samples, i], \n",
    "                color=colorList[2], \n",
    "                label=labelList[0],\n",
    "                lw=4)\n",
    "\n",
    "        ax[2+i].set_ylabel('MSE weights, ' + str(i))\n",
    "        ax[2+i].set_xlabel(r'$t$ iterations')\n",
    "\n",
    "\n",
    "ax[-1].set_xscale('log')\n",
    "ax[-1].plot(geo_samples, risks_w[geo_samples, :].mean(axis=-1), \n",
    "        color=colorList[2], \n",
    "        label=labelList[0],\n",
    "        lw=4)\n",
    "\n",
    "ax[-1].set_ylabel('MSE weights')\n",
    "ax[-1].set_xlabel(r'$t$ iterations')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "risks = np.array(risks_emp)\n",
    "losses = np.array(losses_emp)\n",
    "risks_w = np.row_stack(mse_weights_emp)\n",
    "\n",
    "cmap = matplotlib.cm.get_cmap('viridis')\n",
    "colorList = [cmap(50/1000), cmap(350/1000), cmap(700/1000)]\n",
    "labelList = ['empirical', 'theoretical']\n",
    "\n",
    "extra_axs = 2\n",
    "fig, ax = plt.subplots(3 + extra_axs, 1, figsize=(12,12 + 4 * extra_axs))\n",
    "\n",
    "ax[0].set_xscale('log')\n",
    "ax[0].plot(geo_samples, risks[geo_samples], \n",
    "        color=colorList[1], \n",
    "        label=labelList[0],\n",
    "        lw=4)\n",
    "\n",
    "ax[0].legend(loc=1, bbox_to_anchor=(1, 1), fontsize='x-large',\n",
    "    frameon=False, fancybox=True, shadow=True, ncol=1)\n",
    "ax[0].set_ylabel('risk')\n",
    "ax[0].set_xlabel(r'$t$ iterations')\n",
    "\n",
    "ax[1].set_xscale('log')\n",
    "ax[1].plot(geo_samples, losses[geo_samples], \n",
    "        color=colorList[1], \n",
    "        label=labelList[0],\n",
    "        lw=4)\n",
    "\n",
    "ax[1].set_ylabel('loss')\n",
    "ax[1].set_xlabel(r'$t$ iterations')\n",
    "\n",
    "p = int(args.dim / 2)\n",
    "ax[2].set_xscale('log')\n",
    "ax[2].plot(geo_samples, risks_w[geo_samples, :p].mean(axis=-1), \n",
    "        color=colorList[2], \n",
    "        label=labelList[0],\n",
    "        lw=4)\n",
    "\n",
    "ax[2].set_ylabel('MSE weights, large')\n",
    "ax[2].set_xlabel(r'$t$ iterations')\n",
    "\n",
    "ax[3].set_xscale('log')\n",
    "ax[3].plot(geo_samples, risks_w[geo_samples, p:].mean(axis=-1), \n",
    "        color=colorList[2], \n",
    "        label=labelList[0],\n",
    "        lw=4)\n",
    "\n",
    "ax[3].set_ylabel('MSE weights, small')\n",
    "ax[3].set_xlabel(r'$t$ iterations')\n",
    "\n",
    "\n",
    "ax[-1].set_xscale('log')\n",
    "ax[-1].plot(geo_samples, risks_w[geo_samples, :].mean(axis=-1), \n",
    "        color=colorList[2], \n",
    "        label=labelList[0],\n",
    "        lw=4)\n",
    "\n",
    "ax[-1].set_ylabel('MSE weights')\n",
    "ax[-1].set_xlabel(r'$t$ iterations')\n",
    "\n",
    "\n",
    "#ax[0].set_ylim([9, 13])\n",
    "#ax[1].set_ylim([80, 105])\n",
    "#ax[2].set_ylim([1, 2.55])\n",
    "#ax[3].set_ylim([0.35, 1.05])\n",
    "#ax[4].set_ylim([0.9, 1.6])\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax  = plt.subplots()\n",
    "plt.plot(risks_emp[:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theoretical "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With actual input data\n",
    "def dt(u, z, S, St):\n",
    "    assert S.shape == z.shape\n",
    "    return (St - u * z * S)\n",
    "\n",
    "\n",
    "def dzdt(u, z, S, St):\n",
    "    return u * dt(u, z, S, St)\n",
    "\n",
    "\n",
    "def dudt(u, z, S, St):\n",
    "    return (dt(u, z, S, St) @ z.T).squeeze()\n",
    "\n",
    "\n",
    "# Sampling only noise in output (and assuming that we know the true weights)\n",
    "def dt_s(u, z, S, beta, eps):\n",
    "    assert S.shape == z.shape\n",
    "    return (beta - u * z) * S + eps * S**0.5\n",
    "\n",
    "\n",
    "def dzdt_s(u, z, S, beta, eps):\n",
    "    return u * dt_s(u, z, S, beta, eps)\n",
    "\n",
    "\n",
    "def dudt_s(u, z, S, beta, eps):\n",
    "    return (dt_s(u, z, S, beta, eps) @ z.T).squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the sake of not messing anything up\n",
    "Xs_t, ys_t, Xt_t, yt_t = Xs.T, ys.T, Xt.T, yt.T\n",
    "\n",
    "if transform_data:\n",
    "    V = np.eye(args.dim)\n",
    "    Uh = np.transpose(lin_model.right_singular_vecs)\n",
    "    _, s, _ = np.linalg.svd(Xs_t.numpy(), full_matrices=True)\n",
    "else:\n",
    "    V, s, Uh = np.linalg.svd(Xs_t.numpy(), full_matrices=True)\n",
    "\n",
    "V_tensor, Uh_tensor = torch.tensor(V, dtype=torch.float32), torch.tensor(Uh, dtype=torch.float32)\n",
    "S = torch.tensor(np.concatenate((s**2, np.zeros(args.dim - s.shape[0]))).reshape(1, -1), dtype=torch.float32)\n",
    "St = ys_t @ Xs_t.T @ V_tensor\n",
    "\n",
    "#eps_tensor = (torch.randn(size=(1, args.dim)) * sigma_noise)# @ torch.tensor(Uh).T)[:, :args.dim]).reshape(1, -1) #OBS: nu beror denna av input också\n",
    "\n",
    "beta_tensor = torch.tensor(beta, dtype=torch.float32).reshape(1, -1)\n",
    "eps_tensor = ((ys_t - beta_tensor @ Xs_t) @ Uh_tensor.T)[:, :args.dim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation\n",
    "g_cpu = torch.Generator()\n",
    "g_cpu.manual_seed(args.seed)\n",
    "\n",
    "w_init = args.scales[0] * 0.1 \n",
    "u = torch.normal(0, torch.tensor(w_init), generator=g_cpu)\n",
    "z = torch.normal(0, torch.tensor(w_init), size=(1, args.dim), generator=g_cpu)\n",
    "print(u)\n",
    "print(z)\n",
    "\n",
    "u_track, z_track = [], []\n",
    "u_track.append(u)\n",
    "z_track.append(z)\n",
    "\n",
    "losses_teo = []\n",
    "risks_teo = []\n",
    "mse_weights_teo = []\n",
    "\n",
    "for t in range(int(args.iterations)):\n",
    "    \n",
    "    u = u + args.lr[1] * dudt_s(u_track[-1], z_track[-1], S, beta_tensor, eps_tensor) #dudt(u, z, S, St)\n",
    "    #z = z + args.lr[0] * dzdt_s(u_track[-1], z_track[-1], S, beta_tensor, eps_tensor) #dzdt(u, z, S, St) \n",
    "    #u = (S.max() - S.min()) * z.mean()\n",
    "    \n",
    "    u_track.append(u)\n",
    "    z_track.append(z)\n",
    "    \n",
    "    Wtot = u * z @ V_tensor.T\n",
    "\n",
    "    y_pred = Wtot @ Xs_t\n",
    "\n",
    "    loss = loss_fn(y_pred.T, ys_t.T)\n",
    "    losses_teo.append(loss.item())\n",
    "\n",
    "    mse_weights_teo.append((((Wtot.squeeze()-beta_tensor.squeeze()) / beta_tensor.squeeze())**2))\n",
    "\n",
    "    if not t % args.print_freq:\n",
    "        print(t, loss.item())\n",
    "        \n",
    "    yt_pred = Wtot @ Xt_t\n",
    "\n",
    "    risk = risk_fn(yt_pred.T, yt_t.T)\n",
    "    risks_teo.append(risk.item())\n",
    "\n",
    "    if not t % args.print_freq:\n",
    "        print(t, risk.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_samples = [int(i) for i in np.geomspace(1, len(risks_teo)-1, num=700)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "risks = np.array(risks_teo)\n",
    "losses = np.array(losses_teo)\n",
    "risks_w = np.row_stack(mse_weights_teo)\n",
    "\n",
    "cmap = matplotlib.cm.get_cmap('viridis')\n",
    "colorList = [cmap(50/1000), cmap(350/1000), cmap(700/1000)]\n",
    "labelList = ['empirical', 'theoretical']\n",
    "\n",
    "plot_all_dims = False\n",
    "\n",
    "extra_axs = 0\n",
    "if plot_all_dims:\n",
    "    extra_axs = args.dim\n",
    "\n",
    "fig, ax = plt.subplots(3 + extra_axs, 1, figsize=(12,12 + 4 * extra_axs))\n",
    "ax[0].set_xscale('log')\n",
    "\n",
    "ax[0].plot(geo_samples, risks[geo_samples], \n",
    "        color=colorList[1], \n",
    "        label=labelList[1],\n",
    "        lw=4)\n",
    "\n",
    "ax[0].legend(loc=1, bbox_to_anchor=(1, 1), fontsize='x-large',\n",
    "    frameon=False, fancybox=True, shadow=True, ncol=1)\n",
    "ax[0].set_ylabel('risk')\n",
    "ax[0].set_xlabel(r'$t$ iterations')\n",
    "\n",
    "ax[1].set_xscale('log')\n",
    "ax[1].plot(geo_samples, losses[geo_samples], \n",
    "        color=colorList[1], \n",
    "        label=labelList[1],\n",
    "        lw=4)\n",
    "\n",
    "ax[1].set_ylabel('loss')\n",
    "ax[1].set_xlabel(r'$t$ iterations')\n",
    "\n",
    "if plot_all_dims:\n",
    "    for i in range(args.dim):\n",
    "        ax[2+i].set_xscale('log')\n",
    "        ax[2+i].plot(geo_samples, risks_w[geo_samples, i], \n",
    "                color=colorList[2], \n",
    "                label=labelList[1],\n",
    "                lw=4)\n",
    "\n",
    "        ax[2+i].set_ylabel('MSE weights, ' + str(i))\n",
    "        ax[2+i].set_xlabel(r'$t$ iterations')\n",
    "\n",
    "\n",
    "ax[-1].set_xscale('log')\n",
    "ax[-1].plot(geo_samples, risks_w[geo_samples, :].mean(axis=-1), \n",
    "        color=colorList[2], \n",
    "        label=labelList[1],\n",
    "        lw=4)\n",
    "\n",
    "ax[-1].set_ylabel('MSE weights')\n",
    "ax[-1].set_xlabel(r'$t$ iterations')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_track = np.array(u_track)\n",
    "z_track = np.row_stack(z_track)\n",
    "\n",
    "fig, ax = plt.subplots(2, 1, figsize=(12, 8))\n",
    "\n",
    "ax[0].set_xscale('log')\n",
    "ax[0].plot(geo_samples, u_track[geo_samples], label=\"u\")\n",
    "#ax[0].plot(geo_samples, risks_w[geo_samples, :].mean(axis=-1), label=\"risk\")\n",
    "ax[0].set_ylabel('u')\n",
    "ax[0].set_xlabel(r'$t$ iterations')\n",
    "\n",
    "\n",
    "#ax[0].plot(geo_samples, losses[geo_samples] )\n",
    "\n",
    "\n",
    "ax[1].set_xscale('log')\n",
    "\n",
    "mean_z = True\n",
    "if mean_z:\n",
    "    ax[1].plot(geo_samples, z_track[geo_samples, :int(args.dim/2)].mean(axis=-1), label=\"z, large\")\n",
    "    ax[1].plot(geo_samples, z_track[geo_samples, int(args.dim/2):].mean(axis=-1), label=\"z, small\")\n",
    "    \n",
    "else:\n",
    "    for i in range(args.dim):\n",
    "        ax[1].plot(geo_samples, z_track[geo_samples, i], label=fr\"$z_{i}$\")\n",
    "    \n",
    "ax[1].legend()\n",
    "ax[1].set_ylabel('z')\n",
    "ax[1].set_xlabel(r'$t$ iterations')\n",
    "\n",
    "# Interaktionen ökar med tiden? Trenden följer lossen (eller lossen följer u)?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "risks = np.array(risks_teo)\n",
    "losses = np.array(losses_teo)\n",
    "risks_w = np.row_stack(mse_weights_teo)\n",
    "\n",
    "cmap = matplotlib.cm.get_cmap('viridis')\n",
    "colorList = [cmap(50/1000), cmap(350/1000), cmap(700/1000)]\n",
    "labelList = ['empirical', 'theoretical']\n",
    "\n",
    "extra_axs = 2\n",
    "fig, ax = plt.subplots(3 + extra_axs, 1, figsize=(12,12 + 4 * extra_axs))\n",
    "\n",
    "ax[0].set_xscale('log')\n",
    "ax[0].plot(geo_samples, risks[geo_samples], \n",
    "        color=colorList[1], \n",
    "        label=labelList[1],\n",
    "        lw=4)\n",
    "\n",
    "ax[0].legend(loc=1, bbox_to_anchor=(1, 1), fontsize='x-large',\n",
    "    frameon=False, fancybox=True, shadow=True, ncol=1)\n",
    "ax[0].set_ylabel('risk')\n",
    "ax[0].set_xlabel(r'$t$ iterations')\n",
    "\n",
    "ax[1].set_xscale('log')\n",
    "ax[1].plot(geo_samples, losses[geo_samples], \n",
    "        color=colorList[1], \n",
    "        label=labelList[1],\n",
    "        lw=4)\n",
    "\n",
    "ax[1].set_ylabel('loss')\n",
    "ax[1].set_xlabel(r'$t$ iterations')\n",
    "\n",
    "p = int(args.dim / 2)\n",
    "ax[2].set_xscale('log')\n",
    "ax[2].plot(geo_samples, risks_w[geo_samples, :p].mean(axis=-1), \n",
    "        color=colorList[2], \n",
    "        label=labelList[1],\n",
    "        lw=4)\n",
    "\n",
    "ax[2].set_ylabel('MSE weights, large')\n",
    "ax[2].set_xlabel(r'$t$ iterations')\n",
    "\n",
    "ax[3].set_xscale('log')\n",
    "ax[3].plot(geo_samples, risks_w[geo_samples, p:].mean(axis=-1), \n",
    "        color=colorList[2], \n",
    "        label=labelList[1],\n",
    "        lw=4)\n",
    "\n",
    "ax[3].set_ylabel('MSE weights, small')\n",
    "ax[3].set_xlabel(r'$t$ iterations')\n",
    "\n",
    "\n",
    "ax[-1].set_xscale('log')\n",
    "ax[-1].plot(geo_samples, risks_w[geo_samples, :].mean(axis=-1), \n",
    "        color=colorList[2], \n",
    "        label=labelList[1],\n",
    "        lw=4)\n",
    "\n",
    "ax[-1].set_ylabel('MSE weights')\n",
    "ax[-1].set_xlabel(r'$t$ iterations')\n",
    "\n",
    "\n",
    "#ax[0].set_ylim([9, 13])\n",
    "#ax[1].set_ylim([80, 105])\n",
    "#ax[2].set_ylim([1, 2.55])\n",
    "#ax[3].set_ylim([0.35, 1.05])\n",
    "#ax[4].set_ylim([1, 1.6])\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(risks_teo[-2000:-1]) #MIIIIIHHH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(beta_tensor + eps_tensor * S**(-0.5)) @ (z**(-1)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.row_stack(mse_weights_teo[-2000:-1]).mean(axis=-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VECTOR FIELD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "v_min, v_max = -10, 10\n",
    "grid_size = 20\n",
    "x, y1 = np.meshgrid(np.linspace(v_min, v_max, grid_size),\n",
    "                    np.linspace(v_min, v_max, grid_size))\n",
    "\n",
    "# Example 1\n",
    "y2_1 = 1\n",
    "\n",
    "eps_0 = ys_t.numpy() - beta @ Xs_t.numpy()\n",
    "eps = (eps_0 @ np.transpose(Uh)).squeeze()\n",
    "\n",
    "d1 = (beta[0] - x * y1) * S[0, 0].numpy() + eps[0] * S[0, 0].numpy()**0.5  #St[0, 0].numpy() - x * y1 * S[0, 0].numpy()\n",
    "d2 = (beta[1] - x * y2_1) * S[0, 1].numpy() + eps[1] * S[0, 1].numpy()**0.5  #St[0, 1].numpy() - x * y2_1 * S[0, 1].numpy()\n",
    "\n",
    "v = d1 * y1 + d2 * y2_1\n",
    "w1 = d1 * x\n",
    "\n",
    "ax[0].quiver(x, y1, v, w1)\n",
    "\n",
    "ax[0].set_xlabel(\"u\")\n",
    "ax[0].set_ylabel(fr\"$z_1$\")\n",
    "ax[0].set_title(f\"$z_2$ = {y2_1}\")\n",
    "\n",
    "\n",
    "# Example 2\n",
    "y2_2 = 5\n",
    "d2_2 = (beta[1] - x * y2_2) * S[0, 1].numpy() + eps[1] * S[0, 1].numpy()**0.5  #St[0, 1].numpy() - x * y2_2 * S[0, 1].numpy()\n",
    "\n",
    "v_2 = d1 * y1 + d2_2 * y2_2\n",
    "\n",
    "ax[1].quiver(x, y1, v_2, w1)\n",
    "\n",
    "ax[1].set_xlabel(\"u\")\n",
    "ax[1].set_ylabel(fr\"$z_1$\")\n",
    "\n",
    "ax[1].set_title(f\"$z_2$ = {y2_2}\")\n",
    "\n",
    "\n",
    "# Example 3\n",
    "y2_3 = 10\n",
    "d2_3 = (beta[1] - x * y2_3) * S[0, 1].numpy() + eps[1] * S[0, 1].numpy()**0.5  #St[0, 1].numpy() - x * y2_2 * S[0, 1].numpy()\n",
    "\n",
    "v_3 = d1 * y1 + d2_3 * y2_3\n",
    "\n",
    "ax[2].quiver(x, y1, v_3, w1)\n",
    "\n",
    "ax[2].set_xlabel(\"u\")\n",
    "ax[2].set_ylabel(fr\"$z_1$\")\n",
    "\n",
    "ax[2].set_title(f\"$z_2$ = {y2_3}\")\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "v_min, v_max = -10, 10\n",
    "grid_size = 20\n",
    "x, y2 = np.meshgrid(np.linspace(v_min, v_max, grid_size),\n",
    "                    np.linspace(v_min, v_max, grid_size))\n",
    "\n",
    "# Example 1\n",
    "y1_1 = 1\n",
    "\n",
    "d1 = (beta[0] - x * y1_1) * S[0, 0].numpy() + eps[0] * S[0, 0].numpy()**0.5 # St[0, 0].numpy() - x * y2 * S[0, 0].numpy()\n",
    "d2 = (beta[1] - x * y2) * S[0, 1].numpy() + eps[1] * S[0, 1].numpy()**0.5  #St[0, 1].numpy() - x * y1_1 * S[0, 1].numpy()\n",
    "\n",
    "v = d1 * y1_1 + d2 * y2\n",
    "w2 = d2 * x\n",
    "\n",
    "ax[0].quiver(x, y2, v, w2)\n",
    "\n",
    "ax[0].set_xlabel(\"u\")\n",
    "ax[0].set_ylabel(fr\"$z_2$\")\n",
    "ax[0].set_title(f\"$z_1$ = {y1_1}\")\n",
    "\n",
    "\n",
    "# Example 2\n",
    "y1_2 = 2\n",
    "d1_2 = (beta[0] - x * y1_2) * S[0, 0].numpy() + eps[0] * S[0, 0].numpy()**0.5 # St[0, 0].numpy() - x * y1_2 * S[0, 0].numpy()\n",
    "\n",
    "v_2 = d1_2 * y1_2 + d2 * y2\n",
    "\n",
    "ax[1].quiver(x, y2, v_2, w2)\n",
    "\n",
    "ax[1].set_xlabel(\"u\")\n",
    "ax[1].set_ylabel(fr\"$z_2$\")\n",
    "\n",
    "ax[1].set_title(f\"$z_1$ = {y1_2}\")\n",
    "\n",
    "\n",
    "# Example 3\n",
    "y1_3 = 10\n",
    "d1_3 = (beta[0] - x * y1_2) * S[0, 0].numpy() + eps[0] * S[0, 0].numpy()**0.5 # St[0, 0].numpy() - x * y1_2 * S[0, 0].numpy()\n",
    "\n",
    "v_3 = d1_3 * y1_3 + d2 * y2\n",
    "\n",
    "ax[2].quiver(x, y2, v_3, w2)\n",
    "\n",
    "ax[2].set_xlabel(\"u\")\n",
    "ax[2].set_ylabel(fr\"$z_2$\")\n",
    "\n",
    "ax[2].set_title(f\"$z_1$ = {y1_3}\")\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "v_min, v_max = -20, 20\n",
    "grid_size = 20\n",
    "y1, y2 = np.meshgrid(np.linspace(v_min, v_max, grid_size),\n",
    "                    np.linspace(v_min, v_max, grid_size))\n",
    "\n",
    "\n",
    "# Example 1\n",
    "x_1 = 0.1\n",
    "d1 = (beta[0] - x_1 * y1) * S[0, 0].numpy() + eps[0] * S[0, 0].numpy()**0.5 #St[0, 0].numpy() - x * y1 * S[0, 0].numpy()\n",
    "d2 = (beta[1] - x_1 * y2) * S[0, 1].numpy() + eps[1] * S[0, 1].numpy()**0.5 #St[0, 1].numpy() - x * y2_1 * S[0, 1].numpy()\n",
    "\n",
    "w1 = d1 * x_1\n",
    "w2 = d2 * x_1\n",
    "\n",
    "ax[0].quiver(y1, y2, w1, w2)\n",
    "\n",
    "ax[0].set_xlabel(fr\"$z_1$\")\n",
    "ax[0].set_ylabel(fr\"$z_2$\")\n",
    "ax[0].set_title(f\"u = {x_1}\")\n",
    "\n",
    "\n",
    "# Example 2\n",
    "x_2 = 1\n",
    "d1_2 = (beta[0] - x_2 * y1) * S[0, 0].numpy() + eps_0[0, 0] * S[0, 0].numpy()**0.5 #St[0, 0].numpy() - x_2 * y1 * S[0, 0].numpy()\n",
    "d2_2 = (beta[1] - x_2 * y2) * S[0, 1].numpy() + eps_0[0, 1] * S[0, 1].numpy()**0.5 #St[0, 1].numpy() - x_2 * y2 * S[0, 1].numpy()\n",
    "\n",
    "w1_2 = d1_2 * x_2\n",
    "w2_2 = d2_2 * x_2\n",
    "\n",
    "ax[1].quiver(y1, y2, w1_2, w2_2)\n",
    "\n",
    "ax[1].set_xlabel(fr\"$z_1$\")\n",
    "ax[1].set_ylabel(fr\"$z_2$\")\n",
    "ax[1].set_title(f\"u = {x_2}\")\n",
    "\n",
    "\n",
    "# Example 3\n",
    "x_3 = 10\n",
    "\n",
    "d1_3 = (beta[0] - x_3 * y1) * S[0, 0].numpy() + eps[0] * S[0, 0].numpy()**0.5 #St[0, 0].numpy() - x_2 * y1 * S[0, 0].numpy()\n",
    "d2_3 = (beta[1] - x_3 * y2) * S[0, 1].numpy() + eps[1] * S[0, 1].numpy()**0.5 #St[0, 1].numpy() - x_2 * y2 * S[0, 1].numpy()\n",
    "\n",
    "w1_3 = d1_3 * x_3\n",
    "w2_3 = d2_3 * x_3\n",
    "\n",
    "ax[2].quiver(y1, y2, w1_3, w2_3)\n",
    "\n",
    "ax[2].set_xlabel(fr\"$z_1$\")\n",
    "ax[2].set_ylabel(fr\"$z_2$\")\n",
    "ax[2].set_title(f\"u = {x_3}\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# För kappa > 1 så rör vi oss främst i z1-riktning, men stort u jämnar ut skillnaderna?\n",
    "# Vi bör se att vi rör oss längre ifrån de sanna vikterna vid något tillfälle; men vet inte om vi ser det?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=plt.figaspect(0.5))\n",
    "ax = fig.add_subplot(1, 2, 1, projection='3d')\n",
    "\n",
    "\n",
    "\n",
    "v_min, v_max = -20, 20\n",
    "grid_size = 10\n",
    "x, y1, y2 = np.meshgrid(np.linspace(v_min, v_max, grid_size),\n",
    "                        np.linspace(v_min, v_max, grid_size),\n",
    "                        np.linspace(v_min, v_max, grid_size))\n",
    "\n",
    "\n",
    "d1 = (beta[0] - x * y1) * S[0, 0].numpy() + eps[0] * S[0, 0].numpy()**0.5 #St[0, 0].numpy() - x * y1 * S[0, 0].numpy()\n",
    "d2 = (beta[1] - x * y2) * S[0, 1].numpy() + eps[1] * S[0, 1].numpy()**0.5 #St[0, 1].numpy() - x * y2 * S[0, 1].numpy()\n",
    "\n",
    "v = d1 * y1 + d2 * y2\n",
    "w1 = d1 * x\n",
    "w2 = d2 * x\n",
    "\n",
    "ax.quiver(x, y1, y2, v, w1, w2, length=0.0001)\n",
    "\n",
    "ax.set_xlabel(fr\"$u$\")\n",
    "ax.set_ylabel(fr\"$z_1$\")\n",
    "ax.set_zlabel(fr\"$z_2$\")\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wtot\n",
    "\n",
    "fig, ax = plt.subplots(1, 5, figsize=(20, 4))\n",
    "\n",
    "\n",
    "# u fixed, #1\n",
    "v_min, v_max = -20, 20\n",
    "grid_size = 10\n",
    "x = 1\n",
    "y1, y2 = np.meshgrid(np.linspace(v_min, v_max, grid_size),\n",
    "                     np.linspace(v_min, v_max, grid_size))\n",
    "\n",
    "\n",
    "d1 = (beta[0] - x * y1) * S[0, 0].numpy() + eps[0] * S[0, 0].numpy()**0.5 #St[0, 0].numpy() - x * y1 * S[0, 0].numpy()\n",
    "d2 = (beta[1] - x * y2) * S[0, 1].numpy() + eps[1] * S[0, 1].numpy()**0.5 #St[0, 1].numpy() - x * y2 * S[0, 1].numpy()\n",
    "\n",
    "v = d1 * y1 + d2 * y2\n",
    "w1 = d1 * x\n",
    "w2 = d2 * x\n",
    "\n",
    "# Total weights \n",
    "p1 = x * y1\n",
    "p2 = x * y2\n",
    "\n",
    "q1 = v * y1 + w1 * x\n",
    "q2 = v * y2 + w2 * x\n",
    "\n",
    "ax[0].quiver(p1, p2, q1, q2)\n",
    "\n",
    "ax[0].set_xlabel(fr\"$w_1$\")\n",
    "ax[0].set_ylabel(fr\"$w_2$\")\n",
    "ax[0].set_title(f\"u = {x}\")\n",
    "\n",
    "\n",
    "# u fixed, #2\n",
    "v_min, v_max = -20, 20\n",
    "grid_size = 10\n",
    "x = 5\n",
    "y1, y2 = np.meshgrid(np.linspace(v_min, v_max, grid_size),\n",
    "                     np.linspace(v_min, v_max, grid_size))\n",
    "\n",
    "\n",
    "d1 = (beta[0] - x * y1) * S[0, 0].numpy() + eps[0] * S[0, 0].numpy()**0.5 #St[0, 0].numpy() - x * y1 * S[0, 0].numpy()\n",
    "d2 = (beta[1] - x * y2) * S[0, 1].numpy() + eps[1] * S[0, 1].numpy()**0.5 #St[0, 1].numpy() - x * y2 * S[0, 1].numpy()\n",
    "\n",
    "v = d1 * y1 + d2 * y2\n",
    "w1 = d1 * x\n",
    "w2 = d2 * x\n",
    "\n",
    "# Total weights \n",
    "p1 = x * y1\n",
    "p2 = x * y2\n",
    "\n",
    "q1 = v * y1 + w1 * x\n",
    "q2 = v * y2 + w2 * x\n",
    "\n",
    "ax[1].quiver(p1, p2, q1, q2)\n",
    "\n",
    "ax[1].set_xlabel(fr\"$w_1$\")\n",
    "ax[1].set_ylabel(fr\"$w_2$\")\n",
    "ax[1].set_title(f\"u = {x}\")\n",
    "\n",
    "\n",
    "# u fixed, #3\n",
    "v_min, v_max = -20, 20\n",
    "grid_size = 10\n",
    "x = 10\n",
    "y1, y2 = np.meshgrid(np.linspace(v_min, v_max, grid_size),\n",
    "                     np.linspace(v_min, v_max, grid_size))\n",
    "\n",
    "\n",
    "d1 = (beta[0] - x * y1) * S[0, 0].numpy() + eps[0] * S[0, 0].numpy()**0.5 #St[0, 0].numpy() - x * y1 * S[0, 0].numpy()\n",
    "d2 = (beta[1] - x * y2) * S[0, 1].numpy() + eps[1] * S[0, 1].numpy()**0.5 #St[0, 1].numpy() - x * y2 * S[0, 1].numpy()\n",
    "\n",
    "v = d1 * y1 + d2 * y2\n",
    "w1 = d1 * x\n",
    "w2 = d2 * x\n",
    "\n",
    "# Total weights \n",
    "p1 = x * y1\n",
    "p2 = x * y2\n",
    "\n",
    "q1 = v * y1 + w1 * x\n",
    "q2 = v * y2 + w2 * x\n",
    "\n",
    "ax[2].quiver(p1, p2, q1, q2)\n",
    "\n",
    "ax[2].set_xlabel(fr\"$w_1$\")\n",
    "ax[2].set_ylabel(fr\"$w_2$\")\n",
    "ax[2].set_title(f\"u = {x}\")\n",
    "\n",
    "\n",
    "# z_1 fixed \n",
    "y1 = 5\n",
    "x, y2 = np.meshgrid(np.linspace(v_min, v_max, grid_size),\n",
    "                    np.linspace(v_min, v_max, grid_size))\n",
    "\n",
    "\n",
    "d1 = (beta[0] - x * y1) * S[0, 0].numpy() + eps[0] * S[0, 0].numpy()**0.5 #St[0, 0].numpy() - x * y1 * S[0, 0].numpy()\n",
    "d2 = (beta[1] - x * y2) * S[0, 1].numpy() + eps[1] * S[0, 1].numpy()**0.5 #St[0, 1].numpy() - x * y2 * S[0, 1].numpy()\n",
    "\n",
    "v = d1 * y1 + d2 * y2\n",
    "w1 = d1 * x\n",
    "w2 = d2 * x\n",
    "\n",
    "# Total weights \n",
    "p1 = x * y1\n",
    "p2 = x * y2\n",
    "\n",
    "q1 = v * y1 + w1 * x\n",
    "q2 = v * y2 + w2 * x\n",
    "\n",
    "ax[3].quiver(p1, p2, q1, q2)\n",
    "\n",
    "ax[3].set_xlabel(fr\"$w_1$\")\n",
    "ax[3].set_ylabel(fr\"$w_2$\")\n",
    "ax[3].set_title(f\"$z_1$ = {y1}\")\n",
    "\n",
    "\n",
    "\n",
    "# z_2 fixed \n",
    "y2 = 5\n",
    "x, y1 = np.meshgrid(np.linspace(v_min, v_max, grid_size),\n",
    "                    np.linspace(v_min, v_max, grid_size))\n",
    "\n",
    "\n",
    "d1 = (beta[0] - x * y1) * S[0, 0].numpy() + eps[0] * S[0, 0].numpy()**0.5 #St[0, 0].numpy() - x * y1 * S[0, 0].numpy()\n",
    "d2 = (beta[1] - x * y2) * S[0, 1].numpy() + eps[1] * S[0, 1].numpy()**0.5 #St[0, 1].numpy() - x * y2 * S[0, 1].numpy()\n",
    "\n",
    "v = d1 * y1 + d2 * y2\n",
    "w1 = d1 * x\n",
    "w2 = d2 * x\n",
    "\n",
    "# Total weights \n",
    "p1 = x * y1\n",
    "p2 = x * y2\n",
    "\n",
    "q1 = v * y1 + w1 * x\n",
    "q2 = v * y2 + w2 * x\n",
    "\n",
    "ax[4].quiver(p1, p2, q1, q2)\n",
    "\n",
    "ax[4].set_xlabel(fr\"$w_1$\")\n",
    "ax[4].set_ylabel(fr\"$w_2$\")\n",
    "ax[4].set_title(f\"$z_2$ = {y2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSE\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "\n",
    "# u fixed \n",
    "v_min, v_max = -5, 5\n",
    "grid_size = 10\n",
    "x = 5\n",
    "y1, y2 = np.meshgrid(np.linspace(v_min, v_max, grid_size),\n",
    "                     np.linspace(v_min, v_max, grid_size))\n",
    "\n",
    "\n",
    "d1 = (beta[0] - x * y1) * S[0, 0].numpy() + eps[0] * S[0, 0].numpy()**0.5 #St[0, 0].numpy() - x * y1 * S[0, 0].numpy()\n",
    "d2 = (beta[1] - x * y2) * S[0, 1].numpy() + eps[1] * S[0, 1].numpy()**0.5 #St[0, 1].numpy() - x * y2 * S[0, 1].numpy()\n",
    "\n",
    "v = d1 * y1 + d2 * y2\n",
    "w1 = d1 * x\n",
    "w2 = d2 * x\n",
    "\n",
    "# Total weights \n",
    "p1 = x * y1\n",
    "p2 = x * y2\n",
    "\n",
    "q1 = v * y1 + w1 * x\n",
    "q2 = v * y2 + w2 * x\n",
    "\n",
    "r = (beta[0] - p1)**2 + (beta[1] - p2)**2 \n",
    "\n",
    "beta_v = beta @ np.transpose(V)  # TODO: do all other equations assume V=I or does it not matter?\n",
    "rm = (x * y1 - beta_v[0]) * q1 + (x * y2 - beta_v[1]) * q2 \n",
    "\n",
    "ax[0].quiver(y1, r, w1, rm)\n",
    "\n",
    "ax[0].set_xlabel(fr\"$z_1$\")\n",
    "ax[0].set_ylabel(fr\"$L$\")\n",
    "ax[0].set_title(f\"u = {x}\")\n",
    "\n",
    "\n",
    "# z_1 fixed \n",
    "y1 = 5\n",
    "x, y2 = np.meshgrid(np.linspace(v_min, v_max, grid_size),\n",
    "                    np.linspace(v_min, v_max, grid_size))\n",
    "\n",
    "\n",
    "d1 = (beta[0] - x * y1) * S[0, 0].numpy() + eps[0] * S[0, 0].numpy()**0.5 #St[0, 0].numpy() - x * y1 * S[0, 0].numpy()\n",
    "d2 = (beta[1] - x * y2) * S[0, 1].numpy() + eps[1] * S[0, 1].numpy()**0.5 #St[0, 1].numpy() - x * y2 * S[0, 1].numpy()\n",
    "\n",
    "v = d1 * y1 + d2 * y2\n",
    "w1 = d1 * x\n",
    "w2 = d2 * x\n",
    "\n",
    "# Total weights \n",
    "p1 = x * y1\n",
    "p2 = x * y2\n",
    "\n",
    "q1 = v * y1 + w1 * x\n",
    "q2 = v * y2 + w2 * x\n",
    "\n",
    "r = (beta[0] - p1)**2 + (beta[1] - p2)**2 # Tar V ut sig självt?\n",
    "\n",
    "beta_v = beta @ np.transpose(V)  # TODO: do all other equations assume V=I or does it not matter?\n",
    "rm = (x * y1 - beta_v[0]) * q1 + (x * y2 - beta_v[1]) * q2 \n",
    "\n",
    "ax[1].quiver(y2, r, w2, rm)\n",
    "\n",
    "ax[1].set_xlabel(fr\"$z_2$\")\n",
    "ax[1].set_ylabel(fr\"$L$\")\n",
    "ax[1].set_title(f\"$z_1$ = {y1}\")\n",
    "\n",
    "\n",
    "\n",
    "# z_2 fixed \n",
    "y2 = 5\n",
    "x, y1 = np.meshgrid(np.linspace(v_min, v_max, grid_size),\n",
    "                    np.linspace(v_min, v_max, grid_size))\n",
    "\n",
    "\n",
    "d1 = (beta[0] - x * y1) * S[0, 0].numpy() + eps[0] * S[0, 0].numpy()**0.5 #St[0, 0].numpy() - x * y1 * S[0, 0].numpy()\n",
    "d2 = (beta[1] - x * y2) * S[0, 1].numpy() + eps[1] * S[0, 1].numpy()**0.5 #St[0, 1].numpy() - x * y2 * S[0, 1].numpy()\n",
    "\n",
    "v = d1 * y1 + d2 * y2\n",
    "w1 = d1 * x\n",
    "w2 = d2 * x\n",
    "\n",
    "# Total weights \n",
    "p1 = x * y1\n",
    "p2 = x * y2\n",
    "\n",
    "q1 = v * y1 + w1 * x\n",
    "q2 = v * y2 + w2 * x\n",
    "\n",
    "r = (beta[0] - p1)**2 + (beta[1] - p2)**2 # Tar V ut sig självt?\n",
    "\n",
    "beta_v = beta @ np.transpose(V)  # TODO: do all other equations assume V=I or does it not matter? Se logg 22/11 09:42.\n",
    "rm = (x * y1 - beta_v[0]) * q1 + (x * y2 - beta_v[1]) * q2 \n",
    "\n",
    "ax[2].quiver(y1, r, w1, rm)\n",
    "\n",
    "ax[2].set_xlabel(fr\"$z_1$\")\n",
    "ax[2].set_ylabel(fr\"$L$\")\n",
    "ax[2].set_title(f\"$z_2$ = {y2}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
