{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High-dimensional dynamics of generalization error in neural networks\n",
    "\n",
    "Attempt to reproduce Figure 5B in the paper.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import datetime\n",
    "import pathlib\n",
    "import random\n",
    "import json\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import torch\n",
    "\n",
    "import sys\n",
    "sys.path.append('../code/')\n",
    "from linear_utils import linear_model\n",
    "from train_utils import save_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# argument written in command line format\n",
    "cli_args = '--seed 12 --save-results --risk-loss L2 -t 10000 -w 0.1 0.1 --lr 0.001 -d 2 -n 10 --hidden 50 --sigmas 1 --kappa 5'\n",
    "sigma_noise = 1.0\n",
    "beta = np.array([1.0, 1.0])\n",
    "transform_data = True\n",
    "\n",
    "#cli_args = '--seed 12 --save-results --jacobian --risk-loss L2 -t 20000 -w 0.1 0.1 --lr 0.00001 -d 50 -n 1000 --hidden 50 --sigmas 1 --kappa 3'\n",
    "#sigma_noise = 1.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "A fully-connected ReLU network with one hidden layer, trained to predict y from x\n",
    "by minimizing the MSE loss.\n",
    "\"\"\"\n",
    "\n",
    "# get CLI parameters\n",
    "parser = argparse.ArgumentParser(description='CLI parameters for training')\n",
    "parser.add_argument('--root', type=str, default='', metavar='DIR',\n",
    "                    help='Root directory')\n",
    "parser.add_argument('-t', '--iterations', type=int, default=1e4, metavar='ITERATIONS',\n",
    "                    help='Iterations (default: 1e4)')\n",
    "parser.add_argument('-n', '--samples', type=int, default=100, metavar='N',\n",
    "                    help='Number of samples (default: 100)')\n",
    "parser.add_argument('--print-freq', type=int, default=1000,\n",
    "                    help='CLI output printing frequency (default: 1000)')\n",
    "parser.add_argument('--gpu', type=int, default=None,\n",
    "                    help='Number of GPUS to use')\n",
    "parser.add_argument('--seed', type=int, default=None,\n",
    "                    help='Random seed')                        \n",
    "parser.add_argument('-d', '--dim', type=int, default=50, metavar='DIMENSION',\n",
    "                    help='Feature dimension (default: 50)')\n",
    "parser.add_argument('--hidden', type=int, default=200, metavar='DIMENSION',\n",
    "                    help='Hidden layer dimension (default: 200)')\n",
    "parser.add_argument('--sigmas', type=str, default=None,\n",
    "                    help='Sigmas')     \n",
    "parser.add_argument('-r','--s-range', nargs='*', type=float,\n",
    "                    help='Range for sigmas')\n",
    "parser.add_argument('--kappa', type=float,\n",
    "                    help='Eigenvalue ratio')\n",
    "parser.add_argument('-w','--scales', nargs='*', type=float,\n",
    "                    help='scale of the weights')\n",
    "parser.add_argument('--lr', type=float, default=1e-4, nargs='*', metavar='LR',\n",
    "                    help='learning rate (default: 1e-4)')              \n",
    "parser.add_argument('--normalized', action='store_true', default=False,\n",
    "                    help='normalize sample norm across features')\n",
    "parser.add_argument('--risk-loss', type=str, default='MSE', metavar='LOSS',\n",
    "                    help='Loss for validation')\n",
    "parser.add_argument('--jacobian', action='store_true', default=False,\n",
    "                    help='compute the SVD of the jacobian of the network')\n",
    "parser.add_argument('--save-results', action='store_true', default=False,\n",
    "                    help='Save the results for plots')\n",
    "parser.add_argument('--details', type=str, metavar='N',\n",
    "                    default='no_detail_given',\n",
    "                    help='details about the experimental setup')\n",
    "\n",
    "\n",
    "args = parser.parse_args(cli_args.split())\n",
    "\n",
    "# directories\n",
    "root = pathlib.Path(args.root) if args.root else pathlib.Path.cwd().parent\n",
    "\n",
    "current_date = str(datetime.datetime.today().strftime('%Y-%m-%d-%H-%M-%S'))\n",
    "args.outpath = (pathlib.Path.cwd().parent / 'results' / 'two_layer_nn' /  current_date)\n",
    "\n",
    "if args.save_results:\n",
    "    args.outpath.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "if args.seed is not None:\n",
    "    random.seed(args.seed)\n",
    "    torch.manual_seed(args.seed)\n",
    "    np.random.seed(args.seed)\n",
    "    \n",
    "device = torch.device('cpu')\n",
    "# device = torch.device('cuda') # Uncomment this to run on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_out = 1      # dimension of y\n",
    "\n",
    "# sample training set from the linear model\n",
    "lin_model = linear_model(args.dim, sigma_noise=sigma_noise, beta=beta, normalized=False, sigmas=args.sigmas, s_range=args.s_range, coupled_noise=False, transform_data=transform_data, kappa=args.kappa)\n",
    "Xs, ys = lin_model.sample(args.samples, train=True)\n",
    "Xs = torch.Tensor(Xs).to(device)\n",
    "ys = torch.Tensor(ys.reshape((-1,1))).to(device)\n",
    "\n",
    "# sample the set for empirical risk calculation\n",
    "Xt, yt = lin_model.sample(args.samples, train=False)\n",
    "Xt = torch.Tensor(Xt).to(device)\n",
    "yt = torch.Tensor(yt.reshape((-1,1))).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss functions\n",
    "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "risk_fn = torch.nn.L1Loss(reduction='mean') if args.risk_loss == 'L1' else loss_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Empirical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(\n",
    "           torch.nn.Linear(args.dim, args.hidden, bias=False),\n",
    "           torch.nn.Linear(args.hidden, d_out, bias=False),\n",
    "         ).to(device)      \n",
    "                \n",
    "# use kaiming initialization                \n",
    "if args.scales:\n",
    "    i = 0\n",
    "    with torch.no_grad():\n",
    "        for m in model:\n",
    "            if type(m) == torch.nn.Linear:\n",
    "                if i == 0:\n",
    "                    torch.nn.init.kaiming_normal_(m.weight, a=math.sqrt(5))\n",
    "                    m.weight.data = torch.mul(m.weight.data, args.scales[0])\n",
    "                if i == 1:\n",
    "                    torch.nn.init.kaiming_uniform_(m.weight, a=math.sqrt(5))\n",
    "                    m.weight.data = torch.mul(m.weight.data, args.scales[1])\n",
    "                i += 1\n",
    "                \n",
    "\n",
    "# use same learning rate for the two layers\n",
    "if isinstance(args.lr, list):\n",
    "    stepsize = [max(args.lr)] * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the network\n",
    "losses_emp = []\n",
    "risks_emp = []\n",
    "mse_weights_emp = []\n",
    "for t in range(int(args.iterations)):\n",
    "    y_pred = model(Xs)\n",
    "\n",
    "    loss = loss_fn(y_pred, ys)\n",
    "    losses_emp.append(loss.item())\n",
    "\n",
    "    if not t % args.print_freq:\n",
    "        print(t, loss.item())\n",
    "\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        i = 0\n",
    "        w_tot = torch.diag(torch.ones(args.dim))\n",
    "        for param in model.parameters():\n",
    "            param.data -= stepsize[i] * param.grad\n",
    "            w_tot = w_tot @ param.data.t()\n",
    "\n",
    "            if not len(param.shape) > 1:\n",
    "                i += 1\n",
    "        \n",
    "        w_tot = w_tot.squeeze()\n",
    "        assert w_tot.shape == beta.shape\n",
    "        mse_weights_emp.append(((w_tot-beta)**2))\n",
    "                \n",
    "            \n",
    "    with torch.no_grad():\n",
    "        yt_pred = model(Xt)\n",
    "        \n",
    "        risk = risk_fn(yt_pred, yt)\n",
    "        risks_emp.append(risk.item())\n",
    "\n",
    "        if not t % args.print_freq:\n",
    "            print(t, risk.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_samples = [int(i) for i in np.geomspace(1, len(risks_emp)-1, num=700)]\n",
    "risks_w = np.row_stack(mse_weights_emp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "risks = np.array(risks_emp)\n",
    "losses = np.array(losses_emp)\n",
    "risks_w = np.row_stack(mse_weights_emp)\n",
    "\n",
    "cmap = matplotlib.cm.get_cmap('viridis')\n",
    "colorList = [cmap(50/1000), cmap(350/1000), cmap(700/1000)]\n",
    "labelList = ['empirical', 'theoretical']\n",
    "\n",
    "fig, ax = plt.subplots(3 + args.dim, 1, figsize=(12,12 + 4 * args.dim))\n",
    "ax[0].set_xscale('log')\n",
    "\n",
    "ax[0].plot(geo_samples, risks[geo_samples], \n",
    "        color=colorList[1], \n",
    "        label=labelList[0],\n",
    "        lw=4)\n",
    "\n",
    "ax[0].legend(loc=1, bbox_to_anchor=(1, 1), fontsize='x-large',\n",
    "    frameon=False, fancybox=True, shadow=True, ncol=1)\n",
    "ax[0].set_ylabel('risk')\n",
    "ax[0].set_xlabel(r'$t$ iterations')\n",
    "\n",
    "ax[1].set_xscale('log')\n",
    "ax[1].plot(geo_samples, losses[geo_samples], \n",
    "        color=colorList[1], \n",
    "        label=labelList[0],\n",
    "        lw=4)\n",
    "\n",
    "ax[1].set_ylabel('loss')\n",
    "ax[1].set_xlabel(r'$t$ iterations')\n",
    "\n",
    "for i in range(args.dim):\n",
    "    ax[2+i].set_xscale('log')\n",
    "    ax[2+i].plot(geo_samples, risks_w[geo_samples, i], \n",
    "            color=colorList[2], \n",
    "            label=labelList[0],\n",
    "            lw=4)\n",
    "\n",
    "    ax[2+i].set_ylabel('MSE weights, ' + str(i))\n",
    "    ax[2+i].set_xlabel(r'$t$ iterations')\n",
    "    \n",
    "\n",
    "ax[-1].set_xscale('log')\n",
    "ax[-1].plot(geo_samples, risks_w[geo_samples, :].mean(axis=-1), \n",
    "        color=colorList[2], \n",
    "        label=labelList[0],\n",
    "        lw=4)\n",
    "\n",
    "ax[-1].set_ylabel('MSE weights')\n",
    "ax[-1].set_xlabel(r'$t$ iterations')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(risks_emp[1000:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theoretical "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dt(u, z, S, St):\n",
    "    assert S.shape == z.shape\n",
    "    return (St - u * z * S)\n",
    "\n",
    "def dzdt(u, z, S, St):\n",
    "    \n",
    "    return u * dt(u, z, S, St)\n",
    "\n",
    "\n",
    "def dudt(u, z, S, St):\n",
    "    assert S.shape == z.shape\n",
    "    \n",
    "    return (dt(u, z, S, St) @ z.T).squeeze()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the sake of not messing anything up\n",
    "Xs_t, ys_t, Xt_t, yt_t = Xs.T, ys.T, Xt.T, yt.T\n",
    "\n",
    "V, s, _ = np.linalg.svd(Xs_t, full_matrices=True)\n",
    "S = torch.tensor(np.concatenate((s, np.zeros(args.dim - s.shape[0]))).reshape(1, -1), dtype=torch.float32)\n",
    "St = ys_t @ Xs_t.T @ torch.tensor(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation\n",
    "w_init = args.scales[0] * 10\n",
    "u = torch.normal(0, torch.tensor(w_init))\n",
    "z = torch.normal(0, torch.tensor(w_init), size=(1, args.dim))\n",
    "print(u)\n",
    "print(z)\n",
    "\n",
    "losses_teo = []\n",
    "risks_teo = []\n",
    "mse_weights_teo = []\n",
    "for t in range(int(args.iterations)):\n",
    "    \n",
    "    u = u + args.lr[0] * 10 * dudt(u, z, S, St)\n",
    "    z = z + args.lr[0] * 10 * dzdt(u, z, S, St)\n",
    "    \n",
    "    \n",
    "    Wtot = u * z @ V.T\n",
    "\n",
    "    y_pred = Wtot @ Xs_t\n",
    "\n",
    "    loss = loss_fn(y_pred.T, ys_t.T)\n",
    "    losses_teo.append(loss.item())\n",
    "\n",
    "    mse_weights_teo.append(((Wtot.squeeze()-beta)**2))\n",
    "\n",
    "    if not t % args.print_freq:\n",
    "        print(t, loss.item())\n",
    "        \n",
    "    yt_pred = Wtot @ Xt_t\n",
    "\n",
    "    risk = risk_fn(yt_pred.T, yt_t.T)\n",
    "    risks_teo.append(risk.item())\n",
    "\n",
    "    if not t % args.print_freq:\n",
    "        print(t, risk.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_samples = [int(i) for i in np.geomspace(1, len(risks_teo)-1, num=700)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "risks = np.array(risks_teo)\n",
    "losses = np.array(losses_teo)\n",
    "risks_w = np.row_stack(mse_weights_teo)\n",
    "\n",
    "cmap = matplotlib.cm.get_cmap('viridis')\n",
    "colorList = [cmap(50/1000), cmap(350/1000), cmap(700/1000)]\n",
    "labelList = ['empirical', 'theoretical']\n",
    "\n",
    "fig, ax = plt.subplots(3 + args.dim, 1, figsize=(12,12 + 4 * args.dim))\n",
    "ax[0].set_xscale('log')\n",
    "\n",
    "ax[0].plot(geo_samples, risks[geo_samples], \n",
    "        color=colorList[1], \n",
    "        label=labelList[1],\n",
    "        lw=4)\n",
    "\n",
    "ax[0].legend(loc=1, bbox_to_anchor=(1, 1), fontsize='x-large',\n",
    "    frameon=False, fancybox=True, shadow=True, ncol=1)\n",
    "ax[0].set_ylabel('risk')\n",
    "ax[0].set_xlabel(r'$t$ iterations')\n",
    "\n",
    "ax[1].set_xscale('log')\n",
    "ax[1].plot(geo_samples, losses[geo_samples], \n",
    "        color=colorList[1], \n",
    "        label=labelList[1],\n",
    "        lw=4)\n",
    "\n",
    "ax[1].set_ylabel('loss')\n",
    "ax[1].set_xlabel(r'$t$ iterations')\n",
    "\n",
    "for i in range(args.dim):\n",
    "    ax[2+i].set_xscale('log')\n",
    "    ax[2+i].plot(geo_samples, risks_w[geo_samples, i], \n",
    "            color=colorList[2], \n",
    "            label=labelList[1],\n",
    "            lw=4)\n",
    "\n",
    "    ax[2+i].set_ylabel('MSE weights, ' + str(i))\n",
    "    ax[2+i].set_xlabel(r'$t$ iterations')\n",
    "    \n",
    "\n",
    "ax[-1].set_xscale('log')\n",
    "ax[-1].plot(geo_samples, risks_w[geo_samples, :].mean(axis=-1), \n",
    "        color=colorList[2], \n",
    "        label=labelList[1],\n",
    "        lw=4)\n",
    "\n",
    "ax[-1].set_ylabel('MSE weights')\n",
    "ax[-1].set_xlabel(r'$t$ iterations')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(risks_teo[100:1000]) #MIIIIIHHH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.row_stack(mse_weights_teo[100:1000]).mean(axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
