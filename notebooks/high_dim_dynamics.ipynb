{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High-dimensional dynamics of generalization error in neural networks\n",
    "\n",
    "Attempt to reproduce Figure 5B in the paper.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import datetime\n",
    "import pathlib\n",
    "import random\n",
    "import json\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import torch\n",
    "\n",
    "import sys\n",
    "sys.path.append('../code/')\n",
    "from linear_utils import linear_model\n",
    "from train_utils import save_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# argument written in command line format\n",
    "cli_args = '--seed 12 --save-results --jacobian --risk-loss L2 -t 50000 -w 0.01 0.01 --lr 0.000001 -d 50 -n 100 --hidden 50 --sigmas 1'\n",
    "sigma_noise = 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "A fully-connected ReLU network with one hidden layer, trained to predict y from x\n",
    "by minimizing the MSE loss.\n",
    "\"\"\"\n",
    "\n",
    "# get CLI parameters\n",
    "parser = argparse.ArgumentParser(description='CLI parameters for training')\n",
    "parser.add_argument('--root', type=str, default='', metavar='DIR',\n",
    "                    help='Root directory')\n",
    "parser.add_argument('-t', '--iterations', type=int, default=1e4, metavar='ITERATIONS',\n",
    "                    help='Iterations (default: 1e4)')\n",
    "parser.add_argument('-n', '--samples', type=int, default=100, metavar='N',\n",
    "                    help='Number of samples (default: 100)')\n",
    "parser.add_argument('--print-freq', type=int, default=100,\n",
    "                    help='CLI output printing frequency (default: 1000)')\n",
    "parser.add_argument('--gpu', type=int, default=None,\n",
    "                    help='Number of GPUS to use')\n",
    "parser.add_argument('--seed', type=int, default=None,\n",
    "                    help='Random seed')                        \n",
    "parser.add_argument('-d', '--dim', type=int, default=50, metavar='DIMENSION',\n",
    "                    help='Feature dimension (default: 50)')\n",
    "parser.add_argument('--hidden', type=int, default=200, metavar='DIMENSION',\n",
    "                    help='Hidden layer dimension (default: 200)')\n",
    "parser.add_argument('--sigmas', type=str, default=None,\n",
    "                    help='Sigmas')     \n",
    "parser.add_argument('-r','--s-range', nargs='*', type=float,\n",
    "                    help='Range for sigmas')\n",
    "parser.add_argument('-w','--scales', nargs='*', type=float,\n",
    "                    help='scale of the weights')\n",
    "parser.add_argument('--lr', type=float, default=1e-4, nargs='*', metavar='LR',\n",
    "                    help='learning rate (default: 1e-4)')              \n",
    "parser.add_argument('--normalized', action='store_true', default=False,\n",
    "                    help='normalize sample norm across features')\n",
    "parser.add_argument('--risk-loss', type=str, default='MSE', metavar='LOSS',\n",
    "                    help='Loss for validation')\n",
    "parser.add_argument('--jacobian', action='store_true', default=False,\n",
    "                    help='compute the SVD of the jacobian of the network')\n",
    "parser.add_argument('--save-results', action='store_true', default=False,\n",
    "                    help='Save the results for plots')\n",
    "parser.add_argument('--details', type=str, metavar='N',\n",
    "                    default='no_detail_given',\n",
    "                    help='details about the experimental setup')\n",
    "\n",
    "\n",
    "args = parser.parse_args(cli_args.split())\n",
    "\n",
    "# directories\n",
    "root = pathlib.Path(args.root) if args.root else pathlib.Path.cwd().parent\n",
    "\n",
    "current_date = str(datetime.datetime.today().strftime('%Y-%m-%d-%H-%M-%S'))\n",
    "args.outpath = (pathlib.Path.cwd().parent / 'results' / 'two_layer_nn' /  current_date)\n",
    "\n",
    "if args.save_results:\n",
    "    args.outpath.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "if args.seed is not None:\n",
    "    random.seed(args.seed)\n",
    "    torch.manual_seed(args.seed)\n",
    "    np.random.seed(args.seed)\n",
    "    \n",
    "device = torch.device('cpu')\n",
    "# device = torch.device('cuda') # Uncomment this to run on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_out = 1      # dimension of y\n",
    "\n",
    "# sample training set from the linear model\n",
    "lin_model = linear_model(args.dim, sigma_noise=sigma_noise, normalized=False, sigmas=args.sigmas, s_range=args.s_range)\n",
    "Xs, ys = lin_model.sample(args.samples)\n",
    "Xs = torch.Tensor(Xs).to(device)\n",
    "ys = torch.Tensor(ys.reshape((-1,1))).to(device)\n",
    "\n",
    "# sample the set for empirical risk calculation\n",
    "Xt, yt = lin_model.sample(args.samples)\n",
    "Xt = torch.Tensor(Xt).to(device)\n",
    "yt = torch.Tensor(yt.reshape((-1,1))).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss functions\n",
    "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "risk_fn = torch.nn.L1Loss(reduction='mean') if args.risk_loss == 'L1' else loss_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Empirical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(\n",
    "           torch.nn.Linear(args.dim, args.hidden),\n",
    "           torch.nn.Linear(args.hidden, d_out),\n",
    "         ).to(device)      \n",
    "                \n",
    "# use kaiming initialization                \n",
    "if args.scales:\n",
    "    i = 0\n",
    "    with torch.no_grad():\n",
    "        for m in model:\n",
    "            if type(m) == torch.nn.Linear:\n",
    "                if i == 0:\n",
    "                    torch.nn.init.kaiming_normal_(m.weight, a=math.sqrt(5))\n",
    "                    m.weight.data = torch.mul(m.weight.data, args.scales[0])\n",
    "                if i == 1:\n",
    "                    torch.nn.init.kaiming_uniform_(m.weight, a=math.sqrt(5))\n",
    "                    m.weight.data = torch.mul(m.weight.data, args.scales[1])\n",
    "                i += 1\n",
    "                \n",
    "\n",
    "# use same learning rate for the two layers\n",
    "if isinstance(args.lr, list):\n",
    "    stepsize = [max(args.lr)] * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the network\n",
    "losses_same = []\n",
    "risks_same = []\n",
    "for t in range(int(args.iterations)):\n",
    "    y_pred = model(Xs)\n",
    "\n",
    "    loss = loss_fn(y_pred, ys)\n",
    "    losses_same.append(loss.item())\n",
    "\n",
    "    if not t % args.print_freq:\n",
    "        print(t, loss.item())\n",
    "\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        i = 0\n",
    "        for param in model.parameters():\n",
    "            param.data -= stepsize[i] * param.grad\n",
    "            if not len(param.shape) > 1:\n",
    "                i += 1\n",
    "            \n",
    "    with torch.no_grad():\n",
    "        yt_pred = model(Xt)\n",
    "        \n",
    "        risk = risk_fn(yt_pred, yt)\n",
    "        risks_same.append(risk.item())\n",
    "\n",
    "        if not t % args.print_freq:\n",
    "            print(t, risk.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_samples = [int(i) for i in np.geomspace(1, len(risks)-1, num=700)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "risks = np.array(risks_same)\n",
    "losses = np.array(losses_same)\n",
    "\n",
    "cmap = matplotlib.cm.get_cmap('viridis')\n",
    "colorList = [cmap(50/1000), cmap(350/1000)]\n",
    "labelList = ['same stepsize', 'scaled stepsize']\n",
    "\n",
    "fig = plt.figure(figsize=(12,8))\n",
    "ax = plt.subplot(111)\n",
    "ax.set_xscale('log')\n",
    "\n",
    "ax.plot(geo_samples, risks[geo_samples], \n",
    "        color=colorList[1], \n",
    "        label=labelList[1],\n",
    "        lw=4)\n",
    "\n",
    "ax.legend(loc=1, bbox_to_anchor=(1, 1), fontsize='x-large',\n",
    "    frameon=False, fancybox=True, shadow=True, ncol=1)\n",
    "ax.set_ylabel('risk')\n",
    "ax.set_xlabel(r'$t$ iterations')\n",
    "\n",
    "ax2 = fig.add_subplot(211)\n",
    "ax2.set_xscale('log')\n",
    "ax2.plot(geo_samples, losses[geo_samples], \n",
    "        color=colorList[1], \n",
    "        label=labelList[1],\n",
    "        lw=4)\n",
    "\n",
    "ax2.set_ylabel('loss')\n",
    "ax2.set_xlabel(r'$t$ iterations')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the sake of not messing anything up\n",
    "Xs_t, ys_t, Xt_t, yt_t = Xs.T, ys.T, Xt.T, yt.T\n",
    "\n",
    "V, s, _ = np.linalg.svd(Xs_t, full_matrices=True)\n",
    "S = torch.tensor(np.concatenate((s, np.zeros(args.dim - s.shape[0]))).reshape(1, -1), dtype=torch.float32)\n",
    "St = ys_t @ Xs_t.T @ torch.tensor(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dt(u, z, S, St):\n",
    "    assert S.shape == z.shape\n",
    "\n",
    "    return (St - u * z * S)\n",
    "\n",
    "def dzdt(u, z, S, St):\n",
    "    \n",
    "    return u * dt(u, z, S, St)\n",
    "\n",
    "\n",
    "def dudt(u, z, S, St):\n",
    "    assert S.shape == z.shape\n",
    "    \n",
    "    return (dt(u, z, S, St) @ z.T).squeeze()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation\n",
    "w_init = 0.01\n",
    "u = torch.normal(0, torch.tensor(w_init))\n",
    "z = torch.normal(0, torch.tensor(w_init), size=(1, args.dim))\n",
    "\n",
    "losses_teo = []\n",
    "risks_teo = []\n",
    "for t in range(int(args.iterations)):\n",
    "    \n",
    "    #u = u - args.lr[0] * dudt(u, z, S, St)\n",
    "    z = z - args.lr[0] * dzdt(u, z, S, St)\n",
    "    \n",
    "    \n",
    "    Wtot = u * z @ V.T\n",
    "\n",
    "    y_pred = Wtot @ Xs_t\n",
    "\n",
    "    loss = loss_fn(y_pred.T, ys_t.T)\n",
    "    losses_teo.append(loss.item())\n",
    "\n",
    "    if not t % args.print_freq:\n",
    "        print(t, loss.item())\n",
    "        \n",
    "    yt_pred = Wtot @ Xt_t\n",
    "\n",
    "    risk = risk_fn(yt_pred.T, yt_t.T)\n",
    "    risks_teo.append(risk.item())\n",
    "\n",
    "    if not t % args.print_freq:\n",
    "        print(t, risk.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "risks = np.array(risks_teo)\n",
    "losses = np.array(losses_teo)\n",
    "\n",
    "cmap = matplotlib.cm.get_cmap('viridis')\n",
    "colorList = [cmap(50/1000), cmap(350/1000)]\n",
    "labelList = ['same stepsize', 'scaled stepsize']\n",
    "\n",
    "fig = plt.figure(figsize=(12,8))\n",
    "ax = plt.subplot(111)\n",
    "ax.set_xscale('log')\n",
    "\n",
    "ax.plot(geo_samples, risks[geo_samples], \n",
    "        color=colorList[1], \n",
    "        label=labelList[1],\n",
    "        lw=4)\n",
    "\n",
    "ax.legend(loc=1, bbox_to_anchor=(1, 1), fontsize='x-large',\n",
    "    frameon=False, fancybox=True, shadow=True, ncol=1)\n",
    "ax.set_ylabel('risk')\n",
    "ax.set_xlabel(r'$t$ iterations')\n",
    "\n",
    "ax2 = fig.add_subplot(211)\n",
    "ax2.set_xscale('log')\n",
    "ax2.plot(geo_samples, losses[geo_samples], \n",
    "        color=colorList[1], \n",
    "        label=labelList[1],\n",
    "        lw=4)\n",
    "\n",
    "ax2.set_ylabel('loss')\n",
    "ax2.set_xlabel(r'$t$ iterations')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
