{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8fbc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62836500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESULTS_DIR = os.path.join(\"P:/early_stopping_double_descent\", \"...\") # enter folder direction here (i.e., two_layer_results)\n",
    "\n",
    "SMALL_SIZE = 10\n",
    "MEDIUM_SIZE = 12\n",
    "BIGGER_SIZE = 14\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('axes', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "\n",
    "\n",
    "def get_all_files(lr, batch_norm, uniform_noise):\n",
    "    files = os.listdir(RESULTS_DIR)\n",
    "    files = [file for file in files if file.startswith(f'lr={lr}')]\n",
    "\n",
    "    if batch_norm:\n",
    "        files = [file for file in files if \"batch_norm\" in file]\n",
    "    elif uniform_noise:\n",
    "        files = [file for file in files if \"uniform_noise\" in file]\n",
    "    else:\n",
    "        files = [file for file in files if \"batch_norm\" and \"uniform_noise\" not in file]\n",
    "    return files\n",
    "\n",
    "def get_files(batch_norm):\n",
    "    files = os.listdir(RESULTS_DIR)\n",
    "    files = [file for file in files if file.endswith(\".csv\")]\n",
    "    if batch_norm:\n",
    "        files = [file for file in files if \"batch_norm\" in file]\n",
    "    else:\n",
    "        files = [file for file in files if \"batch_norm\" not in file]\n",
    "    return files\n",
    "\n",
    "def append_id(filename, id):\n",
    "    return \"{0}_{2}.{1}\".format(*filename.rsplit('.', 1) + [id])\n",
    "\n",
    "def get_filename_individual(lr1, lr2, batch_norm):\n",
    "    result_path = os.path.split(RESULTS_DIR)[1]\n",
    "    result_path_split = result_path.split('_')\n",
    "    linear = result_path_split[-1] == \"linear\"\n",
    "    if linear:\n",
    "        w = '_'.join(result_path_split[-3:-1])\n",
    "    else:\n",
    "        w = '_'.join(result_path_split[-2:])\n",
    "    \n",
    "    name = f'lr1={lr1}_lr2={lr2}_w={w}.pdf'\n",
    "    \n",
    "    if batch_norm:\n",
    "        name = append_id(name, \"batch_norm\")\n",
    "    if linear:\n",
    "        name = append_id(name, \"linear\")\n",
    "    return name\n",
    "\n",
    "def get_filename_range(lr1, lr2_low, lr2_high, batch_norm, uniform_noise=False):\n",
    "    result_path = os.path.split(RESULTS_DIR)[1]\n",
    "    result_path_split = result_path.split('_')\n",
    "    linear = result_path_split[-1] == \"linear\"\n",
    "    if linear:\n",
    "        w = '_'.join(result_path_split[-3:-1])\n",
    "    else:\n",
    "        w = '_'.join(result_path_split[-2:])\n",
    "    \n",
    "    name = f'lr1={lr1}_lr2_low={lr2_low}_lr2_high=_{lr2_high}_w={w}.pdf'\n",
    "    \n",
    "    if batch_norm:\n",
    "        name = append_id(name, \"batch_norm\")\n",
    "    elif uniform_noise:\n",
    "        name = append_id(name, \"uniform_noise\")\n",
    "\n",
    "    if linear:\n",
    "        name = append_id(name, \"linear\")\n",
    "        \n",
    "    return name\n",
    "\n",
    "def plot_individual_run(lr1, lr2, batch_norm, uniform_noise=False):\n",
    "    file_path = os.path.join(RESULTS_DIR, f\"lr={lr1}_{lr2}.csv\")\n",
    "    if batch_norm:\n",
    "        file_path = append_id(file_path, \"batch_norm\") \n",
    "    elif uniform_noise:\n",
    "        file_path = append_id(file_path, \"uniform_noise\") \n",
    "        \n",
    "    data = pd.read_csv(file_path, header=None)\n",
    "    geo_samples = [int(i) for i in np.geomspace(1, len(data) - 1, num=700)]\n",
    "    cmap = matplotlib.colormaps['viridis']\n",
    "    colorList = [cmap(50 / 1000), cmap(350 / 1000)]\n",
    "    labelList = ['same stepsize', 'scaled stepsize']\n",
    "\n",
    "    #fig = plt.figure()\n",
    "    fig, ax = plt.subplots(2,1, sharex=True)\n",
    "    for k in range(2):\n",
    "        ax[k].set_xscale('log')\n",
    "        data_vec = data[k]\n",
    "        ax[k].plot(geo_samples, data_vec[geo_samples],\n",
    "            color=colorList[k],\n",
    "            label=labelList[k],\n",
    "            lw=4)\n",
    "\n",
    "    plt.suptitle(fr\"$\\eta_{{\\mathbf{{W}}}} = {lr1}$, $\\eta_{{\\mathbf{{v}}}} = {lr2}$\")\n",
    "    \n",
    "    save_dir = \"plots\"\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)  \n",
    "        \n",
    "    plt.savefig(os.path.join(save_dir, get_filename_individual(lr1, lr2, batch_norm)))\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def get_filename(lr, vmax, batch_norm):\n",
    "    result_path = os.path.split(RESULTS_DIR)[1]\n",
    "    result_path_split = result_path.split('_')\n",
    "    linear = result_path_split[-1] == \"linear\"\n",
    "    if linear:\n",
    "        w = '_'.join(result_path_split[-3:-1])\n",
    "    else:\n",
    "        w = '_'.join(result_path_split[-2:])\n",
    "    \n",
    "    name = f'{lr}_vmax={vmax}_w={w}.pdf'\n",
    "    if batch_norm:\n",
    "        name = append_id(name, \"batch_norm\")\n",
    "    if linear:\n",
    "        name = append_id(name, \"linear\")\n",
    "    return name\n",
    "\n",
    "def plot_results(lr, vmax=20, keep_nan=True, batch_norm=False, uniform_noise=False, plot_nans=False):\n",
    "    files = get_all_files(lr, batch_norm, uniform_noise)\n",
    "    if batch_norm:\n",
    "        f_ext = \"_batch_norm.csv\"\n",
    "        lrs = [f.split('_')[1] for f in files]\n",
    "    elif uniform_noise:\n",
    "        f_ext = \"_uniform_noise.csv\"\n",
    "        lrs = [f.split('_')[1] for f in files]\n",
    "    else:\n",
    "        f_ext = \".csv\"\n",
    "        lrs = [f.split('_')[-1][:-4] for f in files]\n",
    "    \n",
    "    assert len(lrs) == 99, \"Something wrong with the amount of files\"\n",
    "    lrs_float = [float(l) for l in lrs]\n",
    "    lrs_float, lrs = zip(*sorted(zip(lrs_float, lrs)))\n",
    "    \n",
    "    num_its = 50000\n",
    "    risks = np.zeros((len(lrs), num_its))\n",
    "    losses = np.zeros((len(lrs), num_its))\n",
    "    for i, l in enumerate(lrs):\n",
    "        data = pd.read_csv(os.path.join(RESULTS_DIR, f\"lr={lr}_{l}{f_ext}\"), header=None)\n",
    "        risks[i] = data[0]\n",
    "        losses[i] = data[1]\n",
    "    if (~np.isfinite(risks)).any() and np.nonzero(~(~np.isfinite(risks)).any(axis=-1))[0].any():\n",
    "        print(r\"Lr2 with nan/inf, then some lower lr2\")\n",
    "        idx=np.nonzero(~(~np.isfinite(risks)).any(axis=-1))[0][-1] + 1\n",
    "        for j in range(10):\n",
    "            if plot_nans:\n",
    "                plot_individual_run(lr, lrs[idx-j], batch_norm)\n",
    "            else:\n",
    "                print(lrs[idx-j])\n",
    "    else:\n",
    "        print('No nans/inf values')\n",
    "    ratios = np.array(lrs_float)/lr\n",
    "            \n",
    "    # Subsample epochs\n",
    "    geo_samples = [int(i) for i in np.geomspace(1, 50000 - 1, num=700)]\n",
    "    fig, ax = plt.subplots(2,1, sharex=True)\n",
    "    \n",
    "    # Plot\n",
    "    im1 = ax[0].imshow(risks[:, geo_samples].transpose()[::-1, :], interpolation='none', aspect='auto', vmax=vmax, vmin=0)\n",
    "    im2 = ax[1].imshow(losses[:, geo_samples].transpose()[::-1, :], interpolation='none', aspect='auto', vmax=vmax, vmin=0)\n",
    "    fig.colorbar(im1, ax=ax[0])\n",
    "    fig.colorbar(im2, ax=ax[1])\n",
    "    \n",
    "    # Title\n",
    "    title = fr\"$\\eta_{{\\mathbf{{W}}}}={lr}$\"\n",
    "    if batch_norm:\n",
    "        title += \", with batch normalization\"\n",
    "    plt.suptitle(title)\n",
    "    \n",
    "    # Set correct x- and y-ticks\n",
    "    # X axis\n",
    "    ten_powers = 10.0 ** np.arange(-5, 6)\n",
    "    indices = []\n",
    "    for val in ten_powers:\n",
    "        indices += [np.argmin(np.abs(ratios-val))]\n",
    "    \n",
    "    for k in [1]:\n",
    "        ax[k].set_xticks(indices)\n",
    "        ax[k].set_xticklabels([f\"$10^{{{i}}}$\" for i in np.arange(-5, 6)])\n",
    "        ax[k].set_xlabel(r\"$\\eta_{\\mathbf{v}} / \\eta_{\\mathbf{W}}$\")\n",
    "    \n",
    "    # Y axis\n",
    "    ten_powers = 10.0 ** np.arange(4, 0, -1)\n",
    "    indices = []\n",
    "    for val in ten_powers:\n",
    "        indices += [np.argmin(np.abs(geo_samples-val))]\n",
    "    for k in range(2):\n",
    "        ax[k].set_yticks(indices)\n",
    "        ax[k].set_yticklabels([f\"$10^{{{i}}}$\" for i in np.arange(1, 5)])\n",
    "        ax[k].set_ylabel(r\"Iteration $t$\")\n",
    "    \n",
    "    # Save file\n",
    "    save_dir = \"plots\"\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)  \n",
    "        \n",
    "    \n",
    "    figname = get_filename(lr, vmax, batch_norm)\n",
    "    plt.savefig(os.path.join(\"plots\", figname), bbox_inches='tight')\n",
    "    \n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "def plot_same_lr(vmax=20, batch_norm=False):\n",
    "    files = get_files(batch_norm)\n",
    "    if batch_norm:\n",
    "        f_ext = \"_batch_norm.csv\"\n",
    "        lrs = [f.split('_')[1] for f in files]\n",
    "    else:\n",
    "        f_ext = \".csv\"\n",
    "        lrs = [f.split('_')[-1][:-4] for f in files]\n",
    "    assert len(lrs) == 91, \"Not right amount of files\"\n",
    "    lrs_float = [float(l) for l in lrs]\n",
    "    lrs_float, lrs = zip(*sorted(zip(lrs_float, lrs)))\n",
    "    risks = np.zeros((len(lrs), 50000))\n",
    "    losses = np.zeros((len(lrs), 50000))\n",
    "    for i, lr in enumerate(lrs):\n",
    "        data = pd.read_csv(os.path.join(RESULTS_DIR, f\"lr={lr}_{lr}{f_ext}\"), header=None)\n",
    "        risks[i] = data[0]\n",
    "        losses[i] = data[1]\n",
    "    # Subsample epochs\n",
    "    geo_samples = [int(i) for i in np.geomspace(1, 50000 - 1, num=700)]\n",
    "    fig, ax = plt.subplots(2,1, sharex=True)\n",
    "    # Plot\n",
    "    im1 = ax[0].imshow(risks[:, geo_samples].transpose()[::-1, :], interpolation='none', aspect='auto', vmax=vmax)\n",
    "    fig.colorbar(im1, ax=ax[0])\n",
    "    im2 = ax[1].imshow(losses[:, geo_samples].transpose()[::-1, :], interpolation='none', aspect='auto', vmax=vmax)\n",
    "    fig.colorbar(im2, ax=ax[1])\n",
    "    \n",
    "    # Title\n",
    "    title = fr\"Same lr for both layers\"\n",
    "    if batch_norm:\n",
    "        title += \", with batch normalization\"\n",
    "    plt.suptitle(title)\n",
    "    \n",
    "    # Set correct x- and y-ticks\n",
    "    # X axis\n",
    "    ten_powers = 10.0 ** np.arange(-7, -1)\n",
    "    indices = []\n",
    "    for val in ten_powers:\n",
    "        indices += [np.argmin(np.abs(lrs_float-val))]\n",
    "    \n",
    "    ax[1].set_xticks(indices)\n",
    "    ax[1].set_xticklabels([f\"$10^{{{i}}}$\" for i in np.arange(-7, -1)])\n",
    "    ax[1].set_xlabel(\"lr\")\n",
    "    \n",
    "    # Y axis\n",
    "    ten_powers = 10.0 ** np.arange(4, 0, -1)\n",
    "    indices = []\n",
    "    for val in ten_powers:\n",
    "        indices += [np.argmin(np.abs(geo_samples-val))]\n",
    "    for k in range(2):\n",
    "        ax[k].set_yticks(indices)\n",
    "        ax[k].set_yticklabels([f\"$10^{{{i}}}$\" for i in np.arange(1, 5)])\n",
    "        ax[k].set_ylabel(r\"Iteration $t$\")\n",
    "    \n",
    "    figname = get_filename(lr, vmax, batch_norm)\n",
    "    plt.savefig(os.path.join(\"plots\", figname), bbox_inches='tight')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f2b78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for plotting a selection of curves\n",
    "\n",
    "def plot_individual_runs_range(lr1, lr_ratio_low, lr_ratio_high, batch_norm=False, uniform_noise=False):\n",
    "    \"\"\"Plot individual runs within range lr_ratio_low to lr_ratio_high\"\"\"\n",
    "    \n",
    "    files = get_all_files(lr1, batch_norm, uniform_noise)\n",
    "        \n",
    "    if batch_norm:\n",
    "        f_ext = \"_batch_norm.csv\"\n",
    "        lrs = [f.split('_')[1] for f in files]\n",
    "    elif uniform_noise:\n",
    "        f_ext = \"_uniform_noise.csv\"\n",
    "        lrs = [f.split('_')[1] for f in files]\n",
    "    else:\n",
    "        f_ext = \".csv\"\n",
    "        lrs = [f.split('_')[-1][:-4] for f in files]\n",
    "    \n",
    "    # Keep runs only within range\n",
    "    lr2_low, lr2_high = lr_ratio_low * lr1, lr_ratio_high * lr1\n",
    "    # files = [f for f, lr in zip(files, lrs) if float(lr) >= lr2_low and float(lr) <= lr2_high]\n",
    "    lrs = [float(lr) for lr in lrs if float(lr) >= lr2_low and float(lr) <= lr2_high]\n",
    "    lrs.sort()\n",
    "\n",
    "    fig, ax = plt.subplots(2, 1, sharex=True)\n",
    "    ymax = [50, 150000]\n",
    "    ylabels = [\"Test loss\", \"Training loss\"]\n",
    "    for i, lr in enumerate(lrs):\n",
    "        data = pd.read_csv(os.path.join(RESULTS_DIR, f\"lr={lr1}_{lr}{f_ext}\"), header=None)       \n",
    "        geo_samples = [int(i) for i in np.geomspace(1, len(data) - 1, num=700)]\n",
    "\n",
    "        for k in range(2):\n",
    "            if i == 0:\n",
    "                ax[k].set_xscale('log')\n",
    "                ax[k].set_ylim([0, ymax[k]])\n",
    "                ax[k].set_ylabel(ylabels[k])\n",
    "            \n",
    "            data_vec = data[k] \n",
    "            ax[k].plot(geo_samples, data_vec[geo_samples],\n",
    "#                color=colorList[k],\n",
    "                lw=4)\n",
    "            \n",
    "    ax[0].legend([fr\"$\\eta_{{\\mathbf{{v}}}} = {lr2}$\" for lr2 in lrs])\n",
    "    fig.suptitle(fr\"$\\eta_{{\\mathbf{{w}}}} = {lr1}$\")\n",
    "\n",
    "    save_dir = \"plots\"\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)  \n",
    "\n",
    "    plt.savefig(os.path.join(save_dir, get_filename_range(lr1, lr2_low, lr2_high, batch_norm, uniform_noise)))\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852fd722",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_results(1e-4, 20, batch_norm=False, uniform_noise=False, plot_nans=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4259cf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_individual_runs_range(1e-4, 5e-1, 2, uniform_noise=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5d46fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for eta_w in [1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2]:\n",
    "    plot_results(eta_w, 20, plot_nans=False, batch_norm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7a3ca7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
