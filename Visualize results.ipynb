{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8fbc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append('code/')\n",
    "from linear_utils import is_float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62836500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESULTS_DIR = os.path.join(\"P:/early_stopping_double_descent\", \"...\") # enter folder direction here (i.e., two_layer_results)\n",
    "RESULTS_DIR = \"results/two_layer_results_l2\" #\"five_layer_regression_results\"\n",
    "\n",
    "SMALL_SIZE = 10\n",
    "MEDIUM_SIZE = 12\n",
    "BIGGER_SIZE = 14\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('axes', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "\n",
    "\n",
    "def get_all_files(lr, batch_norm, uniform_noise, coupled_noise=None, ext=''):\n",
    "    files = os.listdir(RESULTS_DIR)\n",
    "    files = [file for file in files if file.startswith(f'lr={lr}')]\n",
    "\n",
    "    if batch_norm:\n",
    "        files = [file for file in files if \"batch_norm\" in file]\n",
    "    elif uniform_noise:\n",
    "        files = [file for file in files if \"uniform_noise\" in file]    \n",
    "    else:\n",
    "        files = [file for file in files if \"batch_norm\" and \"uniform_noise\" not in file]\n",
    "        \n",
    "    # Sorry, I will clean this up eventually\n",
    "    if coupled_noise is not None:\n",
    "        files = [file for file in files if f\"coupled_noise_{coupled_noise}\" in file]  \n",
    "        \n",
    "    files = [file for file in files if ext in file]\n",
    "\n",
    "    return files\n",
    "\n",
    "def get_files(batch_norm, uniform_noise, coupled_noise=None, ext=''):\n",
    "    files = os.listdir(RESULTS_DIR)\n",
    "    files = [file for file in files if file.endswith(\".csv\")]\n",
    "    if batch_norm:\n",
    "        files = [file for file in files if \"batch_norm\" in file]\n",
    "    #else:\n",
    "        #files = [file for file in files if \"batch_norm\" not in file]\n",
    "    elif uniform_noise:\n",
    "        files = [file for file in files if \"uniform_noise\" in file]\n",
    "    else:\n",
    "        files = [file for file in files if \"batch_norm\" and \"uniform_noise\" not in file]\n",
    "        \n",
    "    if coupled_noise is not None:\n",
    "        files = [file for file in files if f\"coupled_noise_{coupled_noise}\" in file]  \n",
    "        \n",
    "    files = [file for file in files if ext in file]\n",
    "    \n",
    "    return files\n",
    "\n",
    "def append_id(filename, id):\n",
    "    return \"{0}_{2}.{1}\".format(*filename.rsplit('.', 1) + [id])\n",
    "\n",
    "def get_filename_individual(lr1, lr2, batch_norm):\n",
    "    result_path = os.path.split(RESULTS_DIR)[1]\n",
    "    result_path_split = result_path.split('_')\n",
    "    linear = result_path_split[-1] == \"linear\"\n",
    "    if linear:\n",
    "        w = '_'.join(result_path_split[-3:-1])\n",
    "    else:\n",
    "        w = '_'.join(result_path_split[-2:])\n",
    "    \n",
    "    name = f'lr1={lr1}_lr2={lr2}_w={w}.pdf'\n",
    "    \n",
    "    if batch_norm:\n",
    "        name = append_id(name, \"batch_norm\")\n",
    "    if linear:\n",
    "        name = append_id(name, \"linear\")\n",
    "    return name\n",
    "\n",
    "def get_filename_range(lr1, lr2_low, lr2_high, batch_norm, uniform_noise=False):\n",
    "    result_path = os.path.split(RESULTS_DIR)[1]\n",
    "    result_path_split = result_path.split('_')\n",
    "    linear = result_path_split[-1] == \"linear\"\n",
    "    if linear:\n",
    "        w = '_'.join(result_path_split[-3:-1])\n",
    "    else:\n",
    "        w = '_'.join(result_path_split[-2:])\n",
    "    \n",
    "    name = f'lr1={lr1}_lr2_low={lr2_low}_lr2_high=_{lr2_high}_w={w}.pdf'\n",
    "    \n",
    "    if batch_norm:\n",
    "        name = append_id(name, \"batch_norm\")\n",
    "    elif uniform_noise:\n",
    "        name = append_id(name, \"uniform_noise\")\n",
    "\n",
    "    if linear:\n",
    "        name = append_id(name, \"linear\")\n",
    "        \n",
    "    return name\n",
    "\n",
    "def get_filename_range_pcs(lr1, lr2, pc_low, pc_high, batch_norm, uniform_noise=False):\n",
    "    result_path = os.path.split(RESULTS_DIR)[1]\n",
    "    result_path_split = result_path.split('_')\n",
    "    linear = result_path_split[-1] == \"linear\"\n",
    "    if linear:\n",
    "        w = '_'.join(result_path_split[-3:-1])\n",
    "    else:\n",
    "        w = '_'.join(result_path_split[-2:])\n",
    "    \n",
    "    name = f'lr1={lr1}_lr2={lr2}_pc_low={pc_low}_pc_high=_{pc_high}.pdf'\n",
    "    \n",
    "    if batch_norm:\n",
    "        name = append_id(name, \"batch_norm\")\n",
    "    elif uniform_noise:\n",
    "        name = append_id(name, \"uniform_noise\")\n",
    "\n",
    "    if linear:\n",
    "        name = append_id(name, \"linear\")\n",
    "        \n",
    "    return name\n",
    "\n",
    "def plot_individual_run(lr1, lr2, batch_norm, uniform_noise=False, coupled_noise=None, ext='', plot_extra=False, extra_labels=None):\n",
    "    \n",
    "    file_path = os.path.join(RESULTS_DIR, f\"lr={lr1}_{lr2}.csv\")\n",
    "    if batch_norm:\n",
    "        file_path = append_id(file_path, \"batch_norm\") \n",
    "    elif uniform_noise:\n",
    "        file_path = append_id(file_path, \"uniform_noise\") \n",
    "        \n",
    "    if coupled_noise is not None:\n",
    "        file_path = append_id(file_path, f\"coupled_noise_{coupled_noise}\") \n",
    "        \n",
    "    file_path = append_id(file_path, ext)\n",
    "    \n",
    "    data = pd.read_csv(file_path, header=None)\n",
    "    \n",
    "    geo_samples = [int(i) for i in np.geomspace(1, len(data) - 1, num=700)]\n",
    "    cmap = matplotlib.colormaps['viridis']\n",
    "    colorList = [cmap(50 / 1000), cmap(350 / 1000)]\n",
    "    labelList = ['Test', 'Train']\n",
    "    \n",
    "    if plot_extra:\n",
    "        assert data.shape[-1] > 2, \"No extra data saved\"\n",
    "        num_vec = data.shape[-1]\n",
    "        colorList += [cmap((450 + 100 * t) / 1000) for t in range(num_vec - 2)]\n",
    "        labelList = labelList + extra_labels if extra_labels is not None else labelList + [''] * (num_vec - 2)\n",
    "    else:\n",
    "        num_vec = 2\n",
    "        \n",
    "\n",
    "    #fig = plt.figure()\n",
    "    fig, ax = plt.subplots(num_vec, 1, figsize=(5, num_vec * 5), sharex=True)\n",
    "    for k in range(num_vec):\n",
    "        ax[k].set_xscale('log')\n",
    "    \n",
    "        data_vec = data[k] \n",
    "            \n",
    "        print(data_vec.min())\n",
    "        ax[k].plot(geo_samples, data_vec[geo_samples],\n",
    "            color=colorList[k],\n",
    "            label=labelList[k],\n",
    "            lw=4)\n",
    "        ax[k].set_ylabel(labelList[k])\n",
    "        \n",
    "    plt.suptitle(fr\"$\\eta_{{\\mathbf{{W}}}} = {lr1}$, $\\eta_{{\\mathbf{{v}}}} = {lr2}$\")\n",
    "    \n",
    "    save_dir = \"plots\"\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)  \n",
    "        \n",
    "    plt.savefig(os.path.join(save_dir, get_filename_individual(lr1, lr2, batch_norm)))\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def get_filename(lr, vmax, batch_norm):\n",
    "    result_path = os.path.split(RESULTS_DIR)[1]\n",
    "    result_path_split = result_path.split('_')\n",
    "    linear = result_path_split[-1] == \"linear\"\n",
    "    if linear:\n",
    "        w = '_'.join(result_path_split[-3:-1])\n",
    "    else:\n",
    "        w = '_'.join(result_path_split[-2:])\n",
    "    \n",
    "    name = f'{lr}_vmax={vmax}_w={w}.pdf'\n",
    "    if batch_norm:\n",
    "        name = append_id(name, \"batch_norm\")\n",
    "    if linear:\n",
    "        name = append_id(name, \"linear\")\n",
    "        \n",
    "    return name\n",
    "\n",
    "def plot_results(lr, vmax=20, vmin=0, keep_nan=True, batch_norm=False, uniform_noise=False, coupled_noise=None, ext='', plot_nans=False, num_its=50000):\n",
    "    files = get_all_files(lr, batch_norm, uniform_noise, coupled_noise, ext)\n",
    "    \n",
    "    if not isinstance(vmax, list):\n",
    "        vmax = [vmax] * 2\n",
    "    if not isinstance(vmin, list):\n",
    "        vmin = [vmin] * 2\n",
    "    \n",
    "    if batch_norm:\n",
    "        f_ext = \"_batch_norm\"\n",
    "        lrs = [f.split('_')[1] for f in files]\n",
    "    elif uniform_noise:\n",
    "        f_ext = \"_uniform_noise\"\n",
    "        lrs = [f.split('_')[1] for f in files]        \n",
    "    else:\n",
    "        f_ext = \"\"\n",
    "        lrs = [f.split('_')[-1][:-4] for f in files]\n",
    "        \n",
    "    if coupled_noise:\n",
    "        f_ext += f\"_coupled_noise_{coupled_noise}\"\n",
    "                \n",
    "    f_ext += ext + \".csv\"\n",
    "    \n",
    "    #assert len(lrs) == 99, \"Something wrong with the amount of files\"\n",
    "    lrs_float = [float(l) for l in lrs]\n",
    "    lrs_float, lrs = zip(*sorted(zip(lrs_float, lrs)))\n",
    "    \n",
    "    risks = np.zeros((len(lrs), num_its))\n",
    "    losses = np.zeros((len(lrs), num_its))\n",
    "    for i, l in enumerate(lrs):\n",
    "        data = pd.read_csv(os.path.join(RESULTS_DIR, f\"lr={lr}_{l}{f_ext}\"), header=None)\n",
    "        risks[i] = data[0]\n",
    "        losses[i] = data[1]\n",
    "    if (~np.isfinite(risks)).any() and np.nonzero(~(~np.isfinite(risks)).any(axis=-1))[0].any():\n",
    "        print(r\"Lr2 with nan/inf, then some lower lr2\")\n",
    "        idx=np.nonzero(~(~np.isfinite(risks)).any(axis=-1))[0][-1] + 1\n",
    "        for j in range(10):\n",
    "            if plot_nans:\n",
    "                plot_individual_run(lr, lrs[idx-j], batch_norm)\n",
    "            else:\n",
    "                print(lrs[idx-j])\n",
    "    else:\n",
    "        print('No nans/inf values')\n",
    "    ratios = np.array(lrs_float)/lr\n",
    "            \n",
    "    # Subsample epochs\n",
    "    geo_samples = [int(i) for i in np.geomspace(1, 50000 - 1, num=700)]\n",
    "    fig, ax = plt.subplots(2,1, sharex=True)\n",
    "\n",
    "    # Plot\n",
    "    im1 = ax[0].imshow(risks[:, geo_samples].transpose()[::-1, :], interpolation='none', aspect='auto', vmax=vmax[0], vmin=vmin[0])\n",
    "    im2 = ax[1].imshow(losses[:, geo_samples].transpose()[::-1, :], interpolation='none', aspect='auto', vmax=vmax[1], vmin=vmin[1])\n",
    "    fig.colorbar(im1, ax=ax[0])\n",
    "    fig.colorbar(im2, ax=ax[1])\n",
    "    \n",
    "    # Title\n",
    "    title = fr\"$\\eta_{{\\mathbf{{W}}}}={lr}$\"\n",
    "    \n",
    "    if batch_norm:\n",
    "        title += \", with batch normalization\"\n",
    "    plt.suptitle(title)\n",
    "    \n",
    "    # Set correct x- and y-ticks\n",
    "    # X axis\n",
    "    ten_powers = 10.0 ** np.arange(-5, 6)\n",
    "    indices = []\n",
    "    for val in ten_powers:\n",
    "        indices += [np.argmin(np.abs(ratios-val))]\n",
    "    \n",
    "    for k in [1]:\n",
    "        ax[k].set_xticks(indices)\n",
    "        ax[k].set_xticklabels([f\"$10^{{{i}}}$\" for i in np.arange(-5, 6)])\n",
    "        ax[k].set_xlabel(r\"$\\eta_{\\mathbf{v}} / \\eta_{\\mathbf{W}}$\")\n",
    "    \n",
    "    # Y axis\n",
    "    ten_powers = 10.0 ** np.arange(4, 0, -1)\n",
    "    indices = []\n",
    "    for val in ten_powers:\n",
    "        indices += [np.argmin(np.abs(geo_samples-val))]\n",
    "    for k in range(2):\n",
    "        ax[k].set_yticks(indices)\n",
    "        ax[k].set_yticklabels([f\"$10^{{{i}}}$\" for i in np.arange(1, 5)])\n",
    "        ax[k].set_ylabel(r\"Iteration $t$\")\n",
    "    \n",
    "    # Save file\n",
    "    save_dir = \"plots\"\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)  \n",
    "        \n",
    "    \n",
    "    figname = get_filename(lr, vmax[0], batch_norm)\n",
    "    plt.savefig(os.path.join(\"plots\", figname), bbox_inches='tight')\n",
    "    \n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "def plot_same_lr(vmax=20, vmin=0, batch_norm=False, uniform_noise=False, coupled_noise=None, ext='', plot_nans=False, num_its=50000):\n",
    "    files = get_files(batch_norm, uniform_noise, coupled_noise, ext)\n",
    "    \n",
    "    files = [f for f in files if f.split('_')[0][3:] == f.split('_')[1]]\n",
    "    \n",
    "    if not isinstance(vmax, list):\n",
    "        vmax = [vmax] * 2\n",
    "    if not isinstance(vmin, list):\n",
    "        vmin = [vmin] * 2\n",
    "    \n",
    "    if batch_norm:\n",
    "        f_ext = \"_batch_norm\"\n",
    "        lrs = [f.split('_')[1] for f in files]\n",
    "    elif uniform_noise:\n",
    "        f_ext = \"_uniform_noise\"\n",
    "        lrs = [f.split('_')[1] for f in files]        \n",
    "    else:\n",
    "        f_ext = \"\"\n",
    "        lrs = [f.split('_')[-1][:-4] for f in files]\n",
    "        \n",
    "    if coupled_noise:\n",
    "        f_ext += f\"_coupled_noise_{coupled_noise}\"\n",
    "                \n",
    "    f_ext += ext + \".csv\"\n",
    "        \n",
    "    assert len(lrs) == 91 or len(lrs) == 99, \"Not right amount of files\"\n",
    "    lrs_float = [float(l) for l in lrs]\n",
    "    lrs_float, lrs = zip(*sorted(zip(lrs_float, lrs)))\n",
    "    risks = np.zeros((len(lrs), num_its))\n",
    "    losses = np.zeros((len(lrs), num_its))\n",
    "    for i, lr in enumerate(lrs):\n",
    "        data = pd.read_csv(os.path.join(RESULTS_DIR, f\"lr={lr}_{lr}{f_ext}\"), header=None)\n",
    "        risks[i] = data[0]\n",
    "        losses[i] = data[1]\n",
    "    # Subsample epochs\n",
    "    geo_samples = [int(i) for i in np.geomspace(1, num_its - 1, num=700)]\n",
    "    fig, ax = plt.subplots(2,1, sharex=True)\n",
    "    # Plot\n",
    "    im1 = ax[0].imshow(risks[:, geo_samples].transpose()[::-1, :], interpolation='none', aspect='auto', vmax=vmax[0], vmin=vmin[0])\n",
    "    fig.colorbar(im1, ax=ax[0])\n",
    "    im2 = ax[1].imshow(losses[:, geo_samples].transpose()[::-1, :], interpolation='none', aspect='auto', vmax=vmax[1], vmin=vmin[1])\n",
    "    fig.colorbar(im2, ax=ax[1])\n",
    "    \n",
    "    # Title\n",
    "    title = fr\"Same lr for both layers\"\n",
    "    if batch_norm:\n",
    "        title += \", with batch normalization\"\n",
    "    plt.suptitle(title)\n",
    "    \n",
    "    # Set correct x- and y-ticks\n",
    "    # X axis\n",
    "    ten_powers = 10.0 ** np.arange(-7, -1)\n",
    "    indices = []\n",
    "    for val in ten_powers:\n",
    "        indices += [np.argmin(np.abs(lrs_float-val))]\n",
    "    \n",
    "    ax[1].set_xticks(indices)\n",
    "    ax[1].set_xticklabels([f\"$10^{{{i}}}$\" for i in np.arange(-7, -1)])\n",
    "    ax[1].set_xlabel(\"lr\")\n",
    "    \n",
    "    # Y axis\n",
    "    ten_powers = 10.0 ** np.arange(4, 0, -1)\n",
    "    indices = []\n",
    "    for val in ten_powers:\n",
    "        indices += [np.argmin(np.abs(geo_samples-val))]\n",
    "    for k in range(2):\n",
    "        ax[k].set_yticks(indices)\n",
    "        ax[k].set_yticklabels([f\"$10^{{{i}}}$\" for i in np.arange(1, 5)])\n",
    "        ax[k].set_ylabel(r\"Iteration $t$\")\n",
    "    \n",
    "    figname = get_filename(lr, vmax, batch_norm)\n",
    "    plt.savefig(os.path.join(\"plots\", figname), bbox_inches='tight')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f2b78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for plotting a selection of curves\n",
    "\n",
    "def plot_individual_runs_range(lr1, lr_ratio_low, lr_ratio_high, batch_norm=False, uniform_noise=False, coupled_noise=None, ext='', ymin=[0, 0], ymax = [50, 150000], mod=1):\n",
    "    \"\"\"Plot individual runs within range lr_ratio_low to lr_ratio_high\"\"\"\n",
    "    \n",
    "    files = get_all_files(lr1, batch_norm, uniform_noise, coupled_noise, ext)\n",
    "\n",
    "    if batch_norm:\n",
    "        f_ext = \"_batch_norm\"\n",
    "        lrs = [f.split('_')[1] for f in files]\n",
    "    elif uniform_noise:\n",
    "        f_ext = \"_uniform_noise\"\n",
    "        lrs = [f.split('_')[1] for f in files]\n",
    "    else:\n",
    "        f_ext = \"\"\n",
    "        lrs = [f.split('_')[-1][:-4] for f in files]\n",
    "        \n",
    "    if coupled_noise:\n",
    "        f_ext += f\"_coupled_noise_{coupled_noise}\"\n",
    "                \n",
    "    f_ext += ext + \".csv\"\n",
    "    \n",
    "    # Keep runs only within range\n",
    "    lr2_low, lr2_high = lr_ratio_low * lr1, lr_ratio_high * lr1\n",
    "    # files = [f for f, lr in zip(files, lrs) if float(lr) >= lr2_low and float(lr) <= lr2_high]\n",
    "    lrs = [float(lr) for lr in lrs if float(lr) >= lr2_low and float(lr) <= lr2_high]\n",
    "    lrs.sort()\n",
    "    \n",
    "    lrs = [lr for i, lr in enumerate(lrs) if np.mod(i, mod) == 0]\n",
    "\n",
    "    fig, ax = plt.subplots(2, 1, sharex=True, figsize=(8,10))\n",
    "    ylabels = [\"Test loss\", \"Training loss\"]\n",
    "    for i, lr in enumerate(lrs):\n",
    "        data = pd.read_csv(os.path.join(RESULTS_DIR, f\"lr={lr1}_{lr}{f_ext}\"), header=None)       \n",
    "        geo_samples = [int(i) for i in np.geomspace(1, len(data) - 1, num=700)]\n",
    "\n",
    "        for k in range(2):\n",
    "            if i == 0:\n",
    "                ax[k].set_xscale('log')\n",
    "                ax[k].set_ylim([ymin[k], ymax[k]])\n",
    "                ax[k].set_ylabel(ylabels[k])\n",
    "            \n",
    "            data_vec = data[k] \n",
    "            ax[k].plot(geo_samples, data_vec[geo_samples],\n",
    "#                color=colorList[k],\n",
    "                lw=2)\n",
    "            \n",
    "    ax[0].legend([fr\"$\\eta_{{\\mathbf{{v}}}} = {lr2}$\" for lr2 in lrs], loc=2)\n",
    "    fig.suptitle(fr\"$\\eta_{{\\mathbf{{w}}}} = {lr1}$\")\n",
    "\n",
    "    save_dir = \"plots\"\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)  \n",
    "\n",
    "    plt.savefig(os.path.join(save_dir, get_filename_range(lr1, lr2_low, lr2_high, batch_norm, uniform_noise)))\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecef626",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_individual_runs_range_pcs(lr1, lr2, pc_low, pc_high, batch_norm=False, uniform_noise=False, coupled_noise=None, ext='', ymin=[0, 0], ymax = [50, 150000]):\n",
    "    \"\"\"Plot individual runs within range lr_ratio_low to lr_ratio_high\"\"\"\n",
    "    \n",
    "    files = get_all_files(lr1, batch_norm, uniform_noise, coupled_noise, ext)\n",
    "    files = [file for file in files if file.startswith(f'lr={lr1}_{lr2}')]\n",
    "\n",
    "    if batch_norm:\n",
    "        f_ext = \"_batch_norm\"\n",
    "    elif uniform_noise:\n",
    "        f_ext = \"_uniform_noise\"\n",
    "    else:\n",
    "        f_ext = \"\"\n",
    "        \n",
    "    if coupled_noise:\n",
    "        f_ext += f\"_coupled_noise_{coupled_noise}\"\n",
    "                \n",
    "    f_ext += ext \n",
    "        \n",
    "    pcs = [(f.split('_')[-1]).split('.')[0] for f in files]\n",
    "\n",
    "    # Keep runs only within range\n",
    "    # files = [f for f, lr in zip(files, lrs) if float(lr) >= lr2_low and float(lr) <= lr2_high]\n",
    "    pcs = [float(pc) for pc in pcs if float(pc) >= pc_low and float(pc) <= pc_high]\n",
    "    pcs = [pc for i, pc in enumerate(pcs) if np.mod(i, 2) == 0]\n",
    "\n",
    "    pcs.sort()\n",
    "\n",
    "    fig, ax = plt.subplots(2, 1, sharex=True, figsize=(8,10))\n",
    "    ylabels = [\"Test loss\", \"Training loss\"]\n",
    "    for i, k in enumerate(pcs):\n",
    "        data = pd.read_csv(os.path.join(RESULTS_DIR, f\"lr={lr1}_{lr2}{f_ext}_pcs_{int(k)}.csv\"), header=None)       \n",
    "        geo_samples = [int(i) for i in np.geomspace(1, len(data) - 1, num=700)]\n",
    "\n",
    "        for k in range(2):\n",
    "            if i == 0:\n",
    "                ax[k].set_xscale('log')\n",
    "                ax[k].set_ylim([ymin[k], ymax[k]])\n",
    "                ax[k].set_ylabel(ylabels[k])\n",
    "            \n",
    "            data_vec = data[k] \n",
    "            ax[k].plot(geo_samples, data_vec[geo_samples],\n",
    "#                color=colorList[k],\n",
    "                lw=2)\n",
    "            \n",
    "    ax[0].legend([f\"Comp. {int(pc)}\" for pc in pcs], loc=2)\n",
    "    fig.suptitle(fr\"$\\eta_{{\\mathbf{{w}}}} = {lr1}, \\eta_{{\\mathbf{{v}}}} = {lr2}$\")\n",
    "\n",
    "    save_dir = \"plots\"\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)  \n",
    "\n",
    "    plt.savefig(os.path.join(save_dir, get_filename_range_pcs(lr1, lr2, pc_low, pc_high, batch_norm, uniform_noise)))\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def plot_results_pcs(lr1, lr2, vmax=20, vmin=0, keep_nan=True, batch_norm=False, uniform_noise=False, coupled_noise=None, ext='', num_its=50000):\n",
    "    files = get_all_files(lr1, batch_norm, uniform_noise, coupled_noise, ext)\n",
    "    files = [file for file in files if file.startswith(f'lr={lr1}_{lr2}')]\n",
    "\n",
    "    \n",
    "    if not isinstance(vmax, list):\n",
    "        vmax = [vmax] * 2\n",
    "    if not isinstance(vmin, list):\n",
    "        vmin = [vmin] * 2\n",
    "    \n",
    "    if batch_norm:\n",
    "        f_ext = \"_batch_norm\"\n",
    "    elif uniform_noise:\n",
    "        f_ext = \"_uniform_noise\"\n",
    "    else:\n",
    "        f_ext = \"\"\n",
    "        \n",
    "    if coupled_noise:\n",
    "        f_ext += f\"_coupled_noise_{coupled_noise}\"\n",
    "                \n",
    "    f_ext += ext #+ \".csv\"\n",
    "    \n",
    "    #assert len(lrs) == 100, \"Something wrong with the amount of files\"\n",
    "    pcs = [(f.split('_')[-1]).split('.')[0] for f in files]\n",
    "    pcs = [float(pc) for pc in pcs]\n",
    "    pcs.sort()\n",
    "    \n",
    "    #pcs = pcs[:-1]\n",
    "\n",
    "    risks = np.zeros((len(pcs), num_its))\n",
    "    losses = np.zeros((len(pcs), num_its))\n",
    "    for i, k in enumerate(pcs):\n",
    "        data = pd.read_csv(os.path.join(RESULTS_DIR, f\"lr={lr1}_{lr2}{f_ext}_pcs_{int(k)}.csv\"), header=None)\n",
    "        risks[i] = data[0]\n",
    "        losses[i] = data[1]\n",
    "    if (~np.isfinite(risks)).any() and np.nonzero(~(~np.isfinite(risks)).any(axis=-1))[0].any():\n",
    "        print(r\"Lr2 with nan/inf, then some lower lr2\")\n",
    "        idx=np.nonzero(~(~np.isfinite(risks)).any(axis=-1))[0][-1] + 1\n",
    "        for j in range(10):\n",
    "            print(pcs[idx-j])\n",
    "    else:\n",
    "        print('No nans/inf values')\n",
    "        \n",
    "    #ratios = np.array(lrs_float)/lr\n",
    "            \n",
    "    # Subsample epochs\n",
    "    geo_samples = [int(i) for i in np.geomspace(1, 50000 - 1, num=700)]\n",
    "    fig, ax = plt.subplots(2,1, sharex=True)\n",
    "\n",
    "    # Plot\n",
    "    im1 = ax[0].imshow(risks[:, geo_samples].transpose()[::-1, :], interpolation='none', aspect='auto', vmax=vmax[0], vmin=vmin[0])\n",
    "    im2 = ax[1].imshow(losses[:, geo_samples].transpose()[::-1, :], interpolation='none', aspect='auto', vmax=vmax[1], vmin=vmin[1])\n",
    "    fig.colorbar(im1, ax=ax[0])\n",
    "    fig.colorbar(im2, ax=ax[1])\n",
    "    \n",
    "    # Title\n",
    "    title = fr\"$\\eta_{{\\mathbf{{w}}}} = {lr1}, \\eta_{{\\mathbf{{v}}}} = {lr2}$\"\n",
    "    \n",
    "    if batch_norm:\n",
    "        title += \", with batch normalization\"\n",
    "    plt.suptitle(title)\n",
    "    \n",
    "    # Set correct x- and y-ticks\n",
    "    # X axis\n",
    "    #ten_powers = 10.0 ** np.arange(-5, 6)\n",
    "    #indices = []\n",
    "    #for val in ten_powers:\n",
    "    #    indices += [np.argmin(np.abs(ratios-val))]\n",
    "    \n",
    "    for k in [1]:\n",
    "        inds = np.arange(0, len(pcs), 5)\n",
    "        ax[k].set_xticks(inds)\n",
    "        ax[k].set_xticklabels([pcs[i] for i in inds])\n",
    "        ax[k].set_xlabel(\"Rank of feature matrix\")\n",
    "    \n",
    "    \n",
    "    # Y axis\n",
    "    ten_powers = 10.0 ** np.arange(4, 0, -1)\n",
    "    indices = []\n",
    "    for val in ten_powers:\n",
    "        indices += [np.argmin(np.abs(geo_samples-val))]\n",
    "    for k in range(2):\n",
    "        ax[k].set_yticks(indices)\n",
    "        ax[k].set_yticklabels([f\"$10^{{{i}}}$\" for i in np.arange(1, 5)])\n",
    "        ax[k].set_ylabel(r\"Iteration $t$\")\n",
    "    \n",
    "    # Save file\n",
    "    save_dir = \"plots\"\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)  \n",
    "        \n",
    "    \n",
    "    figname = append_id(get_filename(lr1, vmax[0], batch_norm), \"pcs\")\n",
    "    plt.savefig(os.path.join(\"plots\", figname), bbox_inches='tight')\n",
    "    \n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852fd722",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_results(1e-4, vmax=[9000, 20000], vmin=[6000, 0], batch_norm=False, uniform_noise=True, coupled_noise=10.0, ext='_2.0_dim_100', plot_nans=False, num_its=100001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4259cf64",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_individual_run(0.0001, 0.0001, batch_norm=False, uniform_noise=True, coupled_noise=10.0, ext='2.0_dim_100', plot_extra=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64c008f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_individual_runs_range_pcs(0.0001, 0.0001, 0, 100, batch_norm=False, uniform_noise=True, coupled_noise=10.0, ext='_10.0_dim_100', ymin=[9e3, 0], ymax=[2e4, 10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fce8b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results_pcs(0.0001, 0.0001, vmax=[9.5e5, 10000], vmin=[9e5, 0], batch_norm=False, uniform_noise=True, coupled_noise=100.0, ext='_10.0_dim_100', num_its=100001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5d46fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for eta_w in [1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2]:\n",
    "    plot_results(eta_w, 20, plot_nans=False, batch_norm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca29e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_individual_runs_range(1e-4, 1e-3, 50, batch_norm=False, uniform_noise=True, coupled_noise=10.0, ext='_2.0_dim_100', ymin=[6000, 0], ymax=[9000, 20000], mod=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2e2fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_same_lr(vmax=[37.5, 1000], vmin=[37, 0], batch_norm=False, uniform_noise=True, coupled_noise=50.0, ext='_dim_100', plot_nans=False, num_its=100001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef500930",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
