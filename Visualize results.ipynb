{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8fbc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append('code/')\n",
    "from linear_utils import is_float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62836500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESULTS_DIR = os.path.join(\"P:/early_stopping_double_descent\", \"...\") # enter folder direction here (i.e., two_layer_results)\n",
    "RESULTS_DIR = \"results/two_layer_results_l2/transform_data\" #five_layer_regression_results\"\n",
    "\n",
    "SMALL_SIZE = 10\n",
    "MEDIUM_SIZE = 12\n",
    "BIGGER_SIZE = 14\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('axes', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "\n",
    "\n",
    "def get_all_files(lr, batch_norm, uniform_noise, coupled_noise=None, ext='', is_lr2=False):\n",
    "    files = os.listdir(RESULTS_DIR)\n",
    "    \n",
    "    if is_lr2:\n",
    "        # Given lr is for second layer\n",
    "        files = [file for file in files if file.split('_')[1].startswith(f'{lr}')]\n",
    "    else:\n",
    "        files = [file for file in files if file.startswith(f'lr={lr}')]\n",
    "\n",
    "    if batch_norm:\n",
    "        files = [file for file in files if \"batch_norm\" in file]\n",
    "    elif uniform_noise:\n",
    "        files = [file for file in files if \"uniform_noise\" in file]    \n",
    "    else:\n",
    "        files = [file for file in files if \"batch_norm\" and \"uniform_noise\" not in file]\n",
    "        \n",
    "    # Sorry, I will clean this up eventually\n",
    "    if coupled_noise is not None:\n",
    "        files = [file for file in files if f\"coupled_noise_{coupled_noise}\" in file]  \n",
    "        \n",
    "    files = [file for file in files if ext in file]\n",
    "    \n",
    "    return files\n",
    "\n",
    "def get_files(batch_norm, uniform_noise, coupled_noise=None, ext=''):\n",
    "    files = os.listdir(RESULTS_DIR)\n",
    "    files = [file for file in files if file.endswith(\".csv\")]\n",
    "    if batch_norm:\n",
    "        files = [file for file in files if \"batch_norm\" in file]\n",
    "    #else:\n",
    "        #files = [file for file in files if \"batch_norm\" not in file]\n",
    "    elif uniform_noise:\n",
    "        files = [file for file in files if \"uniform_noise\" in file]\n",
    "    else:\n",
    "        files = [file for file in files if \"batch_norm\" and \"uniform_noise\" not in file]\n",
    "        \n",
    "    if coupled_noise is not None:\n",
    "        files = [file for file in files if f\"coupled_noise_{coupled_noise}\" in file]  \n",
    "        \n",
    "    files = [file for file in files if ext in file]\n",
    "    \n",
    "    return files\n",
    "\n",
    "def append_id(filename, id):\n",
    "    return \"{0}_{2}.{1}\".format(*filename.rsplit('.', 1) + [id])\n",
    "\n",
    "def get_filename_individual(lr1, lr2, batch_norm):\n",
    "    result_path = os.path.split(RESULTS_DIR)[1]\n",
    "    result_path_split = result_path.split('_')\n",
    "    linear = result_path_split[-1] == \"linear\"\n",
    "    if linear:\n",
    "        w = '_'.join(result_path_split[-3:-1])\n",
    "    else:\n",
    "        w = '_'.join(result_path_split[-2:])\n",
    "    \n",
    "    name = f'lr1={lr1}_lr2={lr2}_w={w}.pdf'\n",
    "    \n",
    "    if batch_norm:\n",
    "        name = append_id(name, \"batch_norm\")\n",
    "    if linear:\n",
    "        name = append_id(name, \"linear\")\n",
    "    return name\n",
    "\n",
    "def get_filename_range(lr1, lr2_low, lr2_high, batch_norm, uniform_noise=False):\n",
    "    result_path = os.path.split(RESULTS_DIR)[1]\n",
    "    result_path_split = result_path.split('_')\n",
    "    linear = result_path_split[-1] == \"linear\"\n",
    "    if linear:\n",
    "        w = '_'.join(result_path_split[-3:-1])\n",
    "    else:\n",
    "        w = '_'.join(result_path_split[-2:])\n",
    "    \n",
    "    name = f'lr1={lr1}_lr2_low={lr2_low}_lr2_high=_{lr2_high}_w={w}.pdf'\n",
    "    \n",
    "    if batch_norm:\n",
    "        name = append_id(name, \"batch_norm\")\n",
    "    elif uniform_noise:\n",
    "        name = append_id(name, \"uniform_noise\")\n",
    "\n",
    "    if linear:\n",
    "        name = append_id(name, \"linear\")\n",
    "        \n",
    "    return name\n",
    "\n",
    "def get_filename_range_pcs(lr1, lr2, pc_low, pc_high, batch_norm, uniform_noise=False):\n",
    "    result_path = os.path.split(RESULTS_DIR)[1]\n",
    "    result_path_split = result_path.split('_')\n",
    "    linear = result_path_split[-1] == \"linear\"\n",
    "    if linear:\n",
    "        w = '_'.join(result_path_split[-3:-1])\n",
    "    else:\n",
    "        w = '_'.join(result_path_split[-2:])\n",
    "    \n",
    "    name = f'lr1={lr1}_lr2={lr2}_pc_low={pc_low}_pc_high=_{pc_high}.pdf'\n",
    "    \n",
    "    if batch_norm:\n",
    "        name = append_id(name, \"batch_norm\")\n",
    "    elif uniform_noise:\n",
    "        name = append_id(name, \"uniform_noise\")\n",
    "\n",
    "    if linear:\n",
    "        name = append_id(name, \"linear\")\n",
    "        \n",
    "    return name\n",
    "\n",
    "def get_filename_range_kappas(lr1, lr2, kappa_low, kappa_high, batch_norm, uniform_noise=False):\n",
    "    result_path = os.path.split(RESULTS_DIR)[1]\n",
    "    result_path_split = result_path.split('_')\n",
    "    linear = result_path_split[-1] == \"linear\"\n",
    "    if linear:\n",
    "        w = '_'.join(result_path_split[-3:-1])\n",
    "    else:\n",
    "        w = '_'.join(result_path_split[-2:])\n",
    "    \n",
    "    name = f'lr1={lr1}_lr2={lr2}_kappa_low={kappa_low}_kappa_high=_{kappa_high}.pdf'\n",
    "    \n",
    "    if batch_norm:\n",
    "        name = append_id(name, \"batch_norm\")\n",
    "    elif uniform_noise:\n",
    "        name = append_id(name, \"uniform_noise\")\n",
    "\n",
    "    if linear:\n",
    "        name = append_id(name, \"linear\")\n",
    "        \n",
    "    return name\n",
    "\n",
    "def plot_individual_run(lr1, lr2, batch_norm, uniform_noise=False, coupled_noise=None, ext='', plot_extra=False, extra_labels=None):\n",
    "    \n",
    "    file_path = os.path.join(RESULTS_DIR, f\"lr={lr1}_{lr2}.csv\")\n",
    "    if batch_norm:\n",
    "        file_path = append_id(file_path, \"batch_norm\") \n",
    "    elif uniform_noise:\n",
    "        file_path = append_id(file_path, \"uniform_noise\") \n",
    "        \n",
    "    if coupled_noise is not None:\n",
    "        file_path = append_id(file_path, f\"coupled_noise_{coupled_noise}\") \n",
    "        \n",
    "    file_path = append_id(file_path, ext)\n",
    "    \n",
    "    data = pd.read_csv(file_path, header=None)\n",
    "    \n",
    "    #data = data.to_numpy()\n",
    "     \n",
    "    #data_list = [data[:, 0], data[:, 1], data[:, 2:].sum(axis=-1)]\n",
    "    #extra_labels = [\"Weight MSE\"]\n",
    "\n",
    "    #splits = np.arange(10, 100, 5)\n",
    "    #for split in splits:\n",
    "    #    data_list += [data[:, 2:(split+2)].sum(axis=-1), data[:, (split+2):].sum(axis=-1)]\n",
    "    #    extra_labels += [f\"Weight MSE, split {split}, upper\", f\"Weight MSE, split {split}, lower\"]\n",
    "        \n",
    "    #data = pd.DataFrame(np.column_stack(data_list))\n",
    "    \n",
    "    geo_samples = [int(i) for i in np.geomspace(1, len(data) - 1, num=700)]\n",
    "    cmap = matplotlib.colormaps['viridis']\n",
    "    colorList = [cmap(50 / 1000), cmap(350 / 1000)]\n",
    "    labelList = ['Test', 'Train']\n",
    "    \n",
    "    if plot_extra:\n",
    "        assert data.shape[-1] > 2, \"No extra data saved\"\n",
    "        num_vec = data.shape[-1]\n",
    "        colorList += [cmap((450 + 100 * t) / 1000) for t in range(num_vec - 2)]\n",
    "        labelList = labelList + extra_labels if extra_labels is not None else labelList + [i for i in range(num_vec - 2)]\n",
    "    else:\n",
    "        num_vec = 2\n",
    "\n",
    "    #fig = plt.figure()\n",
    "    fig, ax = plt.subplots(num_vec+1, 1, figsize=(5, num_vec * 3), sharex=True)\n",
    "    for k in range(num_vec):\n",
    "        ax[k].set_xscale('log')\n",
    "            \n",
    "        data_vec = data[k]\n",
    "        print(data_vec[0])\n",
    "        print(data_vec.min())\n",
    "        ax[k].plot(geo_samples, data_vec[geo_samples],\n",
    "            color=colorList[k],\n",
    "            label=labelList[k],\n",
    "            lw=4)\n",
    "        ax[k].set_ylabel(labelList[k])\n",
    "      \n",
    "    if plot_extra:\n",
    "        data_vec = data.iloc[:,2:].sum(axis=1)\n",
    "        ax[-1].plot(geo_samples, data_vec[geo_samples],\n",
    "                color=colorList[k],\n",
    "                label=labelList[k],\n",
    "                lw=4)\n",
    "        ax[-1].set_ylabel('Sum')\n",
    "        #ax[3].set_ylim([8, 17])\n",
    "                \n",
    "    plt.suptitle(fr\"$\\eta_{{\\mathbf{{W}}}} = {lr1}$, $\\eta_{{\\mathbf{{v}}}} = {lr2}$\")\n",
    "    \n",
    "    save_dir = \"plots\"\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)  \n",
    "        \n",
    "    plt.savefig(os.path.join(save_dir, get_filename_individual(lr1, lr2, batch_norm)))\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def get_filename(lr, vmax, batch_norm):\n",
    "    result_path = os.path.split(RESULTS_DIR)[1]\n",
    "    result_path_split = result_path.split('_')\n",
    "    linear = result_path_split[-1] == \"linear\"\n",
    "    if linear:\n",
    "        w = '_'.join(result_path_split[-3:-1])\n",
    "    else:\n",
    "        w = '_'.join(result_path_split[-2:])\n",
    "    \n",
    "    name = f'{lr}_vmax={vmax}_w={w}.pdf'\n",
    "    if batch_norm:\n",
    "        name = append_id(name, \"batch_norm\")\n",
    "    if linear:\n",
    "        name = append_id(name, \"linear\")\n",
    "        \n",
    "    return name\n",
    "\n",
    "def plot_results(lr, vmax=20, vmin=0, keep_nan=True, batch_norm=False, uniform_noise=False, coupled_noise=None, ext='', \n",
    "                 plot_nans=False, num_its=50000, fixed_lr2=False):\n",
    "    \n",
    "    files = get_all_files(lr, batch_norm, uniform_noise, coupled_noise, ext, fixed_lr2)\n",
    "        \n",
    "    if not isinstance(vmax, list):\n",
    "        vmax = [vmax] * 2\n",
    "    if not isinstance(vmin, list):\n",
    "        vmin = [vmin] * 2\n",
    "    \n",
    "    if batch_norm:\n",
    "        f_ext = \"_batch_norm\"\n",
    "    elif uniform_noise:\n",
    "        f_ext = \"_uniform_noise\"\n",
    "    else:\n",
    "        f_ext = \"\"\n",
    "        \n",
    "    #if batch_norm or uniform_noise:\n",
    "    lrs = [(f.split('_')[0]).split('=')[1] for f in files] if fixed_lr2 else [f.split('_')[1] for f in files]\n",
    "    #else:\n",
    "    #    lrs = [f.split('_')[-1][:-4] for f in files]\n",
    "\n",
    "    \n",
    "    lrs = list(set(lrs))\n",
    "    \n",
    "    print(lrs)\n",
    "    if coupled_noise:\n",
    "        f_ext += f\"_coupled_noise_{coupled_noise}\"\n",
    "                \n",
    "    f_ext += ext + \".csv\"\n",
    "    \n",
    "    #assert len(lrs) == 99, \"Something wrong with the amount of files\"\n",
    "    lrs_float = [float(l) for l in lrs]\n",
    "    lrs_float, lrs = zip(*sorted(zip(lrs_float, lrs)))\n",
    "    \n",
    "    risks = np.zeros((len(lrs), num_its))\n",
    "    losses = np.zeros((len(lrs), num_its))\n",
    "    for i, l in enumerate(lrs):\n",
    "        if fixed_lr2:\n",
    "            data = pd.read_csv(os.path.join(RESULTS_DIR, f\"lr={l}_{lr}{f_ext}\"), header=None)\n",
    "        else:\n",
    "            data = pd.read_csv(os.path.join(RESULTS_DIR, f\"lr={lr}_{l}{f_ext}\"), header=None)\n",
    "        \n",
    "        risks[i] = data[0]\n",
    "        losses[i] = data[1]\n",
    "    if (~np.isfinite(risks)).any() and np.nonzero(~(~np.isfinite(risks)).any(axis=-1))[0].any():\n",
    "        print(r\"Lr2 with nan/inf, then some lower lr2\")\n",
    "        idx=np.nonzero(~(~np.isfinite(risks)).any(axis=-1))[0][-1] + 1\n",
    "        for j in range(10):\n",
    "            if plot_nans:\n",
    "                plot_individual_run(lr, lrs[idx-j], batch_norm)\n",
    "            else:\n",
    "                print(lrs[idx-j])\n",
    "    else:\n",
    "        print('No nans/inf values')\n",
    "    ratios = np.array(lrs_float)/lr\n",
    "            \n",
    "    # Subsample epochs\n",
    "    geo_samples = [int(i) for i in np.geomspace(1, 50000 - 1, num=700)]\n",
    "    fig, ax = plt.subplots(2,1, sharex=True)\n",
    "\n",
    "    # Plot\n",
    "    im1 = ax[0].imshow(risks[:, geo_samples].transpose()[::-1, :], interpolation='none', aspect='auto', vmax=vmax[0], vmin=vmin[0])\n",
    "    im2 = ax[1].imshow(losses[:, geo_samples].transpose()[::-1, :], interpolation='none', aspect='auto', vmax=vmax[1], vmin=vmin[1])\n",
    "    fig.colorbar(im1, ax=ax[0])\n",
    "    fig.colorbar(im2, ax=ax[1])\n",
    "    \n",
    "    # Title\n",
    "    title = fr\"$\\eta_{{\\mathbf{{v}}}}={lr}$\" if fixed_lr2 else fr\"$\\eta_{{\\mathbf{{W}}}}={lr}$\"\n",
    "    \n",
    "    if batch_norm:\n",
    "        title += \", with batch normalization\"\n",
    "    plt.suptitle(title)\n",
    "    \n",
    "    # Set correct x- and y-ticks\n",
    "    # X axis\n",
    "    ten_powers = 10.0 ** np.arange(-5, 6)\n",
    "    indices = []\n",
    "    for val in ten_powers:\n",
    "        indices += [np.argmin(np.abs(ratios-val))]\n",
    "    \n",
    "    for k in [1]:\n",
    "        ax[k].set_xticks(indices)\n",
    "        ax[k].set_xticklabels([f\"$10^{{{i}}}$\" for i in np.arange(-5, 6)])\n",
    "        ax[k].set_xlabel(r\"$\\eta_{\\mathbf{W}} / \\eta_{\\mathbf{v}}$\" if fixed_lr2 else r\"$\\eta_{\\mathbf{v}} / \\eta_{\\mathbf{W}}$\")\n",
    "    \n",
    "    # Y axis\n",
    "    ten_powers = 10.0 ** np.arange(4, 0, -1)\n",
    "    indices = []\n",
    "    for val in ten_powers:\n",
    "        indices += [np.argmin(np.abs(geo_samples-val))]\n",
    "    for k in range(2):\n",
    "        ax[k].set_yticks(indices)\n",
    "        ax[k].set_yticklabels([f\"$10^{{{i}}}$\" for i in np.arange(1, 5)])\n",
    "        ax[k].set_ylabel(r\"Iteration $t$\")\n",
    "    \n",
    "    # Save file\n",
    "    save_dir = \"plots\"\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)  \n",
    "        \n",
    "    \n",
    "    figname = get_filename(lr, vmax[0], batch_norm)\n",
    "    plt.savefig(os.path.join(\"plots\", figname), bbox_inches='tight')\n",
    "    \n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "def plot_same_lr(vmax=20, vmin=0, batch_norm=False, uniform_noise=False, coupled_noise=None, ext='', plot_nans=False, num_its=50000):\n",
    "    \n",
    "    files = get_files(batch_norm, uniform_noise, coupled_noise, ext)\n",
    "    \n",
    "    files = [f for f in files if f.split('_')[0][3:] == f.split('_')[1]]\n",
    "    \n",
    "    if not isinstance(vmax, list):\n",
    "        vmax = [vmax] * 2\n",
    "    if not isinstance(vmin, list):\n",
    "        vmin = [vmin] * 2\n",
    "    \n",
    "    if batch_norm:\n",
    "        f_ext = \"_batch_norm\"\n",
    "        lrs = [f.split('_')[1] for f in files]\n",
    "    elif uniform_noise:\n",
    "        f_ext = \"_uniform_noise\"\n",
    "        lrs = [f.split('_')[1] for f in files]        \n",
    "    else:\n",
    "        f_ext = \"\"\n",
    "        lrs = [f.split('_')[-1][:-4] for f in files]\n",
    "        \n",
    "    if coupled_noise:\n",
    "        f_ext += f\"_coupled_noise_{coupled_noise}\"\n",
    "                \n",
    "    f_ext += ext + \".csv\"\n",
    "        \n",
    "    assert len(lrs) == 91 or len(lrs) == 99, \"Not right amount of files\"\n",
    "    lrs_float = [float(l) for l in lrs]\n",
    "    lrs_float, lrs = zip(*sorted(zip(lrs_float, lrs)))\n",
    "    risks = np.zeros((len(lrs), num_its))\n",
    "    losses = np.zeros((len(lrs), num_its))\n",
    "    for i, lr in enumerate(lrs):\n",
    "        data = pd.read_csv(os.path.join(RESULTS_DIR, f\"lr={lr}_{lr}{f_ext}\"), header=None)\n",
    "        risks[i] = data[0]\n",
    "        losses[i] = data[1]\n",
    "    # Subsample epochs\n",
    "    geo_samples = [int(i) for i in np.geomspace(1, num_its - 1, num=700)]\n",
    "    fig, ax = plt.subplots(2,1, sharex=True)\n",
    "    # Plot\n",
    "    im1 = ax[0].imshow(risks[:, geo_samples].transpose()[::-1, :], interpolation='none', aspect='auto', vmax=vmax[0], vmin=vmin[0])\n",
    "    fig.colorbar(im1, ax=ax[0])\n",
    "    im2 = ax[1].imshow(losses[:, geo_samples].transpose()[::-1, :], interpolation='none', aspect='auto', vmax=vmax[1], vmin=vmin[1])\n",
    "    fig.colorbar(im2, ax=ax[1])\n",
    "    \n",
    "    # Title\n",
    "    title = fr\"Same lr for both layers\"\n",
    "    if batch_norm:\n",
    "        title += \", with batch normalization\"\n",
    "    plt.suptitle(title)\n",
    "    \n",
    "    # Set correct x- and y-ticks\n",
    "    # X axis\n",
    "    ten_powers = 10.0 ** np.arange(-7, -1)\n",
    "    indices = []\n",
    "    for val in ten_powers:\n",
    "        indices += [np.argmin(np.abs(lrs_float-val))]\n",
    "    \n",
    "    ax[1].set_xticks(indices)\n",
    "    ax[1].set_xticklabels([f\"$10^{{{i}}}$\" for i in np.arange(-7, -1)])\n",
    "    ax[1].set_xlabel(\"lr\")\n",
    "    \n",
    "    # Y axis\n",
    "    ten_powers = 10.0 ** np.arange(4, 0, -1)\n",
    "    indices = []\n",
    "    for val in ten_powers:\n",
    "        indices += [np.argmin(np.abs(geo_samples-val))]\n",
    "    for k in range(2):\n",
    "        ax[k].set_yticks(indices)\n",
    "        ax[k].set_yticklabels([f\"$10^{{{i}}}$\" for i in np.arange(1, 5)])\n",
    "        ax[k].set_ylabel(r\"Iteration $t$\")\n",
    "    \n",
    "    figname = get_filename(lr, vmax, batch_norm)\n",
    "    plt.savefig(os.path.join(\"plots\", figname), bbox_inches='tight')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f2b78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for plotting a selection of curves\n",
    "\n",
    "def plot_individual_runs_range(lr1, lr_ratio_low, lr_ratio_high, batch_norm=False, uniform_noise=False, coupled_noise=None, \n",
    "                               ext='', ymin=[0, 0], ymax = [50, 150000], mod=1, fixed_lr2=False):\n",
    "    \"\"\"Plot individual runs within range lr_ratio_low to lr_ratio_high\"\"\"\n",
    "    \n",
    "    files = get_all_files(lr1, batch_norm, uniform_noise, coupled_noise, ext, fixed_lr2)\n",
    "\n",
    "    if batch_norm:\n",
    "        f_ext = \"_batch_norm\"\n",
    "        #lrs = [f.split('_')[1] for f in files]\n",
    "    elif uniform_noise:\n",
    "        f_ext = \"_uniform_noise\"\n",
    "        #lrs = [f.split('_')[1] for f in files]\n",
    "    else:\n",
    "        f_ext = \"\"\n",
    "        #lrs = [f.split('_')[-1][:-4] for f in files]\n",
    "        \n",
    "    if coupled_noise:\n",
    "        f_ext += f\"_coupled_noise_{coupled_noise}\"\n",
    "                \n",
    "    f_ext += ext + \".csv\"\n",
    "    \n",
    "    lrs = [(f.split('_')[0]).split('=')[1] for f in files] if fixed_lr2 else [f.split('_')[1] for f in files]\n",
    "    lrs = list(set(lrs))\n",
    "    \n",
    "    # Keep runs only within range\n",
    "    lr2_low, lr2_high = lr_ratio_low * lr1, lr_ratio_high * lr1\n",
    "    # files = [f for f, lr in zip(files, lrs) if float(lr) >= lr2_low and float(lr) <= lr2_high]\n",
    "    lrs = [float(lr) for lr in lrs if float(lr) >= lr2_low and float(lr) <= lr2_high]\n",
    "    lrs.sort()\n",
    "    \n",
    "    #lrs = [lr for i, lr in enumerate(lrs) if np.mod(i, mod) == 0]\n",
    "\n",
    "    fig, ax = plt.subplots(2, 1, sharex=True, figsize=(8,10))\n",
    "    ylabels = [\"Test loss\", \"Training loss\"]\n",
    "    for i, lr in enumerate(lrs):\n",
    "        \n",
    "        if fixed_lr2:\n",
    "            data = pd.read_csv(os.path.join(RESULTS_DIR, f\"lr={lr}_{lr1}{f_ext}\"), header=None)       \n",
    "        else:\n",
    "            data = pd.read_csv(os.path.join(RESULTS_DIR, f\"lr={lr1}_{lr}{f_ext}\"), header=None)\n",
    "            \n",
    "        geo_samples = [int(i) for i in np.geomspace(1, len(data) - 1, num=700)]\n",
    "\n",
    "        for k in range(2):\n",
    "            if i == 0:\n",
    "                ax[k].set_xscale('log')\n",
    "                ax[k].set_ylim([ymin[k], ymax[k]])\n",
    "                ax[k].set_ylabel(ylabels[k])\n",
    "            \n",
    "            data_vec = data[k] \n",
    "            ax[k].plot(geo_samples, data_vec[geo_samples],\n",
    "#                color=colorList[k],\n",
    "                lw=2)\n",
    "            \n",
    "    ax[0].legend([fr\"$\\eta_{{\\mathbf{{W}}}} = {lr2}$\" for lr2 in lrs] if fixed_lr2 else [fr\"$\\eta_{{\\mathbf{{v}}}} = {lr2}$\" for lr2 in lrs], loc=2)\n",
    "    fig.suptitle(fr\"$\\eta_{{\\mathbf{{v}}}} = {lr1}$\" if fixed_lr2 else fr\"$\\eta_{{\\mathbf{{w}}}} = {lr1}$\")\n",
    "\n",
    "    save_dir = \"plots\"\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)  \n",
    "\n",
    "    plt.savefig(os.path.join(save_dir, get_filename_range(lr1, lr2_low, lr2_high, batch_norm, uniform_noise)))\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecef626",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_individual_runs_range_pcs(lr1, lr2, pc_low, pc_high, batch_norm=False, uniform_noise=False, coupled_noise=None, ext='', ymin=[0, 0], ymax = [50, 150000]):\n",
    "    \"\"\"Plot individual runs within range lr_ratio_low to lr_ratio_high\"\"\"\n",
    "    \n",
    "    files = get_all_files(lr1, batch_norm, uniform_noise, coupled_noise, ext)\n",
    "    files = [file for file in files if file.startswith(f'lr={lr1}_{lr2}')]\n",
    "    files = [file for file in files if \"pcs\" in file]    \n",
    "\n",
    "    if batch_norm:\n",
    "        f_ext = \"_batch_norm\"\n",
    "    elif uniform_noise:\n",
    "        f_ext = \"_uniform_noise\"\n",
    "    else:\n",
    "        f_ext = \"\"\n",
    "        \n",
    "    if coupled_noise:\n",
    "        f_ext += f\"_coupled_noise_{coupled_noise}\"\n",
    "                \n",
    "    f_ext += ext \n",
    "        \n",
    "    pcs = [(f.split('_')[-1]).split('.')[0] for f in files]\n",
    "\n",
    "    # Keep runs only within range\n",
    "    # files = [f for f, lr in zip(files, lrs) if float(lr) >= lr2_low and float(lr) <= lr2_high]\n",
    "    pcs = [float(pc) for pc in pcs if float(pc) >= pc_low and float(pc) <= pc_high]\n",
    "    pcs = [pc for i, pc in enumerate(pcs) if np.mod(i, 2) == 0]\n",
    "\n",
    "    pcs.sort()\n",
    "\n",
    "    fig, ax = plt.subplots(2, 1, sharex=True, figsize=(8,10))\n",
    "    ylabels = [\"Test loss\", \"Training loss\"]\n",
    "    for i, k in enumerate(pcs):\n",
    "        data = pd.read_csv(os.path.join(RESULTS_DIR, f\"lr={lr1}_{lr2}{f_ext}_pcs_{int(k)}.csv\"), header=None)       \n",
    "        geo_samples = [int(i) for i in np.geomspace(1, len(data) - 1, num=700)]\n",
    "\n",
    "        for j in range(2):\n",
    "            if i == 0:\n",
    "                ax[j].set_xscale('log')\n",
    "                ax[j].set_ylim([ymin[j], ymax[j]])\n",
    "                ax[j].set_ylabel(ylabels[j])\n",
    "            \n",
    "            data_vec = data[k] \n",
    "            ax[j].plot(geo_samples, data_vec[geo_samples],\n",
    "#                color=colorList[k],\n",
    "                lw=2)\n",
    "            \n",
    "    ax[0].legend([f\"Comp. {int(pc)}\" for pc in pcs], loc=2)\n",
    "    fig.suptitle(fr\"$\\eta_{{\\mathbf{{w}}}} = {lr1}, \\eta_{{\\mathbf{{v}}}} = {lr2}$\")\n",
    "\n",
    "    save_dir = \"plots\"\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)  \n",
    "\n",
    "    plt.savefig(os.path.join(save_dir, get_filename_range_pcs(lr1, lr2, pc_low, pc_high, batch_norm, uniform_noise)))\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def plot_results_pcs(lr1, lr2, vmax=20, vmin=0, keep_nan=True, batch_norm=False, uniform_noise=False, coupled_noise=None, ext='', num_its=50000):\n",
    "    files = get_all_files(lr1, batch_norm, uniform_noise, coupled_noise, ext)\n",
    "    files = [file for file in files if file.startswith(f'lr={lr1}_{lr2}')]\n",
    "    files = [file for file in files if \"pcs\" in file]    \n",
    "\n",
    "    \n",
    "    if not isinstance(vmax, list):\n",
    "        vmax = [vmax] * 2\n",
    "    if not isinstance(vmin, list):\n",
    "        vmin = [vmin] * 2\n",
    "    \n",
    "    if batch_norm:\n",
    "        f_ext = \"_batch_norm\"\n",
    "    elif uniform_noise:\n",
    "        f_ext = \"_uniform_noise\"\n",
    "    else:\n",
    "        f_ext = \"\"\n",
    "        \n",
    "    if coupled_noise:\n",
    "        f_ext += f\"_coupled_noise_{coupled_noise}\"\n",
    "                \n",
    "    f_ext += ext #+ \".csv\"\n",
    "    \n",
    "    #assert len(lrs) == 100, \"Something wrong with the amount of files\"\n",
    "    pcs = [(f.split('_')[-1]).split('.')[0] for f in files] \n",
    "    pcs = [float(pc) for pc in pcs]\n",
    "    pcs.sort()\n",
    "    \n",
    "    #pcs = pcs[:-1]\n",
    "\n",
    "    risks = np.zeros((len(pcs), num_its))\n",
    "    losses = np.zeros((len(pcs), num_its))\n",
    "    for i, k in enumerate(pcs):\n",
    "        data = pd.read_csv(os.path.join(RESULTS_DIR, f\"lr={lr1}_{lr2}{f_ext}_pcs_{int(k)}.csv\"), header=None)\n",
    "        risks[i] = data[0]\n",
    "        losses[i] = data[1]\n",
    "    if (~np.isfinite(risks)).any() and np.nonzero(~(~np.isfinite(risks)).any(axis=-1))[0].any():\n",
    "        print(r\"Lr2 with nan/inf, then some lower lr2\")\n",
    "        idx=np.nonzero(~(~np.isfinite(risks)).any(axis=-1))[0][-1] + 1\n",
    "        for j in range(10):\n",
    "            print(pcs[idx-j])\n",
    "    else:\n",
    "        print('No nans/inf values')\n",
    "        \n",
    "    #ratios = np.array(lrs_float)/lr\n",
    "            \n",
    "    # Subsample epochs\n",
    "    geo_samples = [int(i) for i in np.geomspace(1, num_its - 1, num=700)]\n",
    "    fig, ax = plt.subplots(2,1, sharex=True)\n",
    "\n",
    "    # Plot\n",
    "    im1 = ax[0].imshow(risks[:, geo_samples].transpose()[::-1, :], interpolation='none', aspect='auto', vmax=vmax[0], vmin=vmin[0])\n",
    "    im2 = ax[1].imshow(losses[:, geo_samples].transpose()[::-1, :], interpolation='none', aspect='auto', vmax=vmax[1], vmin=vmin[1])\n",
    "    fig.colorbar(im1, ax=ax[0])\n",
    "    fig.colorbar(im2, ax=ax[1])\n",
    "    \n",
    "    # Title\n",
    "    title = fr\"$\\eta_{{\\mathbf{{w}}}} = {lr1}, \\eta_{{\\mathbf{{v}}}} = {lr2}$\"\n",
    "    \n",
    "    if batch_norm:\n",
    "        title += \", with batch normalization\"\n",
    "    plt.suptitle(title)\n",
    "    \n",
    "    # Set correct x- and y-ticks\n",
    "    # X axis\n",
    "    #ten_powers = 10.0 ** np.arange(-5, 6)\n",
    "    #indices = []\n",
    "    #for val in ten_powers:\n",
    "    #    indices += [np.argmin(np.abs(ratios-val))]\n",
    "    \n",
    "    for k in [1]:\n",
    "        inds = np.arange(0, len(pcs), 5)\n",
    "        ax[k].set_xticks(inds)\n",
    "        ax[k].set_xticklabels([pcs[i] for i in inds])\n",
    "        ax[k].set_xlabel(\"Rank of feature matrix\")\n",
    "    \n",
    "    \n",
    "    # Y axis\n",
    "    ten_powers = 10.0 ** np.arange(4, 0, -1)\n",
    "    indices = []\n",
    "    for val in ten_powers:\n",
    "        indices += [np.argmin(np.abs(geo_samples-val))]\n",
    "    for k in range(2):\n",
    "        ax[k].set_yticks(indices)\n",
    "        ax[k].set_yticklabels([f\"$10^{{{i}}}$\" for i in np.arange(1, 5)])\n",
    "        ax[k].set_ylabel(r\"Iteration $t$\")\n",
    "    \n",
    "    # Save file\n",
    "    save_dir = \"plots\"\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)  \n",
    "        \n",
    "    \n",
    "    figname = append_id(get_filename(lr1, vmax[0], batch_norm), \"pcs\")\n",
    "    plt.savefig(os.path.join(\"plots\", figname), bbox_inches='tight')\n",
    "    \n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3835a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_individual_runs_range_kappa(lr1, lr2, kappa_low, kappa_high, batch_norm=False, uniform_noise=False, coupled_noise=None, ext='', ymin=[0, 0], ymax = [50, 150000]):\n",
    "    \"\"\"Plot individual runs within range lr_ratio_low to lr_ratio_high\"\"\"\n",
    "    \n",
    "    files = get_all_files(lr1, batch_norm, uniform_noise, coupled_noise, ext)\n",
    "    files = [file for file in files if file.startswith(f'lr={lr1}_{lr2}')]\n",
    "    files = [file for file in files if \"kappa\" in file]    \n",
    "\n",
    "    \n",
    "    if batch_norm:\n",
    "        f_ext = \"_batch_norm\"\n",
    "    elif uniform_noise:\n",
    "        f_ext = \"_uniform_noise\"\n",
    "    else:\n",
    "        f_ext = \"\"\n",
    "        \n",
    "    if coupled_noise:\n",
    "        f_ext += f\"_coupled_noise_{coupled_noise}\"\n",
    "        \n",
    "    f_ext += ext \n",
    "                \n",
    "        \n",
    "    kappas = [(f.split('_')[-1]).split('.csv')[0] for f in files]\n",
    "\n",
    "    # Keep runs only within range\n",
    "    # files = [f for f, lr in zip(files, lrs) if float(lr) >= lr2_low and float(lr) <= lr2_high]\n",
    "    kappas = [float(k) for k in kappas if float(k) >= kappa_low and float(k) <= kappa_high]\n",
    "    kappas = list(set(kappas))\n",
    "    kappas = [k for i, k in enumerate(kappas) if np.mod(i, 2) == 0]\n",
    "\n",
    "    kappas.sort()\n",
    "\n",
    "    fig, ax = plt.subplots(2, 1, sharex=True, figsize=(8,10))\n",
    "    ylabels = [\"Test loss\", \"Training loss\"]\n",
    "    for i, k in enumerate(kappas):\n",
    "        data = pd.read_csv(os.path.join(RESULTS_DIR, f\"lr={lr1}_{lr2}{f_ext}_kappa_{k}.csv\"), header=None)       \n",
    "        geo_samples = [int(i) for i in np.geomspace(1, len(data) - 1, num=700)]\n",
    "\n",
    "        for j in range(2):\n",
    "            if i == 0:\n",
    "                ax[j].set_xscale('log')\n",
    "                ax[j].set_ylim([ymin[j], ymax[j]])\n",
    "                ax[j].set_ylabel(ylabels[j])\n",
    "            \n",
    "            data_vec = data[j] \n",
    "            ax[j].plot(geo_samples, data_vec[geo_samples],\n",
    "#                color=colorList[k],\n",
    "                lw=2)\n",
    "            \n",
    "    ax[0].legend([fr\"$\\kappa =$ {k}\" for k in kappas], loc=2)\n",
    "    fig.suptitle(fr\"$\\eta_{{\\mathbf{{w}}}} = {lr1}, \\eta_{{\\mathbf{{v}}}} = {lr2}$\")\n",
    "\n",
    "    save_dir = \"plots\"\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)  \n",
    "\n",
    "    plt.savefig(os.path.join(save_dir, get_filename_range_kappas(lr1, lr2, kappa_low, kappa_high, batch_norm, uniform_noise)))\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def plot_results_kappa(lr1, lr2, vmax=20, vmin=0, keep_nan=True, batch_norm=False, uniform_noise=False, coupled_noise=None, ext='', num_its=50000):\n",
    "    files = get_all_files(lr1, batch_norm, uniform_noise, coupled_noise, ext)\n",
    "    files = [file for file in files if file.startswith(f'lr={lr1}_{lr2}')]\n",
    "    files = [file for file in files if \"kappa\" in file]  \n",
    "        \n",
    "    if not isinstance(vmax, list):\n",
    "        vmax = [vmax] * 2\n",
    "    if not isinstance(vmin, list):\n",
    "        vmin = [vmin] * 2\n",
    "    \n",
    "    if batch_norm:\n",
    "        f_ext = \"_batch_norm\"\n",
    "    elif uniform_noise:\n",
    "        f_ext = \"_uniform_noise\"\n",
    "    else:\n",
    "        f_ext = \"\"\n",
    "        \n",
    "    if coupled_noise:\n",
    "        f_ext += f\"_coupled_noise_{coupled_noise}\"\n",
    "                \n",
    "    f_ext += ext #+ \".csv\"\n",
    "    \n",
    "    \n",
    "    kappas = [float((f.split('_')[-1]).split('.csv')[0]) for f in files]\n",
    "    kappas = list(set(kappas))\n",
    "\n",
    "    #assert len(lrs) == 100, \"Something wrong with the amount of files\"\n",
    "    #kappas = [k for i, k in enumerate(kappas) if np.mod(i, 2) == 0]\n",
    "    kappas.sort()\n",
    "\n",
    "    risks = np.zeros((len(kappas), num_its))\n",
    "    losses = np.zeros((len(kappas), num_its))\n",
    "    for i, k in enumerate(kappas):\n",
    "        \n",
    "        try:\n",
    "            data = pd.read_csv(os.path.join(RESULTS_DIR, f\"lr={lr1}_{lr2}{f_ext}_kappa_{k}.csv\"), header=None)\n",
    "            risks[i] = data[0]\n",
    "            losses[i] = data[1]\n",
    "        except:\n",
    "            risks[i] = np.zeros((num_its))\n",
    "            losses[i] = np.zeros((num_its))\n",
    "            \n",
    "    if (~np.isfinite(risks)).any() and np.nonzero(~(~np.isfinite(risks)).any(axis=-1))[0].any():\n",
    "        print(r\"Lr2 with nan/inf, then some lower lr2\")\n",
    "        idx=np.nonzero(~(~np.isfinite(risks)).any(axis=-1))[0][-1] + 1\n",
    "        for j in range(10):\n",
    "            print(kappas[idx-j])\n",
    "    else:\n",
    "        print('No nans/inf values')\n",
    "        \n",
    "    #ratios = np.array(lrs_float)/lr\n",
    "            \n",
    "    # Subsample epochs\n",
    "    geo_samples = [int(i) for i in np.geomspace(1, num_its - 1, num=700)]\n",
    "    fig, ax = plt.subplots(2,1, sharex=True)\n",
    "\n",
    "    # Plot\n",
    "    im1 = ax[0].imshow(risks[:, geo_samples].transpose()[::-1, :], interpolation='none', aspect='auto', vmax=vmax[0], vmin=vmin[0])\n",
    "    im2 = ax[1].imshow(losses[:, geo_samples].transpose()[::-1, :], interpolation='none', aspect='auto', vmax=vmax[1], vmin=vmin[1])\n",
    "    fig.colorbar(im1, ax=ax[0])\n",
    "    fig.colorbar(im2, ax=ax[1])\n",
    "    \n",
    "    # Title\n",
    "    title = fr\"$\\eta_{{\\mathbf{{w}}}} = {lr1}, \\eta_{{\\mathbf{{v}}}} = {lr2}$\"\n",
    "    \n",
    "    if batch_norm:\n",
    "        title += \", with batch normalization\"\n",
    "    plt.suptitle(title)\n",
    "    \n",
    "    # Set correct x- and y-ticks\n",
    "    # X axis\n",
    "    #ten_powers = 10.0 ** np.arange(-5, 6)\n",
    "    #indices = []\n",
    "    #for val in ten_powers:\n",
    "    #    indices += [np.argmin(np.abs(ratios-val))]\n",
    "    \n",
    "    for k in [1]:\n",
    "        inds = np.arange(0, len(kappas), 5)\n",
    "        ax[k].set_xticks(inds)\n",
    "        ax[k].set_xticklabels([round(kappas[i], 2) for i in inds])\n",
    "        ax[k].set_xlabel(\"Eigenvalue ratio\")\n",
    "    \n",
    "    \n",
    "    # Y axis\n",
    "    ten_powers = 10.0 ** np.arange(4, 0, -1)\n",
    "    indices = []\n",
    "    for val in ten_powers:\n",
    "        indices += [np.argmin(np.abs(geo_samples-val))]\n",
    "    for k in range(2):\n",
    "        ax[k].set_yticks(indices)\n",
    "        ax[k].set_yticklabels([f\"$10^{{{i}}}$\" for i in np.arange(1, 5)])\n",
    "        ax[k].set_ylabel(r\"Iteration $t$\")\n",
    "    \n",
    "    # Save file\n",
    "    save_dir = \"plots\"\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)  \n",
    "        \n",
    "    \n",
    "    figname = append_id(get_filename(lr1, vmax[0], batch_norm), \"kappas\")\n",
    "    plt.savefig(os.path.join(\"plots\", figname), bbox_inches='tight')\n",
    "    \n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4259cf64",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_individual_run(0.001, 0.001, batch_norm=False, uniform_noise=True, coupled_noise=None, ext='1.0_dim_2_samples_10_hidden_100_linear_kappa_3.0', plot_extra=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d527183",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_individual_runs_range_kappa(0.001, 0.001, 4, 9, batch_norm=False, uniform_noise=True, coupled_noise=None, ext='_1.0_dim_10', ymin=[0, 80], ymax=[100, 150])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c38964",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results_kappa(0.001, 0.001, vmax=[80, 200], vmin=[0, 80], batch_norm=False, uniform_noise=True, coupled_noise=None, ext='_1.0_dim_10', num_its=100001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fddf5253",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_individual_runs_range(0.001, 10, 100, batch_norm=False, uniform_noise=True, coupled_noise=None, ext='_1.0_dim_2_samples_10_kappa_3.0', ymin=[0, 0], ymax=[50, 50], fixed_lr2=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef2991c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(0.001, vmax=[20, 50], vmin=[0, 0], batch_norm=False, uniform_noise=True, coupled_noise=None, ext='_1.0_dim_2_samples_10_kappa_3.0', num_its=100001, fixed_lr2=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64c008f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_individual_runs_range_pcs(0.0001, 0.0001, 0, 100, batch_norm=False, uniform_noise=True, coupled_noise=10.0, ext='_10.0_dim_100', ymin=[9e3, 0], ymax=[2e4, 10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fce8b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results_pcs(0.0001, 0.0001, vmax=[9.5e5, 10000], vmin=[9e5, 0], batch_norm=False, uniform_noise=True, coupled_noise=100.0, ext='_10.0_dim_100', num_its=100001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5d46fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for eta_w in [1e-7, 1e-6, 1e-5, 1e-4, 1e-3, 1e-2]:\n",
    "    plot_results(eta_w, 20, plot_nans=False, batch_norm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca29e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_individual_runs_range(1e-4, 1e-5, 10, batch_norm=False, uniform_noise=True, coupled_noise=5.0, ext='_2.0_dim_100_linear', ymin=[4000, 0], ymax=[60000, 20000], mod=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2e2fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_same_lr(vmax=[37.5, 1000], vmin=[37, 0], batch_norm=False, uniform_noise=True, coupled_noise=50.0, ext='_dim_100', plot_nans=False, num_its=100001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef500930",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
