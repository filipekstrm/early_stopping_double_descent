{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8fbc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append('code/')\n",
    "from linear_utils import is_float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62836500",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SMALL_SIZE = 10\n",
    "MEDIUM_SIZE = 12\n",
    "BIGGER_SIZE = 14\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('axes', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "\n",
    "\n",
    "def get_all_files(sweep=None, key_word=\"\"):\n",
    "    \n",
    "    if sweep is None:\n",
    "        os.listdir(RESULTS_DIR)\n",
    "    else:\n",
    "        files = os.listdir(os.path.join(RESULTS_DIR, sweep))\n",
    "        \n",
    "    files = [file for file in files if \".txt\" in file]\n",
    "    files = [file for file in files if key_word in file]\n",
    "\n",
    "    return files\n",
    "\n",
    "\n",
    "def get_run_name(key_word=\"\", val=None):\n",
    "                    \n",
    "    if val is not None:\n",
    "        run_name = key_word + f\"_{val}\"\n",
    "    else:\n",
    "        run_name = key_word\n",
    "\n",
    "        assert key_word != \"\", \"Empty run name\"\n",
    "        \n",
    "    return run_name\n",
    "\n",
    "\n",
    "def get_file(sweep=None, key_word=\"\", val=None):\n",
    "\n",
    "    files = get_all_files(sweep, key_word)\n",
    "    \n",
    "    if val is None:\n",
    "        file = files[0]\n",
    "    else:\n",
    "        file = [file for file in files if file == get_run_name(key_word, val) + \".txt\"][0]\n",
    "    \n",
    "    return file\n",
    "\n",
    "\n",
    "def append_id(filename, id):\n",
    "    return \"{0}_{2}.{1}\".format(*filename.rsplit('.', 1) + [id])\n",
    "\n",
    "\n",
    "def get_filename(metric, sweep=None, key_word=\"\", val=None):\n",
    "    \n",
    "    name = metric + \"_\" + key_word\n",
    "    \n",
    "    if val is not None:\n",
    "        name += f\"_{val}\"\n",
    "        \n",
    "    if sweep is not None:\n",
    "        name = sweep + \"_\" + name\n",
    "    \n",
    "    return name\n",
    "\n",
    "\n",
    "def get_filename_range(metric, min_val, max_val, sweep=None, key_word=\"\"):\n",
    "    \n",
    "    name = metric + \"_\" + key_word\n",
    "    \n",
    "    name += f\"_min_{min_val}_max_{max_val}\"\n",
    "    \n",
    "    if sweep is not None:\n",
    "        name = sweep + \"_\" + name\n",
    "    \n",
    "    return name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8d1551",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_individual_run(metrics, labels, sweep=None, key_word=\"\", val=None, num_its=100001, refs=None):\n",
    "    \n",
    "    assert len(metrics) == len(labels), \"Must provide a label for each metric\"\n",
    "    \n",
    "    file = get_file(sweep, key_word, val)\n",
    "    \n",
    "    if sweep is None:\n",
    "        base_dir = RESULTS_DIR\n",
    "    else:\n",
    "        base_dir = os.path.join(RESULTS_DIR, sweep)\n",
    "    \n",
    "    with open(os.path.join(base_dir, file), \"r\") as f:\n",
    "        # Load the dictionary from the file\n",
    "        data_dict = json.load(f)\n",
    "    \n",
    "    print(data_dict.keys())\n",
    "        \n",
    "    geo_samples = [int(i) for i in np.geomspace(1, num_its - 1, num=700)]\n",
    "    cmap = matplotlib.colormaps['viridis']\n",
    "    #colors = [cmap((50 + 300 * i) / 1000) for i in range(len(metrics))]\n",
    "    \n",
    "    fig, ax = plt.subplots(len(metrics), 1, figsize=(5, len(metrics) * 3), sharex=True)\n",
    "    for k, metric in enumerate(metrics):\n",
    "        ax[k].set_xscale('log') # ??\n",
    "        ax[k].set_ylabel(labels[k])\n",
    "   \n",
    "        data_vec = None    \n",
    "        if isinstance(metric, list):\n",
    "            for i, m in enumerate(metric):\n",
    "                assert m in data_dict, \"Unknown metric\"\n",
    "\n",
    "                if i == 0:\n",
    "                    data_vec = np.array(data_dict[m])\n",
    "                else:\n",
    "                    data_vec *= np.array(data_dict[m])\n",
    "\n",
    "        else:\n",
    "            assert metric in data_dict, \"Unknown metric\"\n",
    "            data_vec = np.array(data_dict[metric])\n",
    "        \n",
    "        ax[k].plot(geo_samples, data_vec[geo_samples],\n",
    "            #color=colors[k],\n",
    "            lw=4)\n",
    "        \n",
    "    if refs is not None:\n",
    "        assert len(refs) == len(metrics) or len(ref) == 1, \"Must provide a reference for each metric\"\n",
    "\n",
    "        if len(refs) == 1:\n",
    "            refs = refs * len(metrics)\n",
    "            \n",
    "        lstyles = ['dotted', 'dashed', 'dashdot']\n",
    "        for k, ref in enumerate(refs):\n",
    "            \n",
    "            if isinstance(ref, list):\n",
    "                for i, r in enumerate(ref):\n",
    "                    ax[k].axhline(y=r, color='r', linestyle=lstyles[i])\n",
    "            else:        \n",
    "                ax[k].axhline(y=ref, color='r', linestyle=lstyles[0])\n",
    "            \n",
    "    ax[-1].set_xlabel(\"Iterations\")\n",
    "          \n",
    "    save_dir = \"plots\"\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)  \n",
    "        \n",
    "    \n",
    "        \n",
    "    plt.savefig(os.path.join(save_dir, get_filename('_'.join(['x'.join(m) if isinstance(m, list) else m for m in metrics]), sweep, key_word, val) + \".pdf\"))\n",
    "    plt.show()\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f2b78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for plotting a selection of curves\n",
    "\n",
    "def plot_individual_runs_range(metrics, labels, min_val, max_val, ymin=None, ymax=None, sweep=None, key_word=\"\", num_its=100001):\n",
    "    \n",
    "    assert len(metrics) == len(labels), \"Must provide a label for each metric\"\n",
    "    \n",
    "    if ymin is not None and not isinstance(ymin, list):\n",
    "        ymin = [ymin] * len(metrics)\n",
    "    if ymax is not None and not isinstance(ymax, list):\n",
    "        ymax = [ymax] * len(metrics)\n",
    "    \n",
    "    files = get_all_files(sweep, key_word)\n",
    "    \n",
    "    vals = [(file.split(key_word + \"_\")[-1]).split(\".txt\")[0] for file in files]\n",
    "    vals = [float(val) for val in vals if float(val) >= min_val and float(val) <= max_val]\n",
    "        \n",
    "    geo_samples = [int(i) for i in np.geomspace(1, num_its - 1, num=700)]\n",
    "    cmap = matplotlib.colormaps['viridis']\n",
    "    #colors = [cmap((50 + 300 * i) / 1000) for i in range(len(metrics))]\n",
    "    \n",
    "    fig, ax = plt.subplots(len(metrics), 1, figsize=(5, len(metrics) * 3), sharex=True)\n",
    "    \n",
    "    if sweep is None:\n",
    "        base_dir = RESULTS_DIR\n",
    "    else:\n",
    "        base_dir = os.path.join(RESULTS_DIR, sweep)\n",
    "        \n",
    "    vals.sort()\n",
    "    for val in vals:\n",
    "        \n",
    "        with open(os.path.join(base_dir, get_run_name(key_word, val) + \".txt\"), \"r\") as f:\n",
    "            # Load the dictionary from the file\n",
    "            data_dict = json.load(f)\n",
    "\n",
    "        for k, metric in enumerate(metrics):\n",
    "                \n",
    "            data_vec = None    \n",
    "            if isinstance(metric, list):\n",
    "                for i, m in enumerate(metric):\n",
    "                    assert m in data_dict, \"Unknown metric\"\n",
    "                    \n",
    "                    if i == 0:\n",
    "                        data_vec = np.array(data_dict[m])\n",
    "                    else:\n",
    "                        data_vec *= np.array(data_dict[m])\n",
    "            else:\n",
    "                assert metric in data_dict, \"Unknown metric\"\n",
    "                data_vec = np.array(data_dict[metric])\n",
    "\n",
    "            if data_vec.shape[-1] < num_its:\n",
    "                data_vec_0 = np.zeros((num_its,))\n",
    "                data_vec_0[-data_vec.shape[-1]:] = data_vec\n",
    "                data_vec = data_vec_0\n",
    "           \n",
    "            ax[k].plot(geo_samples, data_vec[geo_samples],\n",
    "                #color=colors,\n",
    "                #label=key_word + f\"_{val}\",\n",
    "                lw=4)                \n",
    "    \n",
    "    for k, axis in enumerate(ax):\n",
    "        axis.set_xscale('log') # ??\n",
    "        axis.set_ylabel(labels[k])\n",
    "        axis.legend([val for val in vals], loc=2)\n",
    "        \n",
    "        if ymin is not None and ymax is not None:\n",
    "            axis.set_ylim([ymin[k], ymax[k]])\n",
    "\n",
    "            \n",
    "    ax[-1].set_xlabel(\"Iterations\")\n",
    "          \n",
    "    save_dir = \"plots\"\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)  \n",
    "        \n",
    "        \n",
    "    plt.savefig(os.path.join(save_dir, get_filename_range('_'.join(['x'.join(m) if isinstance(m, list) else m for m in metrics]), min_val, max_val, sweep, key_word) + \".pdf\"))\n",
    "    plt.show()\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e7bc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(metrics, labels, vmin=0, vmax=50, sweep=None, key_word=\"\", keep_nan=True, plot_nans=False, \n",
    "                 num_its=100001, ratio=1, xlabel=None, title=None):\n",
    "\n",
    "    assert len(metrics) == len(labels), \"Must provide a label for each metric\"\n",
    "\n",
    "    if not isinstance(vmin, list):\n",
    "        vmin = [vmin] * len(metrics)\n",
    "    if not isinstance(vmax, list):\n",
    "        vmax = [vmax] * len(metrics)   \n",
    "    \n",
    "    files = get_all_files(sweep, key_word)\n",
    " \n",
    "    vals = [(file.split(key_word + \"_\")[-1]).split(\".txt\")[0] for file in files]\n",
    "    vals = list(set(vals))\n",
    "    vals_float = [float(v) for v in vals]\n",
    "    vals_float, vals = zip(*sorted(zip(vals_float, vals)))\n",
    "    \n",
    "    if sweep is None:\n",
    "        base_dir = RESULTS_DIR\n",
    "    else:\n",
    "        base_dir = os.path.join(RESULTS_DIR, sweep)\n",
    "    \n",
    "    metrics_data = np.zeros((len(metrics), len(vals), num_its))\n",
    "    for i, v in enumerate(vals):\n",
    "\n",
    "        with open(os.path.join(base_dir, get_run_name(key_word, v) + \".txt\"), \"r\") as f:\n",
    "            # Load the dictionary from the file\n",
    "            data_dict = json.load(f)\n",
    "                                \n",
    "        for k, metric in enumerate(metrics):  \n",
    "            \n",
    "            \n",
    "            #if metric.startswith(\"weight_norm\"):\n",
    "            #    print(data_dict[metric][0])\n",
    "            \n",
    "            curr_data = None\n",
    "            if isinstance(metric, list):\n",
    "                for j, m in enumerate(metric):\n",
    "                    assert m in data_dict, \"Unknown metric\"\n",
    "                    \n",
    "                    if j == 0:\n",
    "                        curr_data = np.array(data_dict[m])\n",
    "                    else:\n",
    "                        curr_data *= np.array(data_dict[m])\n",
    "            else:\n",
    "                assert metric in data_dict, \"Unknown metric\"\n",
    "                curr_data = np.array(data_dict[metric])\n",
    "            \n",
    "            if len(curr_data) < num_its:\n",
    "                metrics_data[k, i, (num_its-len(data_dict[metric])):] =  curr_data\n",
    "            else:\n",
    "                metrics_data[k, i, :] = curr_data\n",
    "      \n",
    "    for k, metric in enumerate(metrics):\n",
    "        if (~np.isfinite(metrics_data[k, :, :])).any():\n",
    "            print(r\"Value with nan/inf, then some lower val\")\n",
    "            idx=np.nonzero(~(~np.isfinite(metrics_data[k, :, :])).any(axis=-1))[0][-1] # + 1\n",
    "            for j in range(10):\n",
    "                if plot_nans:\n",
    "                    plot_individual_run([metric], [labels[k]], sweep, key_word, vals[idx-j])\n",
    "                else:\n",
    "                    print(vals[idx-j])\n",
    "        else:\n",
    "            print('No nans/inf values')\n",
    "        \n",
    "        \n",
    "    ratios = np.array(vals_float) / ratio\n",
    "            \n",
    "    # Subsample epochs\n",
    "    geo_samples = [int(i) for i in np.geomspace(1, num_its - 1, num=700)]\n",
    "    fig, ax = plt.subplots(len(metrics), 1, figsize=(5, len(metrics) * 3), sharex=False)\n",
    "    \n",
    "\n",
    "    # For setting correct x- and y-ticks\n",
    "    # X axis\n",
    "    min_pow_x = math.floor(math.log(min(ratios), 10))\n",
    "    max_pow_x = math.floor(math.log(max(ratios), 10))\n",
    "    ten_powers_x = 10.0 ** np.arange(min_pow_x, max_pow_x)\n",
    "    \n",
    "    x_indices = []\n",
    "    for val in ten_powers_x:\n",
    "        x_indices += [np.argmin(np.abs(ratios-val))]\n",
    "    \n",
    "    # Y axis\n",
    "    max_pow_y = math.floor(math.log(num_its, 10))\n",
    "    min_pow_y = 0\n",
    "    print(np.arange(max_pow_y, min_pow_y, -1))\n",
    "    ten_powers_y = 10.0 ** np.arange(max_pow_y, min_pow_y, -1)\n",
    "    y_indices = []\n",
    "    for val in ten_powers_y:\n",
    "        y_indices += [np.argmin(np.abs(geo_samples[::-1]-val))]\n",
    "        print(val)\n",
    "        print(y_indices)\n",
    "        \n",
    "    \n",
    "    metrics_data = np.transpose(metrics_data, axes=(0, 2, 1))\n",
    "    for k in range(len(metrics)):\n",
    "        # Plot\n",
    "        im = ax[k].imshow(metrics_data[k, geo_samples, :][::-1, :], interpolation='none', aspect='auto', vmax=vmax[k], vmin=vmin[k])\n",
    "        fig.colorbar(im, ax=ax[k])\n",
    "    \n",
    "        ax[k].set_title(labels[k])\n",
    "        \n",
    "        # x-axis\n",
    "        ax[k].set_xticks(x_indices)\n",
    "        ax[k].set_xticklabels([f\"$10^{{{i}}}$\" for i in np.arange(min_pow_x, max_pow_x)])\n",
    "        \n",
    "        if xlabel is None:\n",
    "            ax[k].set_xlabel(key_word)\n",
    "        else:\n",
    "            ax[k].set_xlabel(xlabel)\n",
    "            \n",
    "        # y-axis\n",
    "        ax[k].set_yticks(y_indices)\n",
    "        ax[k].set_yticklabels([f\"$10^{{{i}}}$\" for i in np.arange(max_pow_y, min_pow_y, -1)]) \n",
    "        ax[k].set_ylabel(r\"Iteration $t$\")\n",
    "                \n",
    "            \n",
    "    if title is not None:\n",
    "        plt.suptitle(title)\n",
    "        \n",
    "    fig.tight_layout(pad=2.0)\n",
    "    \n",
    "    # Save file\n",
    "    save_dir = \"plots\"\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)  \n",
    "        \n",
    "    plt.savefig(os.path.join(\"plots\", get_filename('_'.join(['x'.join(m) if isinstance(m, list) else m for m in metrics]), sweep, key_word)) + \".pdf\", bbox_inches='tight')\n",
    "    \n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f164b828",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_dicts(sweep, key_word=\"\"):\n",
    "    \n",
    "    files = get_all_files(sweep, key_word)\n",
    " \n",
    "    vals = [(file.split(key_word + \"_\")[-1]).split(\".txt\")[0] for file in files]\n",
    "    vals = list(set(vals))\n",
    "    vals_float = [float(v) for v in vals]\n",
    "    vals_float, vals = zip(*sorted(zip(vals_float, vals)))\n",
    "    \n",
    "    if sweep is None:\n",
    "        base_dir = RESULTS_DIR\n",
    "    else:\n",
    "        base_dir = os.path.join(RESULTS_DIR, sweep)\n",
    "    \n",
    "    for i, v in enumerate(vals):\n",
    "\n",
    "        with open(os.path.join(base_dir, get_run_name(key_word, v) + \".txt\"), \"r\") as f:\n",
    "            # Load the dictionary from the file\n",
    "            data_dict = json.load(f)\n",
    "            \n",
    "            \n",
    "        with open(os.path.join(base_dir, get_run_name(key_word, v) + \"_old.txt\"), \"w\") as f:\n",
    "            json.dump(data_dict, f)\n",
    "            \n",
    "        fixed_dict = {}\n",
    "        grad_norm, weight_norm = [], [] # We assume that these are sorted\n",
    "        for key, value in data_dict.items():\n",
    "            if \"grad_norm\" in key:\n",
    "                grad_norm.append(value)\n",
    "            elif \"weight_norm\" in key:\n",
    "                weight_norm.append(value)\n",
    "            else:\n",
    "                fixed_dict[key] = value\n",
    "            \n",
    "        grad_norm = np.row_stack(grad_norm)\n",
    "        weight_norm = np.row_stack(weight_norm)\n",
    "        \n",
    "        for i in range(grad_norm.shape[-1]):\n",
    "            fixed_dict[\"grad_norm_\" + str(i + 1)] = grad_norm[:, i].tolist()\n",
    "            \n",
    "        for i in range(weight_norm.shape[-1]):\n",
    "            fixed_dict[\"weight_norm_\" + str(i + 1)] = weight_norm[:, i].tolist()\n",
    "        \n",
    "        with open(os.path.join(base_dir, get_run_name(key_word, v) + \".txt\"), \"w\") as f:\n",
    "            json.dump(fixed_dict, f)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e002607",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_DIR = \"results/two_layer_results_l2/transform_data\" #/theoretical\" #five_layer_regression_results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c36808c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_individual_run([\"loss\", \"risk\"], [\"train MSE\", \"test MSE\"], sweep=\"d2n10lr1\", key_word=\"lr1\", val=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fffe3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results([\"loss\", \"risk\", \"weight_mse_1\", \"weight_mse_2\", \"weight_mse_min_1\", \"weight_mse_min_2\", \"weight_norm_1\", \"weight_norm_2\"], [\"train MSE\", \"test MSE\", \"weight MSE true, large\", \"weight MSE true, small\", \"weight MSE global, large\", \"weight MSE global, small\", \"Weight norm, layer 1\", \"Weight norm, layer 2\"], vmin=[15, 0, 0, 0, 0, 0, 0, 0], vmax=[20, 8, 0.3, 1.1, 1.0, 0.15, 1, 0.5], sweep=\"d2n10lr1normalfixedinit\", key_word=\"lr1\", ratio=0.001, xlabel=\"lr layer 1 / lr layer 2\", title=\"lr layer 2=0.001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f89099",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results([\"loss\", \"risk\", \"weight_mse_1\", \"weight_mse_2\", \"weight_mse_min_1\", \"weight_mse_min_2\", \"weight_norm_1\", \"weight_norm_2\"], [\"train MSE\", \"test MSE\", \"weight MSE true, large\", \"weight MSE true, small\", \"weight MSE global, large\", \"weight MSE global, small\", \"Weight norm, layer 1\", \"Weight norm, layer 2\"], vmin=[15, 0, 0, 0, 0, 0, 0, 0], vmax=[20, 8, 0.3, 1.1, 1.0, 0.15, 1, 0.5], sweep=\"d2n10lr1normalfixedinitscaled\", key_word=\"lr1\", ratio=0.001, xlabel=\"lr layer 1 / lr layer 2\", title=\"lr layer 2=0.001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1438828d",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_opt = np.array([[0.8291264, 0.3558922]])\n",
    "W1_init = np.ones((50, 2)) * 0.01\n",
    "_, S, _ = np.linalg.svd(W1_init @ np.diag([3.0, 1.0]) @ W1_init.T)\n",
    "print(S)\n",
    "\n",
    "w2_star = np.linalg.solve(xs_init.T @ xs_init, )\n",
    "plot_individual_run([\"loss\", \"risk\", \"weights_1\", \"weights_2\"], [\"train MSE\", \"test MSE\", fr\"$w_1$\", fr\"$w_2$\"], sweep=\"d2n10lr1normalfixedinit\", key_word=\"lr1\", val=1.04811313e-07, refs=[15.9306793, 2, [global_opt[0, 0], 1/3], [global_opt[0, 1], 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c05fa51",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results([\"weights_1\", \"weights_2\", \"weights_3\"], [fr\"$u$\", fr\"$z_1$\", fr\"$z_2$\"], vmin=[0, 0, -2], vmax=[5, 5, 0], sweep=\"d2n10lr1teofixedinitoppsigns\", key_word=\"lr1\", ratio=0.001, xlabel=\"lr layer 1 / lr layer 2\", title=\"lr layer 2=0.001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19be9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results([[\"weights_1\", \"weights_2\"], [\"weights_1\", \"weights_3\"]], [fr\"$uz_1$\", fr\"$uz_2$\"], vmin=[0, -2], vmax=[1.5, 0], sweep=\"d2n10lr1teofixedinitoppsigns\", key_word=\"lr1\", ratio=0.001, xlabel=\"lr layer 1 / lr layer 2\", title=\"lr layer 2=0.001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3611232",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_individual_runs_range([\"weights_1\", \"weights_2\", \"weights_3\"], [fr\"$u$\", fr\"$z_1$\", fr\"$z_2$\"], 0.0000001, 0.000001, ymin=[0, 0, -0.3], ymax=[10, 0.3, 0], sweep=\"d2n10lr1teofixedinitoppsigns\", key_word=\"lr1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115e4aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MÅSTE FIXA LINJER\n",
    "plot_individual_run([\"loss\", \"risk\", [\"weights_1\", \"weights_2\"], [\"weights_1\", \"weights_3\"]], [\"train MSE\", \"test MSE\", fr\"$uz_1$\", fr\"$uz_2$\"], sweep=\"d2n10lr1teofixedinitminshift\", key_word=\"lr1\", val=1.04811313e-07, refs=[15.9306793, 2, [0.8291264, 1/3], [-1.6441076, -1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c3c17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ustar = (9 * 0.8291264 * 0.1 + 1 * 0.3558922 * 19.9) / (9 * 0.1**2 + 1 * 19.9**2)\n",
    "plot_individual_run([\"loss\", \"risk\", [\"weights_1\", \"weights_2\"], [\"weights_1\", \"weights_3\"]], [\"train MSE\", \"test MSE\", fr\"$uz_1$\", fr\"$uz_2$\"], sweep=\"d2n10lr1teofixedinitoppsignse\", key_word=\"lr1\", val=0.001, refs=[15.9306793, 2, [0.8291264, 1/3, ustar * 0.1], [0.3558922, 1, ustar * 19.9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a047ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ustar = (9 * 0.8291264 * 0.1 + 1 * 0.3558922 * 19.9) / (9 * 0.1**2 + 1 * 19.9**2)\n",
    "ustarshift = (9 * 0.8291264 * 10 + 1 * 0.3558922 * 10) / (9 * 10**2 + 1 * 10**2)\n",
    "plot_individual_run([\"loss\", \"risk\", \"weights_1\", \"weights_2\", \"weights_3\", [\"weights_1\", \"weights_2\"], [\"weights_1\", \"weights_3\"]], [\"train MSE\", \"test MSE\", fr\"$u$\", fr\"$z_1$\", fr\"$z_2$\", fr\"$uz_1$\", fr\"$uz_2$\"], sweep=\"d2n10lr1teofixedinitoppsignse\", key_word=\"lr1\", val=0.001, refs=[15.9306793, 2, [ustar, ustarshift, 0.8291264 / ustar, 0.3558922 /ustar, [0.8291264, 1/3, ustar * 0.1], [0.3558922, 1, ustar * 19.9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996ada12",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_individual_run([\"loss\", \"risk\", \"weight_mse_2\", \"weight_mse_min_2\", [\"weights_1\", \"weights_2\"], [\"weights_1\", \"weights_3\"]], [\"train MSE\", \"test MSE\", \"weight MSE true, small\", \"weight MSE global, small\", fr\"$uz_1$\", fr\"$uz_2$\"], sweep=\"d2n10lr1teofixedinit\", key_word=\"lr1\", val=1.04811313e-07, refs=[15.9306793, 2, 0, 0, [0.8291264, 1/3], [0.3558922, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01cc3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ustar = (9 * 0.8291264 * 0.001 + 1 * 0.3558922 * 0.1) / (9 * 0.001**2 + 1 * 0.1**2)\n",
    "ustarshift = (9 * 0.8291264 * 0.1 + 1 * 0.3558922 * 0.08) / (9 * 0.1**2 + 1 * 0.08**2)\n",
    "plot_individual_run([\"loss\", \"risk\",  \"weight_mse_1\", \"weight_mse_2\", \"weight_mse_min_1\", \"weights_1\", \"weights_2\", \"weights_3\", [\"weights_1\", \"weights_2\"], [\"weights_1\", \"weights_3\"]], [\"train MSE\", \"test MSE\", fr\"$u$\", fr\"$z_1$\", fr\"$z_2$\", fr\"$uz_1$\", fr\"$uz_2$\"], sweep=\"d2n10lr1teofixedinitscaledswitch\", key_word=\"lr1\", val=1.04811313e-07, refs=[15.9306793, 2, [ustar, ustarshift], 0.8291264 / ustar, 0.3558922 /ustar, [0.8291264, 1/3, ustar * 0.001], [0.3558922, 1, ustar * 0.1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3efa8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ustar = (9 * 0.8291264 * 0.1 + 1 * 0.3558922 * 0.1) / (9 * 0.1**2 + 1 * 0.1**2)\n",
    "plot_individual_run([\"loss\", \"risk\", \"weights_1\", \"weights_2\", \"weights_3\", [\"weights_1\", \"weights_2\"], [\"weights_1\", \"weights_3\"]], [\"train MSE\", \"test MSE\", fr\"$u$\", fr\"$z_1$\", fr\"$z_2$\", fr\"$uz_1$\", fr\"$uz_2$\"], sweep=\"d2n10lr1teofixedinit\", key_word=\"lr1\", val=1.04811313e-07, refs=[15.9306793, 2, ustar, 0.8291264 / ustar, 0.3558922 /ustar, [0.8291264, 1/3, ustar * 0.1], [0.3558922, 1, ustar * 0.1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b59a0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
